{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qol-ovwtLUoI",
        "outputId": "b0afd9f5-b046-437f-d0f3-0b6a6243c497"
      },
      "source": [
        "%cd '/content/drive/My Drive/AI'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akQKed_BKnZ_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.regularizers import l1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OQ3skMDKrSu"
      },
      "source": [
        "dataframe = pd.read_csv(\"4.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBhEoYpKuZi"
      },
      "source": [
        "nn_input = np.asarray(dataframe.iloc[:,0:4])\n",
        "nn_output = np.asarray(dataframe.iloc[:,4])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-PAwNJfFiwd",
        "outputId": "7c4513ca-0695-403c-93ac-29b8fca439e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04LoNzphKzqR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_temp, y_train, y_temp = train_test_split( nn_input, nn_output, test_size = 0.1, random_state = 55) \n",
        "x_valid, x_test, y_valid, y_test = train_test_split( x_temp, y_temp, test_size = 0.1, random_state = 65) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbHnX9Q7Kzng"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, input_dim=4, activity_regularizer=l1(0.005)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(500, activity_regularizer=l1(0.006)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(800, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(900, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(500, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1, activity_regularizer=l1(0.002)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxtrwoCiK5CQ"
      },
      "source": [
        "model.compile(loss='mse',\n",
        "                  optimizer=Adam(learning_rate=0.001),\n",
        "                  metrics=['mse', 'mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uz2PxcoLqJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e5c6ab-e3b2-4eaa-aef5-ad94205238c8"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 200,\n",
        "                        validation_data=(x_valid, y_valid),\n",
        "                        batch_size = 16, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 18s 7ms/step - loss: 7.1041 - mse: 6.7847 - mae: 2.0726 - val_loss: 6.7933 - val_mse: 6.7143 - val_mae: 2.0604\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7267 - mse: 6.6756 - mae: 2.0695 - val_loss: 6.7300 - val_mse: 6.7098 - val_mae: 2.0598\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7494 - mse: 6.7326 - mae: 2.0413 - val_loss: 6.7244 - val_mse: 6.7108 - val_mae: 2.0599\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9253 - mse: 6.9090 - mae: 2.0897 - val_loss: 6.7360 - val_mse: 6.7199 - val_mae: 2.0613\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8750 - mse: 6.8584 - mae: 2.0909 - val_loss: 6.7292 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7945 - mse: 6.7802 - mae: 2.0692 - val_loss: 6.7370 - val_mse: 6.7085 - val_mae: 2.0595\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6591 - mse: 6.6415 - mae: 2.0581 - val_loss: 6.7239 - val_mse: 6.7138 - val_mae: 2.0604\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8784 - mse: 6.8420 - mae: 2.0745 - val_loss: 6.7830 - val_mse: 6.7135 - val_mae: 2.0603\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9751 - mse: 6.9301 - mae: 2.1045 - val_loss: 6.7710 - val_mse: 6.7446 - val_mae: 2.0652\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8646 - mse: 6.8380 - mae: 2.0820 - val_loss: 6.7266 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7045 - mse: 6.6921 - mae: 2.0500 - val_loss: 6.7198 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7836 - mse: 6.7723 - mae: 2.0767 - val_loss: 6.7278 - val_mse: 6.7087 - val_mae: 2.0596\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7823 - mse: 6.7645 - mae: 2.0779 - val_loss: 6.7274 - val_mse: 6.7140 - val_mae: 2.0604\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 6.8818 - mse: 6.8716 - mae: 2.0902 - val_loss: 6.7273 - val_mse: 6.7141 - val_mae: 2.0604\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5166 - mse: 6.5040 - mae: 2.0263 - val_loss: 6.7322 - val_mse: 6.7149 - val_mae: 2.0605\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8757 - mse: 6.8599 - mae: 2.0937 - val_loss: 6.7190 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7400 - mse: 6.7328 - mae: 2.0793 - val_loss: 6.7174 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7273 - mse: 6.7208 - mae: 2.0849 - val_loss: 6.7194 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8560 - mse: 6.8498 - mae: 2.0865 - val_loss: 6.7197 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7025 - mse: 6.6943 - mae: 2.0666 - val_loss: 6.7220 - val_mse: 6.7138 - val_mae: 2.0604\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8641 - mse: 6.8568 - mae: 2.0808 - val_loss: 6.7200 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7261 - mse: 6.7194 - mae: 2.0674 - val_loss: 6.7237 - val_mse: 6.7076 - val_mae: 2.0593\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7779 - mse: 6.7504 - mae: 2.0684 - val_loss: 6.7208 - val_mse: 6.7136 - val_mae: 2.0603\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9191 - mse: 6.9110 - mae: 2.0963 - val_loss: 6.7187 - val_mse: 6.7115 - val_mae: 2.0600\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9268 - mse: 6.9189 - mae: 2.0872 - val_loss: 6.7262 - val_mse: 6.7115 - val_mae: 2.0600\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9135 - mse: 6.9035 - mae: 2.0872 - val_loss: 6.7203 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7867 - mse: 6.7795 - mae: 2.0792 - val_loss: 6.7173 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9190 - mse: 6.9138 - mae: 2.1028 - val_loss: 6.7170 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0462 - mse: 7.0413 - mae: 2.1140 - val_loss: 6.7170 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0094 - mse: 7.0057 - mae: 2.1018 - val_loss: 6.7166 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9953 - mse: 6.9907 - mae: 2.1197 - val_loss: 6.7160 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7460 - mse: 6.7421 - mae: 2.0569 - val_loss: 6.7165 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.1578 - mse: 7.1544 - mae: 2.1380 - val_loss: 6.7159 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8330 - mse: 6.8299 - mae: 2.0979 - val_loss: 6.7155 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9765 - mse: 6.9736 - mae: 2.1104 - val_loss: 6.7159 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6773 - mse: 6.6743 - mae: 2.0557 - val_loss: 6.7153 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7293 - mse: 6.7264 - mae: 2.0741 - val_loss: 6.7155 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7643 - mse: 6.7606 - mae: 2.0736 - val_loss: 6.7181 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9539 - mse: 6.9497 - mae: 2.0872 - val_loss: 6.7179 - val_mse: 6.7132 - val_mae: 2.0603\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7366 - mse: 6.7323 - mae: 2.0731 - val_loss: 6.8807 - val_mse: 6.7164 - val_mae: 2.0606\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9757 - mse: 6.8805 - mae: 2.0914 - val_loss: 6.7443 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6388 - mse: 6.6144 - mae: 2.0399 - val_loss: 6.7243 - val_mse: 6.7112 - val_mae: 2.0600\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0124 - mse: 7.0017 - mae: 2.1140 - val_loss: 6.7188 - val_mse: 6.7116 - val_mae: 2.0601\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9006 - mse: 6.8924 - mae: 2.1048 - val_loss: 6.7210 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6843 - mse: 6.6757 - mae: 2.0612 - val_loss: 6.7194 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9239 - mse: 6.9165 - mae: 2.0853 - val_loss: 6.7188 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8467 - mse: 6.8402 - mae: 2.0911 - val_loss: 6.7173 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8403 - mse: 6.8352 - mae: 2.0915 - val_loss: 6.7172 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9961 - mse: 6.9912 - mae: 2.1181 - val_loss: 6.7173 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7284 - mse: 6.7232 - mae: 2.0753 - val_loss: 6.7165 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8665 - mse: 6.8624 - mae: 2.1024 - val_loss: 6.7156 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8286 - mse: 6.8248 - mae: 2.0838 - val_loss: 6.7154 - val_mse: 6.7116 - val_mae: 2.0601\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8933 - mse: 6.8895 - mae: 2.0944 - val_loss: 6.7154 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0234 - mse: 7.0199 - mae: 2.1142 - val_loss: 6.7173 - val_mse: 6.7129 - val_mae: 2.0603\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8171 - mse: 6.8133 - mae: 2.0737 - val_loss: 6.7177 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7191 - mse: 6.7151 - mae: 2.0653 - val_loss: 6.7161 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8646 - mse: 6.8609 - mae: 2.0729 - val_loss: 6.7157 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8173 - mse: 6.8007 - mae: 2.0732 - val_loss: 6.7763 - val_mse: 6.7079 - val_mae: 2.0594\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8163 - mse: 6.7768 - mae: 2.0795 - val_loss: 6.7363 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0082 - mse: 6.9919 - mae: 2.0999 - val_loss: 6.7211 - val_mse: 6.7134 - val_mae: 2.0603\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8319 - mse: 6.8241 - mae: 2.0984 - val_loss: 6.7205 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8689 - mse: 6.8605 - mae: 2.0923 - val_loss: 6.7213 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5978 - mse: 6.5908 - mae: 2.0495 - val_loss: 6.7191 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0614 - mse: 7.0557 - mae: 2.1131 - val_loss: 6.7183 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9513 - mse: 6.9452 - mae: 2.1089 - val_loss: 6.7183 - val_mse: 6.7132 - val_mae: 2.0603\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8394 - mse: 6.8341 - mae: 2.0854 - val_loss: 6.7172 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8196 - mse: 6.8153 - mae: 2.0696 - val_loss: 6.7172 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7883 - mse: 6.7826 - mae: 2.0607 - val_loss: 6.7210 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8958 - mse: 6.8893 - mae: 2.0931 - val_loss: 6.7178 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8816 - mse: 6.8768 - mae: 2.1023 - val_loss: 6.7171 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7926 - mse: 6.7883 - mae: 2.0775 - val_loss: 6.7156 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7764 - mse: 6.7728 - mae: 2.0848 - val_loss: 6.7161 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0257 - mse: 7.0218 - mae: 2.1075 - val_loss: 6.7158 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7829 - mse: 6.7796 - mae: 2.0796 - val_loss: 6.7158 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6587 - mse: 6.6556 - mae: 2.0517 - val_loss: 6.7151 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8188 - mse: 6.8147 - mae: 2.0731 - val_loss: 6.7174 - val_mse: 6.7108 - val_mae: 2.0599\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7793 - mse: 6.7750 - mae: 2.0655 - val_loss: 6.7155 - val_mse: 6.7112 - val_mae: 2.0600\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9127 - mse: 6.9094 - mae: 2.0937 - val_loss: 6.7151 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7655 - mse: 6.7619 - mae: 2.0731 - val_loss: 6.7150 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9534 - mse: 6.9504 - mae: 2.0954 - val_loss: 6.7151 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9077 - mse: 6.9045 - mae: 2.0945 - val_loss: 6.7451 - val_mse: 6.7189 - val_mae: 2.0611\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8185 - mse: 6.7690 - mae: 2.0790 - val_loss: 6.7230 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9529 - mse: 6.9447 - mae: 2.0985 - val_loss: 6.7192 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6058 - mse: 6.6000 - mae: 2.0414 - val_loss: 6.7174 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8565 - mse: 6.8519 - mae: 2.0919 - val_loss: 6.7174 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 6.8349 - mse: 6.8301 - mae: 2.0835 - val_loss: 6.7174 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9313 - mse: 6.9271 - mae: 2.1015 - val_loss: 6.7166 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9157 - mse: 6.9121 - mae: 2.1013 - val_loss: 6.7171 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0126 - mse: 7.0085 - mae: 2.1087 - val_loss: 6.7162 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8583 - mse: 6.8539 - mae: 2.0779 - val_loss: 6.7164 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9925 - mse: 6.9885 - mae: 2.1104 - val_loss: 6.7183 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8378 - mse: 6.8320 - mae: 2.0900 - val_loss: 6.7250 - val_mse: 6.7135 - val_mae: 2.0603\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8862 - mse: 6.8762 - mae: 2.1139 - val_loss: 6.7192 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7436 - mse: 6.7368 - mae: 2.0720 - val_loss: 6.7179 - val_mse: 6.7113 - val_mae: 2.0600\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8932 - mse: 6.8876 - mae: 2.1046 - val_loss: 6.7160 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9509 - mse: 6.9466 - mae: 2.1036 - val_loss: 6.7181 - val_mse: 6.7134 - val_mae: 2.0603\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8158 - mse: 6.8116 - mae: 2.0978 - val_loss: 6.7161 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7076 - mse: 6.7036 - mae: 2.0592 - val_loss: 6.7190 - val_mse: 6.7138 - val_mae: 2.0604\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0477 - mse: 7.0422 - mae: 2.1099 - val_loss: 6.7173 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9660 - mse: 6.9104 - mae: 2.0996 - val_loss: 6.7653 - val_mse: 6.7148 - val_mae: 2.0605\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8131 - mse: 6.7903 - mae: 2.0756 - val_loss: 6.7225 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7198 - mse: 6.7107 - mae: 2.0806 - val_loss: 6.7224 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7861 - mse: 6.7767 - mae: 2.0667 - val_loss: 6.7184 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7633 - mse: 6.7567 - mae: 2.0749 - val_loss: 6.7161 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7681 - mse: 6.7633 - mae: 2.0708 - val_loss: 6.7161 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9719 - mse: 6.9672 - mae: 2.1107 - val_loss: 6.7166 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0070 - mse: 7.0021 - mae: 2.0997 - val_loss: 6.7164 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7047 - mse: 6.7005 - mae: 2.0374 - val_loss: 6.7159 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9852 - mse: 6.9815 - mae: 2.1133 - val_loss: 6.7157 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8381 - mse: 6.8343 - mae: 2.0913 - val_loss: 6.7168 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8754 - mse: 6.8712 - mae: 2.0944 - val_loss: 6.7169 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8221 - mse: 6.8184 - mae: 2.0792 - val_loss: 6.7155 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9623 - mse: 6.9590 - mae: 2.1176 - val_loss: 6.7153 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8648 - mse: 6.8618 - mae: 2.0930 - val_loss: 6.7164 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9067 - mse: 6.9013 - mae: 2.0879 - val_loss: 6.7172 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7771 - mse: 6.7730 - mae: 2.0842 - val_loss: 6.7154 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8997 - mse: 6.8963 - mae: 2.0903 - val_loss: 6.7160 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9046 - mse: 6.9015 - mae: 2.0930 - val_loss: 6.7167 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9146 - mse: 6.9114 - mae: 2.0901 - val_loss: 6.7155 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8216 - mse: 6.8182 - mae: 2.0762 - val_loss: 6.7157 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7955 - mse: 6.7921 - mae: 2.0880 - val_loss: 6.7158 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.1208 - mse: 7.1172 - mae: 2.1303 - val_loss: 6.7154 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8463 - mse: 6.8429 - mae: 2.0850 - val_loss: 6.7150 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8529 - mse: 6.8498 - mae: 2.0924 - val_loss: 6.7150 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0003 - mse: 6.9971 - mae: 2.1130 - val_loss: 6.7152 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9774 - mse: 6.9723 - mae: 2.0977 - val_loss: 7.2009 - val_mse: 6.6970 - val_mae: 2.0564\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0952 - mse: 6.9125 - mae: 2.0982 - val_loss: 6.7549 - val_mse: 6.7113 - val_mae: 2.0600\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8665 - mse: 6.8202 - mae: 2.0827 - val_loss: 6.7474 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6364 - mse: 6.6023 - mae: 2.0504 - val_loss: 6.7430 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9939 - mse: 6.9651 - mae: 2.0957 - val_loss: 6.7325 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8292 - mse: 6.8081 - mae: 2.0797 - val_loss: 6.7293 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9776 - mse: 6.9621 - mae: 2.1013 - val_loss: 6.7301 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7991 - mse: 6.7835 - mae: 2.0738 - val_loss: 6.7235 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9452 - mse: 6.9324 - mae: 2.1002 - val_loss: 6.7277 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8268 - mse: 6.8145 - mae: 2.0751 - val_loss: 6.7247 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6713 - mse: 6.6595 - mae: 2.0579 - val_loss: 6.7219 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8551 - mse: 6.8448 - mae: 2.0846 - val_loss: 6.7202 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8629 - mse: 6.8532 - mae: 2.0750 - val_loss: 6.7215 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8200 - mse: 6.8107 - mae: 2.0730 - val_loss: 6.7205 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8617 - mse: 6.8536 - mae: 2.0900 - val_loss: 6.7208 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7665 - mse: 6.7581 - mae: 2.0760 - val_loss: 6.7203 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9118 - mse: 6.9045 - mae: 2.0963 - val_loss: 6.7188 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8024 - mse: 6.7956 - mae: 2.0890 - val_loss: 6.7184 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9234 - mse: 6.9169 - mae: 2.0994 - val_loss: 6.7176 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7724 - mse: 6.7665 - mae: 2.0689 - val_loss: 6.7193 - val_mse: 6.7135 - val_mae: 2.0603\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7935 - mse: 6.7873 - mae: 2.0755 - val_loss: 6.7191 - val_mse: 6.7114 - val_mae: 2.0600\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9563 - mse: 6.9484 - mae: 2.0966 - val_loss: 6.7163 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8706 - mse: 6.8661 - mae: 2.0973 - val_loss: 6.7182 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9092 - mse: 6.9049 - mae: 2.0900 - val_loss: 6.7192 - val_mse: 6.7139 - val_mae: 2.0604\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7860 - mse: 6.7813 - mae: 2.0882 - val_loss: 6.7162 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7334 - mse: 6.7296 - mae: 2.0772 - val_loss: 6.7157 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9531 - mse: 6.9496 - mae: 2.1122 - val_loss: 6.7171 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8220 - mse: 6.8176 - mae: 2.0842 - val_loss: 6.7156 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8253 - mse: 6.8220 - mae: 2.0837 - val_loss: 6.7161 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8340 - mse: 6.8303 - mae: 2.0849 - val_loss: 6.7154 - val_mse: 6.7116 - val_mae: 2.0601\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8332 - mse: 6.8297 - mae: 2.0832 - val_loss: 6.7149 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7540 - mse: 6.7507 - mae: 2.0820 - val_loss: 6.7163 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8939 - mse: 6.8906 - mae: 2.0830 - val_loss: 6.7157 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7381 - mse: 6.7348 - mae: 2.0689 - val_loss: 6.7159 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6042 - mse: 6.6010 - mae: 2.0514 - val_loss: 6.7159 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7186 - mse: 6.7156 - mae: 2.0676 - val_loss: 6.7158 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0516 - mse: 7.0484 - mae: 2.1078 - val_loss: 6.7157 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7870 - mse: 6.7840 - mae: 2.0663 - val_loss: 6.7154 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8151 - mse: 6.8122 - mae: 2.0745 - val_loss: 6.7151 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7095 - mse: 6.7067 - mae: 2.0674 - val_loss: 6.7152 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7888 - mse: 6.7860 - mae: 2.0767 - val_loss: 6.7160 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7781 - mse: 6.7747 - mae: 2.0595 - val_loss: 6.7155 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7005 - mse: 6.6974 - mae: 2.0749 - val_loss: 6.7147 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5664 - mse: 6.5636 - mae: 2.0283 - val_loss: 6.7154 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8176 - mse: 6.8124 - mae: 2.0792 - val_loss: 6.7170 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9023 - mse: 6.8975 - mae: 2.0794 - val_loss: 6.7164 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5292 - mse: 6.5249 - mae: 2.0393 - val_loss: 6.7159 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8856 - mse: 6.8816 - mae: 2.1011 - val_loss: 6.7156 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 6.9253 - mse: 6.9206 - mae: 2.1080 - val_loss: 6.7154 - val_mse: 6.7114 - val_mae: 2.0600\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7934 - mse: 6.7897 - mae: 2.0814 - val_loss: 6.7158 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7301 - mse: 6.7258 - mae: 2.0710 - val_loss: 6.7164 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9116 - mse: 6.9070 - mae: 2.0868 - val_loss: 6.7158 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0059 - mse: 7.0021 - mae: 2.1138 - val_loss: 6.7153 - val_mse: 6.7102 - val_mae: 2.0598\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0384 - mse: 7.0310 - mae: 2.1053 - val_loss: 6.7163 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9583 - mse: 6.9538 - mae: 2.1096 - val_loss: 6.7161 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9429 - mse: 6.9394 - mae: 2.0956 - val_loss: 6.7158 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8197 - mse: 6.8160 - mae: 2.0729 - val_loss: 6.7163 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0935 - mse: 7.0901 - mae: 2.1233 - val_loss: 6.7157 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7725 - mse: 6.7692 - mae: 2.0733 - val_loss: 6.7162 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8022 - mse: 6.7992 - mae: 2.0886 - val_loss: 6.7157 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8964 - mse: 6.8931 - mae: 2.0977 - val_loss: 6.7159 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8662 - mse: 6.8633 - mae: 2.0946 - val_loss: 6.7158 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0164 - mse: 7.0132 - mae: 2.1074 - val_loss: 6.7149 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9855 - mse: 6.9824 - mae: 2.1179 - val_loss: 6.7150 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0017 - mse: 6.9988 - mae: 2.1139 - val_loss: 6.7153 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9289 - mse: 6.9247 - mae: 2.1047 - val_loss: 6.7167 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0007 - mse: 6.9963 - mae: 2.1160 - val_loss: 6.7203 - val_mse: 6.7136 - val_mae: 2.0603\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0965 - mse: 7.0912 - mae: 2.0994 - val_loss: 6.7166 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0293 - mse: 7.0217 - mae: 2.1075 - val_loss: 6.7401 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0214 - mse: 6.9676 - mae: 2.1082 - val_loss: 6.7290 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6661 - mse: 6.6497 - mae: 2.0514 - val_loss: 6.7223 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8694 - mse: 6.8594 - mae: 2.0821 - val_loss: 6.7205 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6791 - mse: 6.6717 - mae: 2.0628 - val_loss: 6.7191 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7177 - mse: 6.7114 - mae: 2.0697 - val_loss: 6.7196 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6546 - mse: 6.6472 - mae: 2.0470 - val_loss: 6.7183 - val_mse: 6.7118 - val_mae: 2.0601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_soV27MfcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc88bc00-8152-4b42-9da8-fedbbe48cdce"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(50, input_dim=4, activation='relu'))\n",
        "model2.add(Dense(40, activation='relu'))\n",
        "model2.add(Dense(30, activation='relu'))\n",
        "model2.add(Dense(20, activation='relu'))\n",
        "model2.add(Dense(10, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "\n",
        "model2.compile(optimizer='rmsprop', loss='mse', metrics=['mse', 'mae'])\n",
        "\n",
        "# training model\n",
        "history = model2.fit(x_train, y_train, epochs = 200,\n",
        "                        validation_data=(x_valid, y_valid),\n",
        "                        batch_size = 16, verbose = 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "563/563 [==============================] - 3s 4ms/step - loss: 6.7393 - mse: 6.7393 - mae: 2.0749 - val_loss: 7.0225 - val_mse: 7.0225 - val_mae: 2.1126\n",
            "Epoch 2/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6776 - mse: 6.6776 - mae: 2.0685 - val_loss: 7.0484 - val_mse: 7.0484 - val_mae: 2.1166\n",
            "Epoch 3/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8259 - mse: 6.8259 - mae: 2.0823 - val_loss: 7.0493 - val_mse: 7.0493 - val_mae: 2.1162\n",
            "Epoch 4/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7850 - mse: 6.7850 - mae: 2.0808 - val_loss: 7.0420 - val_mse: 7.0420 - val_mae: 2.1158\n",
            "Epoch 5/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8218 - mse: 6.8218 - mae: 2.0828 - val_loss: 7.0497 - val_mse: 7.0497 - val_mae: 2.1172\n",
            "Epoch 6/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7446 - mse: 6.7446 - mae: 2.0882 - val_loss: 7.0343 - val_mse: 7.0343 - val_mae: 2.1154\n",
            "Epoch 7/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7393 - mse: 6.7393 - mae: 2.0720 - val_loss: 7.0444 - val_mse: 7.0444 - val_mae: 2.1180\n",
            "Epoch 8/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7739 - mse: 6.7739 - mae: 2.0801 - val_loss: 7.0500 - val_mse: 7.0500 - val_mae: 2.1169\n",
            "Epoch 9/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8707 - mse: 6.8707 - mae: 2.0815 - val_loss: 7.0522 - val_mse: 7.0522 - val_mae: 2.1181\n",
            "Epoch 10/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8641 - mse: 6.8641 - mae: 2.0918 - val_loss: 7.0801 - val_mse: 7.0801 - val_mae: 2.1206\n",
            "Epoch 11/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7562 - mse: 6.7562 - mae: 2.0713 - val_loss: 7.0907 - val_mse: 7.0907 - val_mae: 2.1235\n",
            "Epoch 12/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6817 - mse: 6.6817 - mae: 2.0593 - val_loss: 7.0651 - val_mse: 7.0651 - val_mae: 2.1193\n",
            "Epoch 13/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8666 - mse: 6.8666 - mae: 2.0960 - val_loss: 7.0658 - val_mse: 7.0658 - val_mae: 2.1208\n",
            "Epoch 14/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6793 - mse: 6.6793 - mae: 2.0581 - val_loss: 7.0863 - val_mse: 7.0863 - val_mae: 2.1216\n",
            "Epoch 15/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7460 - mse: 6.7460 - mae: 2.0676 - val_loss: 7.0890 - val_mse: 7.0890 - val_mae: 2.1233\n",
            "Epoch 16/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7373 - mse: 6.7373 - mae: 2.0708 - val_loss: 7.0578 - val_mse: 7.0578 - val_mae: 2.1194\n",
            "Epoch 17/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7485 - mse: 6.7485 - mae: 2.0730 - val_loss: 7.0990 - val_mse: 7.0990 - val_mae: 2.1239\n",
            "Epoch 18/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7815 - mse: 6.7815 - mae: 2.0718 - val_loss: 7.0713 - val_mse: 7.0713 - val_mae: 2.1211\n",
            "Epoch 19/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7510 - mse: 6.7510 - mae: 2.0758 - val_loss: 7.0853 - val_mse: 7.0853 - val_mae: 2.1255\n",
            "Epoch 20/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0091 - mse: 7.0091 - mae: 2.1192 - val_loss: 7.0733 - val_mse: 7.0733 - val_mae: 2.1215\n",
            "Epoch 21/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7509 - mse: 6.7509 - mae: 2.0683 - val_loss: 7.1249 - val_mse: 7.1249 - val_mae: 2.1279\n",
            "Epoch 22/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6518 - mse: 6.6518 - mae: 2.0645 - val_loss: 7.1208 - val_mse: 7.1208 - val_mae: 2.1290\n",
            "Epoch 23/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9772 - mse: 6.9772 - mae: 2.1041 - val_loss: 7.1350 - val_mse: 7.1350 - val_mae: 2.1303\n",
            "Epoch 24/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5817 - mse: 6.5817 - mae: 2.0367 - val_loss: 7.1037 - val_mse: 7.1037 - val_mae: 2.1259\n",
            "Epoch 25/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7566 - mse: 6.7566 - mae: 2.0694 - val_loss: 7.0847 - val_mse: 7.0847 - val_mae: 2.1231\n",
            "Epoch 26/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7490 - mse: 6.7490 - mae: 2.0669 - val_loss: 7.1039 - val_mse: 7.1039 - val_mae: 2.1250\n",
            "Epoch 27/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7003 - mse: 6.7003 - mae: 2.0616 - val_loss: 7.1066 - val_mse: 7.1066 - val_mae: 2.1245\n",
            "Epoch 28/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6826 - mse: 6.6826 - mae: 2.0549 - val_loss: 7.1822 - val_mse: 7.1822 - val_mae: 2.1378\n",
            "Epoch 29/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6097 - mse: 6.6097 - mae: 2.0477 - val_loss: 7.1602 - val_mse: 7.1602 - val_mae: 2.1325\n",
            "Epoch 30/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6719 - mse: 6.6719 - mae: 2.0537 - val_loss: 7.1077 - val_mse: 7.1077 - val_mae: 2.1251\n",
            "Epoch 31/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6630 - mse: 6.6630 - mae: 2.0555 - val_loss: 7.1653 - val_mse: 7.1653 - val_mae: 2.1325\n",
            "Epoch 32/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7515 - mse: 6.7515 - mae: 2.0714 - val_loss: 7.1841 - val_mse: 7.1841 - val_mae: 2.1399\n",
            "Epoch 33/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6995 - mse: 6.6995 - mae: 2.0670 - val_loss: 7.2304 - val_mse: 7.2304 - val_mae: 2.1439\n",
            "Epoch 34/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6290 - mse: 6.6290 - mae: 2.0478 - val_loss: 7.1922 - val_mse: 7.1922 - val_mae: 2.1398\n",
            "Epoch 35/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6486 - mse: 6.6486 - mae: 2.0499 - val_loss: 7.1678 - val_mse: 7.1678 - val_mae: 2.1322\n",
            "Epoch 36/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7729 - mse: 6.7729 - mae: 2.0755 - val_loss: 7.2383 - val_mse: 7.2383 - val_mae: 2.1414\n",
            "Epoch 37/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7402 - mse: 6.7402 - mae: 2.0578 - val_loss: 7.1659 - val_mse: 7.1659 - val_mae: 2.1389\n",
            "Epoch 38/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9137 - mse: 6.9137 - mae: 2.0937 - val_loss: 7.2559 - val_mse: 7.2559 - val_mae: 2.1491\n",
            "Epoch 39/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7070 - mse: 6.7070 - mae: 2.0585 - val_loss: 7.2597 - val_mse: 7.2597 - val_mae: 2.1467\n",
            "Epoch 40/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6941 - mse: 6.6941 - mae: 2.0521 - val_loss: 7.2225 - val_mse: 7.2225 - val_mae: 2.1432\n",
            "Epoch 41/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0224 - mse: 7.0224 - mae: 2.1047 - val_loss: 7.1849 - val_mse: 7.1849 - val_mae: 2.1401\n",
            "Epoch 42/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5699 - mse: 6.5699 - mae: 2.0496 - val_loss: 7.1919 - val_mse: 7.1919 - val_mae: 2.1424\n",
            "Epoch 43/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7284 - mse: 6.7284 - mae: 2.0691 - val_loss: 7.2443 - val_mse: 7.2443 - val_mae: 2.1493\n",
            "Epoch 44/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6377 - mse: 6.6377 - mae: 2.0587 - val_loss: 7.2548 - val_mse: 7.2548 - val_mae: 2.1476\n",
            "Epoch 45/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5685 - mse: 6.5685 - mae: 2.0391 - val_loss: 7.2903 - val_mse: 7.2903 - val_mae: 2.1467\n",
            "Epoch 46/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7441 - mse: 6.7441 - mae: 2.0804 - val_loss: 7.3447 - val_mse: 7.3447 - val_mae: 2.1590\n",
            "Epoch 47/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5588 - mse: 6.5588 - mae: 2.0359 - val_loss: 7.2553 - val_mse: 7.2553 - val_mae: 2.1497\n",
            "Epoch 48/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6919 - mse: 6.6919 - mae: 2.0626 - val_loss: 7.3506 - val_mse: 7.3506 - val_mae: 2.1619\n",
            "Epoch 49/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7195 - mse: 6.7195 - mae: 2.0591 - val_loss: 7.2515 - val_mse: 7.2515 - val_mae: 2.1479\n",
            "Epoch 50/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5852 - mse: 6.5852 - mae: 2.0415 - val_loss: 7.3075 - val_mse: 7.3075 - val_mae: 2.1510\n",
            "Epoch 51/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5380 - mse: 6.5380 - mae: 2.0372 - val_loss: 7.2873 - val_mse: 7.2873 - val_mae: 2.1510\n",
            "Epoch 52/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8586 - mse: 6.8586 - mae: 2.0833 - val_loss: 7.3299 - val_mse: 7.3299 - val_mae: 2.1597\n",
            "Epoch 53/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3990 - mse: 6.3990 - mae: 2.0127 - val_loss: 7.3408 - val_mse: 7.3408 - val_mae: 2.1630\n",
            "Epoch 54/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6532 - mse: 6.6532 - mae: 2.0473 - val_loss: 7.4002 - val_mse: 7.4002 - val_mae: 2.1684\n",
            "Epoch 55/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4621 - mse: 6.4621 - mae: 2.0382 - val_loss: 7.1958 - val_mse: 7.1958 - val_mae: 2.1389\n",
            "Epoch 56/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6542 - mse: 6.6542 - mae: 2.0510 - val_loss: 7.2463 - val_mse: 7.2463 - val_mae: 2.1476\n",
            "Epoch 57/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5497 - mse: 6.5497 - mae: 2.0273 - val_loss: 7.2762 - val_mse: 7.2762 - val_mae: 2.1519\n",
            "Epoch 58/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5396 - mse: 6.5396 - mae: 2.0335 - val_loss: 7.3593 - val_mse: 7.3593 - val_mae: 2.1656\n",
            "Epoch 59/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7249 - mse: 6.7249 - mae: 2.0644 - val_loss: 7.2407 - val_mse: 7.2407 - val_mae: 2.1500\n",
            "Epoch 60/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4789 - mse: 6.4789 - mae: 2.0254 - val_loss: 7.4282 - val_mse: 7.4282 - val_mae: 2.1769\n",
            "Epoch 61/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5701 - mse: 6.5701 - mae: 2.0421 - val_loss: 7.1728 - val_mse: 7.1728 - val_mae: 2.1417\n",
            "Epoch 62/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5150 - mse: 6.5150 - mae: 2.0369 - val_loss: 7.2579 - val_mse: 7.2579 - val_mae: 2.1555\n",
            "Epoch 63/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4954 - mse: 6.4954 - mae: 2.0247 - val_loss: 7.2061 - val_mse: 7.2061 - val_mae: 2.1489\n",
            "Epoch 64/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6256 - mse: 6.6256 - mae: 2.0511 - val_loss: 7.3408 - val_mse: 7.3408 - val_mae: 2.1653\n",
            "Epoch 65/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4768 - mse: 6.4768 - mae: 2.0169 - val_loss: 7.3030 - val_mse: 7.3030 - val_mae: 2.1606\n",
            "Epoch 66/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5105 - mse: 6.5105 - mae: 2.0302 - val_loss: 7.3253 - val_mse: 7.3253 - val_mae: 2.1673\n",
            "Epoch 67/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6018 - mse: 6.6018 - mae: 2.0538 - val_loss: 7.2723 - val_mse: 7.2723 - val_mae: 2.1541\n",
            "Epoch 68/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4828 - mse: 6.4828 - mae: 2.0218 - val_loss: 7.2749 - val_mse: 7.2749 - val_mae: 2.1560\n",
            "Epoch 69/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6402 - mse: 6.6402 - mae: 2.0412 - val_loss: 7.3797 - val_mse: 7.3797 - val_mae: 2.1770\n",
            "Epoch 70/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4783 - mse: 6.4783 - mae: 2.0263 - val_loss: 7.2862 - val_mse: 7.2862 - val_mae: 2.1555\n",
            "Epoch 71/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4580 - mse: 6.4580 - mae: 2.0154 - val_loss: 7.3213 - val_mse: 7.3213 - val_mae: 2.1659\n",
            "Epoch 72/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3699 - mse: 6.3699 - mae: 2.0022 - val_loss: 7.5142 - val_mse: 7.5142 - val_mae: 2.1972\n",
            "Epoch 73/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4441 - mse: 6.4441 - mae: 2.0281 - val_loss: 7.2221 - val_mse: 7.2221 - val_mae: 2.1536\n",
            "Epoch 74/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4635 - mse: 6.4635 - mae: 2.0159 - val_loss: 7.4013 - val_mse: 7.4013 - val_mae: 2.1783\n",
            "Epoch 75/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4580 - mse: 6.4580 - mae: 2.0134 - val_loss: 7.3936 - val_mse: 7.3936 - val_mae: 2.1798\n",
            "Epoch 76/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3813 - mse: 6.3813 - mae: 2.0005 - val_loss: 7.4033 - val_mse: 7.4033 - val_mae: 2.1793\n",
            "Epoch 77/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3902 - mse: 6.3902 - mae: 2.0116 - val_loss: 7.3078 - val_mse: 7.3078 - val_mae: 2.1648\n",
            "Epoch 78/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4286 - mse: 6.4286 - mae: 2.0113 - val_loss: 7.3257 - val_mse: 7.3257 - val_mae: 2.1704\n",
            "Epoch 79/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4404 - mse: 6.4404 - mae: 2.0228 - val_loss: 7.3001 - val_mse: 7.3001 - val_mae: 2.1622\n",
            "Epoch 80/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3736 - mse: 6.3736 - mae: 1.9999 - val_loss: 7.3524 - val_mse: 7.3524 - val_mae: 2.1731\n",
            "Epoch 81/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5306 - mse: 6.5306 - mae: 2.0145 - val_loss: 7.3073 - val_mse: 7.3073 - val_mae: 2.1642\n",
            "Epoch 82/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3271 - mse: 6.3271 - mae: 1.9981 - val_loss: 7.3853 - val_mse: 7.3853 - val_mae: 2.1731\n",
            "Epoch 83/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3109 - mse: 6.3109 - mae: 1.9921 - val_loss: 7.3369 - val_mse: 7.3369 - val_mae: 2.1667\n",
            "Epoch 84/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4459 - mse: 6.4459 - mae: 2.0164 - val_loss: 7.4633 - val_mse: 7.4633 - val_mae: 2.1880\n",
            "Epoch 85/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3966 - mse: 6.3966 - mae: 2.0102 - val_loss: 7.6468 - val_mse: 7.6468 - val_mae: 2.2169\n",
            "Epoch 86/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5917 - mse: 6.5917 - mae: 2.0340 - val_loss: 7.4381 - val_mse: 7.4381 - val_mae: 2.1886\n",
            "Epoch 87/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3410 - mse: 6.3410 - mae: 1.9931 - val_loss: 7.4473 - val_mse: 7.4473 - val_mae: 2.1930\n",
            "Epoch 88/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3375 - mse: 6.3375 - mae: 1.9919 - val_loss: 7.4608 - val_mse: 7.4608 - val_mae: 2.1967\n",
            "Epoch 89/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5040 - mse: 6.5040 - mae: 2.0221 - val_loss: 7.4589 - val_mse: 7.4589 - val_mae: 2.1905\n",
            "Epoch 90/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4832 - mse: 6.4832 - mae: 2.0180 - val_loss: 7.3683 - val_mse: 7.3683 - val_mae: 2.1751\n",
            "Epoch 91/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3887 - mse: 6.3887 - mae: 2.0068 - val_loss: 7.5708 - val_mse: 7.5708 - val_mae: 2.2038\n",
            "Epoch 92/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4989 - mse: 6.4989 - mae: 2.0104 - val_loss: 7.5638 - val_mse: 7.5638 - val_mae: 2.2114\n",
            "Epoch 93/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3713 - mse: 6.3713 - mae: 2.0023 - val_loss: 7.5086 - val_mse: 7.5086 - val_mae: 2.2001\n",
            "Epoch 94/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.4535 - mse: 6.4535 - mae: 2.0174 - val_loss: 7.5137 - val_mse: 7.5137 - val_mae: 2.2042\n",
            "Epoch 95/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2517 - mse: 6.2517 - mae: 1.9812 - val_loss: 7.5029 - val_mse: 7.5029 - val_mae: 2.2008\n",
            "Epoch 96/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2858 - mse: 6.2858 - mae: 1.9822 - val_loss: 7.4392 - val_mse: 7.4392 - val_mae: 2.1903\n",
            "Epoch 97/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2431 - mse: 6.2431 - mae: 1.9821 - val_loss: 7.3171 - val_mse: 7.3171 - val_mae: 2.1705\n",
            "Epoch 98/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2520 - mse: 6.2520 - mae: 1.9867 - val_loss: 7.4731 - val_mse: 7.4731 - val_mae: 2.1913\n",
            "Epoch 99/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2485 - mse: 6.2485 - mae: 1.9848 - val_loss: 7.8257 - val_mse: 7.8257 - val_mae: 2.2406\n",
            "Epoch 100/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3232 - mse: 6.3232 - mae: 1.9900 - val_loss: 7.2755 - val_mse: 7.2755 - val_mae: 2.1590\n",
            "Epoch 101/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1498 - mse: 6.1498 - mae: 1.9555 - val_loss: 7.3016 - val_mse: 7.3016 - val_mae: 2.1702\n",
            "Epoch 102/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2236 - mse: 6.2236 - mae: 1.9752 - val_loss: 7.3260 - val_mse: 7.3260 - val_mae: 2.1776\n",
            "Epoch 103/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3751 - mse: 6.3751 - mae: 2.0040 - val_loss: 7.5347 - val_mse: 7.5347 - val_mae: 2.2024\n",
            "Epoch 104/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1471 - mse: 6.1471 - mae: 1.9731 - val_loss: 7.4737 - val_mse: 7.4737 - val_mae: 2.1968\n",
            "Epoch 105/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1548 - mse: 6.1548 - mae: 1.9719 - val_loss: 7.5672 - val_mse: 7.5672 - val_mae: 2.1999\n",
            "Epoch 106/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2077 - mse: 6.2077 - mae: 1.9724 - val_loss: 7.5324 - val_mse: 7.5324 - val_mae: 2.2026\n",
            "Epoch 107/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2611 - mse: 6.2611 - mae: 1.9807 - val_loss: 7.4623 - val_mse: 7.4623 - val_mae: 2.1963\n",
            "Epoch 108/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2470 - mse: 6.2470 - mae: 1.9871 - val_loss: 7.5669 - val_mse: 7.5669 - val_mae: 2.2137\n",
            "Epoch 109/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1515 - mse: 6.1515 - mae: 1.9711 - val_loss: 7.5879 - val_mse: 7.5879 - val_mae: 2.1987\n",
            "Epoch 110/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3632 - mse: 6.3632 - mae: 1.9951 - val_loss: 7.4607 - val_mse: 7.4607 - val_mae: 2.1892\n",
            "Epoch 111/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2960 - mse: 6.2960 - mae: 1.9876 - val_loss: 7.6283 - val_mse: 7.6283 - val_mae: 2.2194\n",
            "Epoch 112/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0549 - mse: 6.0549 - mae: 1.9525 - val_loss: 7.5187 - val_mse: 7.5187 - val_mae: 2.2025\n",
            "Epoch 113/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3468 - mse: 6.3468 - mae: 2.0009 - val_loss: 7.5455 - val_mse: 7.5455 - val_mae: 2.2017\n",
            "Epoch 114/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2485 - mse: 6.2485 - mae: 1.9854 - val_loss: 7.6452 - val_mse: 7.6452 - val_mae: 2.2211\n",
            "Epoch 115/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.3179 - mse: 6.3179 - mae: 1.9910 - val_loss: 7.4664 - val_mse: 7.4664 - val_mae: 2.1891\n",
            "Epoch 116/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1016 - mse: 6.1016 - mae: 1.9487 - val_loss: 7.4909 - val_mse: 7.4909 - val_mae: 2.1846\n",
            "Epoch 117/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1082 - mse: 6.1082 - mae: 1.9510 - val_loss: 7.4460 - val_mse: 7.4460 - val_mae: 2.1762\n",
            "Epoch 118/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1479 - mse: 6.1479 - mae: 1.9687 - val_loss: 7.5704 - val_mse: 7.5704 - val_mae: 2.2207\n",
            "Epoch 119/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1723 - mse: 6.1723 - mae: 1.9702 - val_loss: 7.6499 - val_mse: 7.6499 - val_mae: 2.2177\n",
            "Epoch 120/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1001 - mse: 6.1001 - mae: 1.9607 - val_loss: 7.5287 - val_mse: 7.5287 - val_mae: 2.1983\n",
            "Epoch 121/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2061 - mse: 6.2061 - mae: 1.9710 - val_loss: 7.6048 - val_mse: 7.6048 - val_mae: 2.2284\n",
            "Epoch 122/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1275 - mse: 6.1275 - mae: 1.9600 - val_loss: 7.5753 - val_mse: 7.5753 - val_mae: 2.2060\n",
            "Epoch 123/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2318 - mse: 6.2318 - mae: 1.9732 - val_loss: 7.5842 - val_mse: 7.5842 - val_mae: 2.2149\n",
            "Epoch 124/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1760 - mse: 6.1760 - mae: 1.9581 - val_loss: 7.4975 - val_mse: 7.4975 - val_mae: 2.1985\n",
            "Epoch 125/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.2267 - mse: 6.2267 - mae: 1.9723 - val_loss: 7.5738 - val_mse: 7.5738 - val_mae: 2.2068\n",
            "Epoch 126/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0650 - mse: 6.0650 - mae: 1.9477 - val_loss: 7.5126 - val_mse: 7.5126 - val_mae: 2.1947\n",
            "Epoch 127/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0151 - mse: 6.0151 - mae: 1.9458 - val_loss: 7.7261 - val_mse: 7.7261 - val_mae: 2.2286\n",
            "Epoch 128/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0994 - mse: 6.0994 - mae: 1.9455 - val_loss: 7.7912 - val_mse: 7.7912 - val_mae: 2.2456\n",
            "Epoch 129/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1152 - mse: 6.1152 - mae: 1.9443 - val_loss: 7.8551 - val_mse: 7.8551 - val_mae: 2.2513\n",
            "Epoch 130/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1694 - mse: 6.1694 - mae: 1.9562 - val_loss: 7.7238 - val_mse: 7.7238 - val_mae: 2.2186\n",
            "Epoch 131/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9854 - mse: 5.9854 - mae: 1.9301 - val_loss: 7.4556 - val_mse: 7.4556 - val_mae: 2.1947\n",
            "Epoch 132/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0803 - mse: 6.0803 - mae: 1.9512 - val_loss: 7.6372 - val_mse: 7.6372 - val_mae: 2.2184\n",
            "Epoch 133/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9646 - mse: 5.9646 - mae: 1.9237 - val_loss: 7.6619 - val_mse: 7.6619 - val_mae: 2.2171\n",
            "Epoch 134/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9951 - mse: 5.9951 - mae: 1.9344 - val_loss: 7.7654 - val_mse: 7.7654 - val_mae: 2.2276\n",
            "Epoch 135/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1025 - mse: 6.1025 - mae: 1.9539 - val_loss: 7.9341 - val_mse: 7.9341 - val_mae: 2.2606\n",
            "Epoch 136/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1089 - mse: 6.1089 - mae: 1.9538 - val_loss: 7.6667 - val_mse: 7.6667 - val_mae: 2.2174\n",
            "Epoch 137/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0059 - mse: 6.0059 - mae: 1.9319 - val_loss: 7.8732 - val_mse: 7.8732 - val_mae: 2.2493\n",
            "Epoch 138/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9021 - mse: 5.9021 - mae: 1.9225 - val_loss: 7.5997 - val_mse: 7.5997 - val_mae: 2.2126\n",
            "Epoch 139/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0583 - mse: 6.0583 - mae: 1.9548 - val_loss: 7.6284 - val_mse: 7.6284 - val_mae: 2.2259\n",
            "Epoch 140/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9286 - mse: 5.9286 - mae: 1.9304 - val_loss: 7.7513 - val_mse: 7.7513 - val_mae: 2.2342\n",
            "Epoch 141/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9286 - mse: 5.9286 - mae: 1.9112 - val_loss: 7.9758 - val_mse: 7.9758 - val_mae: 2.2653\n",
            "Epoch 142/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9191 - mse: 5.9191 - mae: 1.9173 - val_loss: 7.9326 - val_mse: 7.9326 - val_mae: 2.2653\n",
            "Epoch 143/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1055 - mse: 6.1055 - mae: 1.9424 - val_loss: 7.5513 - val_mse: 7.5513 - val_mae: 2.2041\n",
            "Epoch 144/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.1343 - mse: 6.1343 - mae: 1.9471 - val_loss: 7.6665 - val_mse: 7.6665 - val_mae: 2.2230\n",
            "Epoch 145/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9330 - mse: 5.9330 - mae: 1.9145 - val_loss: 7.7586 - val_mse: 7.7586 - val_mae: 2.2328\n",
            "Epoch 146/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0651 - mse: 6.0651 - mae: 1.9490 - val_loss: 7.6525 - val_mse: 7.6525 - val_mae: 2.2185\n",
            "Epoch 147/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9593 - mse: 5.9593 - mae: 1.9356 - val_loss: 7.8113 - val_mse: 7.8113 - val_mae: 2.2431\n",
            "Epoch 148/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9806 - mse: 5.9806 - mae: 1.9272 - val_loss: 7.6678 - val_mse: 7.6678 - val_mae: 2.2298\n",
            "Epoch 149/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8436 - mse: 5.8436 - mae: 1.9174 - val_loss: 7.7216 - val_mse: 7.7216 - val_mae: 2.2192\n",
            "Epoch 150/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.0395 - mse: 6.0395 - mae: 1.9411 - val_loss: 7.8573 - val_mse: 7.8573 - val_mae: 2.2370\n",
            "Epoch 151/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9424 - mse: 5.9424 - mae: 1.9291 - val_loss: 7.7513 - val_mse: 7.7513 - val_mae: 2.2409\n",
            "Epoch 152/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8443 - mse: 5.8443 - mae: 1.9039 - val_loss: 7.7849 - val_mse: 7.7849 - val_mae: 2.2402\n",
            "Epoch 153/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8849 - mse: 5.8849 - mae: 1.9096 - val_loss: 7.6527 - val_mse: 7.6527 - val_mae: 2.2200\n",
            "Epoch 154/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9846 - mse: 5.9846 - mae: 1.9231 - val_loss: 7.4909 - val_mse: 7.4909 - val_mae: 2.1917\n",
            "Epoch 155/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8950 - mse: 5.8950 - mae: 1.9184 - val_loss: 7.7011 - val_mse: 7.7011 - val_mae: 2.2345\n",
            "Epoch 156/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9185 - mse: 5.9185 - mae: 1.9124 - val_loss: 7.7652 - val_mse: 7.7652 - val_mae: 2.2457\n",
            "Epoch 157/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7773 - mse: 5.7773 - mae: 1.8929 - val_loss: 8.0649 - val_mse: 8.0649 - val_mae: 2.2746\n",
            "Epoch 158/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9886 - mse: 5.9886 - mae: 1.9242 - val_loss: 7.6272 - val_mse: 7.6272 - val_mae: 2.2275\n",
            "Epoch 159/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9161 - mse: 5.9161 - mae: 1.9164 - val_loss: 7.9462 - val_mse: 7.9462 - val_mae: 2.2464\n",
            "Epoch 160/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6847 - mse: 5.6847 - mae: 1.8789 - val_loss: 7.9850 - val_mse: 7.9850 - val_mae: 2.2682\n",
            "Epoch 161/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8729 - mse: 5.8729 - mae: 1.8970 - val_loss: 7.8081 - val_mse: 7.8081 - val_mae: 2.2480\n",
            "Epoch 162/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6309 - mse: 5.6309 - mae: 1.8672 - val_loss: 8.0452 - val_mse: 8.0452 - val_mae: 2.2786\n",
            "Epoch 163/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7759 - mse: 5.7759 - mae: 1.9004 - val_loss: 7.7723 - val_mse: 7.7723 - val_mae: 2.2229\n",
            "Epoch 164/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9280 - mse: 5.9280 - mae: 1.9150 - val_loss: 7.8825 - val_mse: 7.8825 - val_mae: 2.2504\n",
            "Epoch 165/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8356 - mse: 5.8356 - mae: 1.8939 - val_loss: 7.8215 - val_mse: 7.8215 - val_mae: 2.2534\n",
            "Epoch 166/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9915 - mse: 5.9915 - mae: 1.9267 - val_loss: 7.8390 - val_mse: 7.8390 - val_mae: 2.2512\n",
            "Epoch 167/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7092 - mse: 5.7092 - mae: 1.8680 - val_loss: 8.0980 - val_mse: 8.0980 - val_mae: 2.2694\n",
            "Epoch 168/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7617 - mse: 5.7617 - mae: 1.8843 - val_loss: 7.7760 - val_mse: 7.7760 - val_mae: 2.2375\n",
            "Epoch 169/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6941 - mse: 5.6941 - mae: 1.8936 - val_loss: 7.7706 - val_mse: 7.7706 - val_mae: 2.2220\n",
            "Epoch 170/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8393 - mse: 5.8393 - mae: 1.9044 - val_loss: 7.8928 - val_mse: 7.8928 - val_mae: 2.2464\n",
            "Epoch 171/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7105 - mse: 5.7105 - mae: 1.8811 - val_loss: 7.8485 - val_mse: 7.8485 - val_mae: 2.2383\n",
            "Epoch 172/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7791 - mse: 5.7791 - mae: 1.8942 - val_loss: 7.8443 - val_mse: 7.8443 - val_mae: 2.2566\n",
            "Epoch 173/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7751 - mse: 5.7751 - mae: 1.8915 - val_loss: 8.1381 - val_mse: 8.1381 - val_mae: 2.2740\n",
            "Epoch 174/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7889 - mse: 5.7889 - mae: 1.8939 - val_loss: 8.1218 - val_mse: 8.1218 - val_mae: 2.2714\n",
            "Epoch 175/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5766 - mse: 5.5766 - mae: 1.8633 - val_loss: 7.9561 - val_mse: 7.9561 - val_mae: 2.2580\n",
            "Epoch 176/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8074 - mse: 5.8074 - mae: 1.9019 - val_loss: 7.8683 - val_mse: 7.8683 - val_mae: 2.2419\n",
            "Epoch 177/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.9283 - mse: 5.9283 - mae: 1.9092 - val_loss: 7.8793 - val_mse: 7.8793 - val_mae: 2.2514\n",
            "Epoch 178/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7857 - mse: 5.7857 - mae: 1.8960 - val_loss: 8.0136 - val_mse: 8.0136 - val_mae: 2.2493\n",
            "Epoch 179/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8294 - mse: 5.8294 - mae: 1.8960 - val_loss: 7.9929 - val_mse: 7.9929 - val_mae: 2.2685\n",
            "Epoch 180/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6312 - mse: 5.6312 - mae: 1.8672 - val_loss: 7.9887 - val_mse: 7.9887 - val_mae: 2.2645\n",
            "Epoch 181/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6133 - mse: 5.6133 - mae: 1.8642 - val_loss: 7.8111 - val_mse: 7.8111 - val_mae: 2.2478\n",
            "Epoch 182/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6286 - mse: 5.6286 - mae: 1.8642 - val_loss: 7.9837 - val_mse: 7.9837 - val_mae: 2.2586\n",
            "Epoch 183/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7508 - mse: 5.7508 - mae: 1.8893 - val_loss: 8.1595 - val_mse: 8.1595 - val_mae: 2.2966\n",
            "Epoch 184/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.4977 - mse: 5.4977 - mae: 1.8313 - val_loss: 8.1493 - val_mse: 8.1493 - val_mae: 2.2798\n",
            "Epoch 185/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.4538 - mse: 5.4538 - mae: 1.8321 - val_loss: 7.9750 - val_mse: 7.9750 - val_mae: 2.2752\n",
            "Epoch 186/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.8545 - mse: 5.8545 - mae: 1.9048 - val_loss: 8.3238 - val_mse: 8.3238 - val_mae: 2.3122\n",
            "Epoch 187/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6380 - mse: 5.6380 - mae: 1.8693 - val_loss: 7.8107 - val_mse: 7.8107 - val_mae: 2.2333\n",
            "Epoch 188/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5102 - mse: 5.5102 - mae: 1.8491 - val_loss: 8.0801 - val_mse: 8.0801 - val_mae: 2.2859\n",
            "Epoch 189/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5858 - mse: 5.5858 - mae: 1.8483 - val_loss: 8.1299 - val_mse: 8.1299 - val_mae: 2.2798\n",
            "Epoch 190/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5354 - mse: 5.5354 - mae: 1.8517 - val_loss: 7.7398 - val_mse: 7.7398 - val_mae: 2.2384\n",
            "Epoch 191/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6203 - mse: 5.6203 - mae: 1.8649 - val_loss: 8.1633 - val_mse: 8.1633 - val_mae: 2.2739\n",
            "Epoch 192/200\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 5.7062 - mse: 5.7062 - mae: 1.8687 - val_loss: 7.8918 - val_mse: 7.8918 - val_mae: 2.2408\n",
            "Epoch 193/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5870 - mse: 5.5870 - mae: 1.8526 - val_loss: 8.0162 - val_mse: 8.0162 - val_mae: 2.2579\n",
            "Epoch 194/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5660 - mse: 5.5660 - mae: 1.8524 - val_loss: 7.8763 - val_mse: 7.8763 - val_mae: 2.2531\n",
            "Epoch 195/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5120 - mse: 5.5120 - mae: 1.8375 - val_loss: 7.9378 - val_mse: 7.9378 - val_mae: 2.2615\n",
            "Epoch 196/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6358 - mse: 5.6358 - mae: 1.8618 - val_loss: 8.0950 - val_mse: 8.0950 - val_mae: 2.2833\n",
            "Epoch 197/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.7471 - mse: 5.7471 - mae: 1.8811 - val_loss: 7.9077 - val_mse: 7.9077 - val_mae: 2.2517\n",
            "Epoch 198/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.5923 - mse: 5.5923 - mae: 1.8601 - val_loss: 7.9892 - val_mse: 7.9892 - val_mae: 2.2573\n",
            "Epoch 199/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6302 - mse: 5.6302 - mae: 1.8604 - val_loss: 7.8976 - val_mse: 7.8976 - val_mae: 2.2682\n",
            "Epoch 200/200\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 5.6035 - mse: 5.6035 - mae: 1.8481 - val_loss: 7.8958 - val_mse: 7.8958 - val_mae: 2.2493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpOqO64zG6Hv",
        "outputId": "fba4ece1-a8f0-4f8f-baa9-5a08c4ac45fb"
      },
      "source": [
        "len(x_train), len(x_valid), len(x_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8999, 900, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0BWR-dNERAt",
        "outputId": "a8c2d815-0938-4775-e653-eea5fbde3cff"
      },
      "source": [
        "predictions = model2.predict(x_test)\n",
        "for i in range(len(predictions)):\n",
        "  print(predictions[i], y_test[i])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.94746053] -1.66501564864875\n",
            "[-1.5829128] 0.152149539474605\n",
            "[-0.7083777] -2.3468032768778397\n",
            "[0.92888194] -0.44815126070383104\n",
            "[1.2252012] 0.527815734338596\n",
            "[0.31152284] 0.45019460355392893\n",
            "[-1.4622265] 5.34533310713699\n",
            "[0.6752724] 2.28027602468346\n",
            "[-0.43152457] -1.10979221417234\n",
            "[-0.43575495] 0.839196373543002\n",
            "[-1.8102943] 0.7754432253207021\n",
            "[-0.3613714] 0.96893395982464\n",
            "[-0.31968987] -1.5957609299991997\n",
            "[0.16497664] 0.05703370239846799\n",
            "[-0.4794612] 2.9230320286980294\n",
            "[-0.11690433] 0.5050041726616521\n",
            "[1.8069967] 0.5998712979988821\n",
            "[-0.90438116] -3.82951811516721\n",
            "[-0.00969006] 0.35008312221027194\n",
            "[-0.68937415] 0.8373062571357509\n",
            "[-0.56386286] 0.9320190625940409\n",
            "[-0.67647463] 1.98442400660755\n",
            "[0.05676834] 1.17374569045698\n",
            "[0.31357533] -2.2950824144771698\n",
            "[-0.6641426] 4.62989343822145\n",
            "[0.3875069] -5.58812734193312\n",
            "[0.42372802] -0.926334443534416\n",
            "[-0.8169563] -6.37562164284168\n",
            "[0.13747285] 0.7543541101286521\n",
            "[-2.324392] -0.10132486274447501\n",
            "[-0.77135634] 1.5945590988443799\n",
            "[-0.10642596] -0.019918070830946998\n",
            "[-2.1262465] 1.94827005745442\n",
            "[4.1091943] -0.9233797143077029\n",
            "[0.48325968] -1.88543048301274\n",
            "[-0.5429364] -2.24647792657973\n",
            "[0.723055] 1.8950110083573402\n",
            "[-0.5103469] -4.185128904830569\n",
            "[1.4180524] -2.66126277429726\n",
            "[-1.220546] 1.86901062421101\n",
            "[-1.9596714] 2.9243032727618505\n",
            "[0.9721885] -0.23235793440575397\n",
            "[-0.43334627] -3.1702897382766895\n",
            "[-2.5669103] 4.38797460378044\n",
            "[0.8712561] -1.9437267767657598\n",
            "[0.5325478] -0.8528389597395329\n",
            "[-0.16642644] 3.4244954692596696\n",
            "[-0.32216656] -3.7232907966401703\n",
            "[-1.3822457] -4.972136735534691\n",
            "[-1.1631001] 3.3183253578327103\n",
            "[0.62670577] -2.99171644804827\n",
            "[0.7835377] 1.96669488387891\n",
            "[-1.0783852] 4.32376977149531\n",
            "[0.9924789] -0.383690740906328\n",
            "[-0.52472156] -1.31839504256544\n",
            "[0.099445] 5.31248921609687\n",
            "[-0.2109002] 0.255191217522601\n",
            "[0.00884853] -1.07746279585952\n",
            "[-1.2762221] -2.84287135369071\n",
            "[0.99982345] -0.36844941501023404\n",
            "[-2.0370197] -0.70722618936756\n",
            "[0.74164] -0.7512313795649871\n",
            "[0.5929688] 0.012677390964326\n",
            "[0.49931717] -0.6127859322221341\n",
            "[0.27797025] -3.8195582965906296\n",
            "[3.4731538] -1.2729702746873999\n",
            "[-0.27274597] 1.09863923686552\n",
            "[0.73955256] 0.522686545573637\n",
            "[0.13133413] 3.38961367012252\n",
            "[-1.0089018] 1.3484799981245\n",
            "[-1.4740976] 2.2822672825803303\n",
            "[-0.6299812] 1.3220281234783602\n",
            "[-0.939046] -4.742594040400889\n",
            "[-1.612866] -3.89716781774795\n",
            "[0.19401954] 1.14851325775881\n",
            "[2.1033962] 1.31584010933561\n",
            "[-1.7435759] -5.06972841631549\n",
            "[0.09972464] -3.9653085900422798\n",
            "[-0.68827635] -2.4026331251355\n",
            "[0.91463387] -0.06787716954116099\n",
            "[-0.7140097] 1.19351571480564\n",
            "[1.8497487] 2.77316989765984\n",
            "[-1.6384455] 1.3795448086983002\n",
            "[-0.22185732] -3.2261366662893702\n",
            "[0.34271538] 5.3516435213054505\n",
            "[-1.2350897] 0.14483802250462602\n",
            "[-0.16420569] 0.8479458585834\n",
            "[-0.5596026] 0.7810052805364621\n",
            "[0.5195541] -5.456900107553719\n",
            "[-1.4673709] -1.4044451744784499\n",
            "[-0.32801497] -5.09827243026014\n",
            "[1.7464621] -0.193131996564787\n",
            "[1.6006542] -5.22643788392744\n",
            "[-1.1062833] -0.195932404753185\n",
            "[0.41856062] -1.8744481086800502\n",
            "[0.5140475] -2.0539537687582703\n",
            "[0.6474792] 0.11772139480151299\n",
            "[-0.22877337] -4.18091189028849\n",
            "[0.21547697] 0.24258016484804001\n",
            "[-0.09999515] 2.65809702311491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjK6n529rRhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9380958-4243-42ea-896b-16d793d6ddc7"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Dense(128, activation=\"relu\", input_dim=4))\n",
        "model3.add(Dense(32, activation=\"relu\"))\n",
        "model3.add(Dense(8, activation=\"relu\"))\n",
        "# Since the regression is performed, a Dense layer containing a single neuron with a linear activation function.\n",
        "# Typically ReLu-based activation are used but since it is performed regression, it is needed a linear activation.\n",
        "model3.add(Dense(1, activation=\"linear\"))\n",
        "\n",
        "# Compile model: The model is initialized with the Adam optimizer and then it is compiled.\n",
        "model3.compile(loss='mse', metrics=['mse', 'mae'], optimizer=Adam(lr=1e-3, decay=1e-3 / 200))\n",
        "\n",
        "# Patient early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "\n",
        "# Fit the model\n",
        "history = model3.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=10000000, batch_size=100, verbose=2, callbacks=[es])\n",
        "\n",
        "# Calculate predictions\n",
        "# PredTestSet = model3.predict(X1)\n",
        "# PredValSet = model3.predict(X2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000000\n",
            "60/60 - 1s - loss: 6.8557 - mse: 6.8557 - mae: 2.0884 - val_loss: 6.7047 - val_mse: 6.7047 - val_mae: 2.0585\n",
            "Epoch 2/10000000\n",
            "60/60 - 0s - loss: 6.8365 - mse: 6.8365 - mae: 2.0854 - val_loss: 6.7048 - val_mse: 6.7048 - val_mae: 2.0586\n",
            "Epoch 3/10000000\n",
            "60/60 - 0s - loss: 6.8302 - mse: 6.8302 - mae: 2.0846 - val_loss: 6.7045 - val_mse: 6.7045 - val_mae: 2.0586\n",
            "Epoch 4/10000000\n",
            "60/60 - 0s - loss: 6.8247 - mse: 6.8247 - mae: 2.0839 - val_loss: 6.7051 - val_mse: 6.7051 - val_mae: 2.0587\n",
            "Epoch 5/10000000\n",
            "60/60 - 0s - loss: 6.8209 - mse: 6.8209 - mae: 2.0830 - val_loss: 6.7047 - val_mse: 6.7047 - val_mae: 2.0588\n",
            "Epoch 6/10000000\n",
            "60/60 - 0s - loss: 6.8185 - mse: 6.8185 - mae: 2.0826 - val_loss: 6.7054 - val_mse: 6.7054 - val_mae: 2.0593\n",
            "Epoch 7/10000000\n",
            "60/60 - 0s - loss: 6.8122 - mse: 6.8122 - mae: 2.0819 - val_loss: 6.7081 - val_mse: 6.7081 - val_mae: 2.0590\n",
            "Epoch 8/10000000\n",
            "60/60 - 0s - loss: 6.8063 - mse: 6.8063 - mae: 2.0812 - val_loss: 6.7082 - val_mse: 6.7082 - val_mae: 2.0596\n",
            "Epoch 9/10000000\n",
            "60/60 - 0s - loss: 6.8060 - mse: 6.8060 - mae: 2.0804 - val_loss: 6.7045 - val_mse: 6.7045 - val_mae: 2.0592\n",
            "Epoch 10/10000000\n",
            "60/60 - 0s - loss: 6.8046 - mse: 6.8046 - mae: 2.0798 - val_loss: 6.7036 - val_mse: 6.7036 - val_mae: 2.0589\n",
            "Epoch 11/10000000\n",
            "60/60 - 0s - loss: 6.7928 - mse: 6.7928 - mae: 2.0780 - val_loss: 6.7088 - val_mse: 6.7088 - val_mae: 2.0602\n",
            "Epoch 12/10000000\n",
            "60/60 - 0s - loss: 6.7968 - mse: 6.7968 - mae: 2.0786 - val_loss: 6.7082 - val_mse: 6.7082 - val_mae: 2.0607\n",
            "Epoch 13/10000000\n",
            "60/60 - 0s - loss: 6.7941 - mse: 6.7941 - mae: 2.0777 - val_loss: 6.7120 - val_mse: 6.7120 - val_mae: 2.0615\n",
            "Epoch 14/10000000\n",
            "60/60 - 0s - loss: 6.7832 - mse: 6.7832 - mae: 2.0768 - val_loss: 6.7084 - val_mse: 6.7084 - val_mae: 2.0609\n",
            "Epoch 15/10000000\n",
            "60/60 - 0s - loss: 6.7815 - mse: 6.7815 - mae: 2.0760 - val_loss: 6.7128 - val_mse: 6.7128 - val_mae: 2.0616\n",
            "Epoch 16/10000000\n",
            "60/60 - 0s - loss: 6.7783 - mse: 6.7783 - mae: 2.0756 - val_loss: 6.7116 - val_mse: 6.7116 - val_mae: 2.0610\n",
            "Epoch 17/10000000\n",
            "60/60 - 0s - loss: 6.7763 - mse: 6.7763 - mae: 2.0752 - val_loss: 6.7094 - val_mse: 6.7094 - val_mae: 2.0610\n",
            "Epoch 18/10000000\n",
            "60/60 - 0s - loss: 6.7724 - mse: 6.7724 - mae: 2.0744 - val_loss: 6.7130 - val_mse: 6.7130 - val_mae: 2.0610\n",
            "Epoch 19/10000000\n",
            "60/60 - 0s - loss: 6.7656 - mse: 6.7656 - mae: 2.0738 - val_loss: 6.7279 - val_mse: 6.7279 - val_mae: 2.0637\n",
            "Epoch 20/10000000\n",
            "60/60 - 0s - loss: 6.7743 - mse: 6.7743 - mae: 2.0751 - val_loss: 6.7203 - val_mse: 6.7203 - val_mae: 2.0625\n",
            "Epoch 21/10000000\n",
            "60/60 - 0s - loss: 6.7643 - mse: 6.7643 - mae: 2.0729 - val_loss: 6.7264 - val_mse: 6.7264 - val_mae: 2.0639\n",
            "Epoch 22/10000000\n",
            "60/60 - 0s - loss: 6.7562 - mse: 6.7562 - mae: 2.0727 - val_loss: 6.7185 - val_mse: 6.7185 - val_mae: 2.0625\n",
            "Epoch 23/10000000\n",
            "60/60 - 0s - loss: 6.7555 - mse: 6.7555 - mae: 2.0720 - val_loss: 6.7229 - val_mse: 6.7229 - val_mae: 2.0635\n",
            "Epoch 24/10000000\n",
            "60/60 - 0s - loss: 6.7561 - mse: 6.7561 - mae: 2.0729 - val_loss: 6.7225 - val_mse: 6.7225 - val_mae: 2.0634\n",
            "Epoch 25/10000000\n",
            "60/60 - 0s - loss: 6.7521 - mse: 6.7521 - mae: 2.0716 - val_loss: 6.7415 - val_mse: 6.7415 - val_mae: 2.0668\n",
            "Epoch 26/10000000\n",
            "60/60 - 0s - loss: 6.7454 - mse: 6.7454 - mae: 2.0707 - val_loss: 6.7412 - val_mse: 6.7412 - val_mae: 2.0669\n",
            "Epoch 27/10000000\n",
            "60/60 - 0s - loss: 6.7415 - mse: 6.7415 - mae: 2.0703 - val_loss: 6.7380 - val_mse: 6.7380 - val_mae: 2.0651\n",
            "Epoch 28/10000000\n",
            "60/60 - 0s - loss: 6.7387 - mse: 6.7387 - mae: 2.0688 - val_loss: 6.7298 - val_mse: 6.7298 - val_mae: 2.0639\n",
            "Epoch 29/10000000\n",
            "60/60 - 0s - loss: 6.7329 - mse: 6.7329 - mae: 2.0691 - val_loss: 6.7443 - val_mse: 6.7443 - val_mae: 2.0675\n",
            "Epoch 30/10000000\n",
            "60/60 - 0s - loss: 6.7326 - mse: 6.7326 - mae: 2.0682 - val_loss: 6.7427 - val_mse: 6.7427 - val_mae: 2.0681\n",
            "Epoch 31/10000000\n",
            "60/60 - 0s - loss: 6.7282 - mse: 6.7282 - mae: 2.0680 - val_loss: 6.7346 - val_mse: 6.7346 - val_mae: 2.0651\n",
            "Epoch 32/10000000\n",
            "60/60 - 0s - loss: 6.7203 - mse: 6.7203 - mae: 2.0665 - val_loss: 6.7314 - val_mse: 6.7314 - val_mae: 2.0660\n",
            "Epoch 33/10000000\n",
            "60/60 - 0s - loss: 6.7216 - mse: 6.7216 - mae: 2.0665 - val_loss: 6.7551 - val_mse: 6.7551 - val_mae: 2.0693\n",
            "Epoch 34/10000000\n",
            "60/60 - 0s - loss: 6.7160 - mse: 6.7160 - mae: 2.0657 - val_loss: 6.7347 - val_mse: 6.7347 - val_mae: 2.0651\n",
            "Epoch 35/10000000\n",
            "60/60 - 0s - loss: 6.7146 - mse: 6.7146 - mae: 2.0648 - val_loss: 6.7503 - val_mse: 6.7503 - val_mae: 2.0690\n",
            "Epoch 36/10000000\n",
            "60/60 - 0s - loss: 6.7057 - mse: 6.7057 - mae: 2.0646 - val_loss: 6.7684 - val_mse: 6.7684 - val_mae: 2.0717\n",
            "Epoch 37/10000000\n",
            "60/60 - 0s - loss: 6.7022 - mse: 6.7022 - mae: 2.0642 - val_loss: 6.7507 - val_mse: 6.7507 - val_mae: 2.0676\n",
            "Epoch 38/10000000\n",
            "60/60 - 0s - loss: 6.6972 - mse: 6.6972 - mae: 2.0624 - val_loss: 6.7626 - val_mse: 6.7626 - val_mae: 2.0704\n",
            "Epoch 39/10000000\n",
            "60/60 - 0s - loss: 6.6919 - mse: 6.6919 - mae: 2.0609 - val_loss: 6.7712 - val_mse: 6.7712 - val_mae: 2.0718\n",
            "Epoch 40/10000000\n",
            "60/60 - 0s - loss: 6.6926 - mse: 6.6926 - mae: 2.0620 - val_loss: 6.7908 - val_mse: 6.7908 - val_mae: 2.0747\n",
            "Epoch 41/10000000\n",
            "60/60 - 0s - loss: 6.6899 - mse: 6.6899 - mae: 2.0606 - val_loss: 6.7788 - val_mse: 6.7788 - val_mae: 2.0736\n",
            "Epoch 42/10000000\n",
            "60/60 - 0s - loss: 6.6882 - mse: 6.6882 - mae: 2.0622 - val_loss: 6.7676 - val_mse: 6.7676 - val_mae: 2.0714\n",
            "Epoch 43/10000000\n",
            "60/60 - 0s - loss: 6.6881 - mse: 6.6881 - mae: 2.0624 - val_loss: 6.7921 - val_mse: 6.7921 - val_mae: 2.0760\n",
            "Epoch 44/10000000\n",
            "60/60 - 0s - loss: 6.6842 - mse: 6.6842 - mae: 2.0614 - val_loss: 6.7947 - val_mse: 6.7947 - val_mae: 2.0757\n",
            "Epoch 45/10000000\n",
            "60/60 - 0s - loss: 6.6720 - mse: 6.6720 - mae: 2.0590 - val_loss: 6.7897 - val_mse: 6.7897 - val_mae: 2.0753\n",
            "Epoch 46/10000000\n",
            "60/60 - 0s - loss: 6.6723 - mse: 6.6723 - mae: 2.0589 - val_loss: 6.7789 - val_mse: 6.7789 - val_mae: 2.0736\n",
            "Epoch 47/10000000\n",
            "60/60 - 0s - loss: 6.6635 - mse: 6.6635 - mae: 2.0578 - val_loss: 6.7913 - val_mse: 6.7913 - val_mae: 2.0737\n",
            "Epoch 48/10000000\n",
            "60/60 - 0s - loss: 6.6642 - mse: 6.6642 - mae: 2.0577 - val_loss: 6.7854 - val_mse: 6.7854 - val_mae: 2.0734\n",
            "Epoch 49/10000000\n",
            "60/60 - 0s - loss: 6.6572 - mse: 6.6572 - mae: 2.0558 - val_loss: 6.8045 - val_mse: 6.8045 - val_mae: 2.0786\n",
            "Epoch 50/10000000\n",
            "60/60 - 0s - loss: 6.6506 - mse: 6.6506 - mae: 2.0561 - val_loss: 6.7803 - val_mse: 6.7803 - val_mae: 2.0721\n",
            "Epoch 51/10000000\n",
            "60/60 - 0s - loss: 6.6526 - mse: 6.6526 - mae: 2.0557 - val_loss: 6.8090 - val_mse: 6.8090 - val_mae: 2.0786\n",
            "Epoch 52/10000000\n",
            "60/60 - 0s - loss: 6.6604 - mse: 6.6604 - mae: 2.0567 - val_loss: 6.8058 - val_mse: 6.8058 - val_mae: 2.0767\n",
            "Epoch 53/10000000\n",
            "60/60 - 0s - loss: 6.6500 - mse: 6.6500 - mae: 2.0543 - val_loss: 6.8145 - val_mse: 6.8145 - val_mae: 2.0780\n",
            "Epoch 54/10000000\n",
            "60/60 - 0s - loss: 6.6404 - mse: 6.6404 - mae: 2.0537 - val_loss: 6.8246 - val_mse: 6.8246 - val_mae: 2.0801\n",
            "Epoch 55/10000000\n",
            "60/60 - 0s - loss: 6.6363 - mse: 6.6363 - mae: 2.0535 - val_loss: 6.8112 - val_mse: 6.8112 - val_mae: 2.0798\n",
            "Epoch 56/10000000\n",
            "60/60 - 0s - loss: 6.6384 - mse: 6.6384 - mae: 2.0536 - val_loss: 6.8383 - val_mse: 6.8383 - val_mae: 2.0835\n",
            "Epoch 57/10000000\n",
            "60/60 - 0s - loss: 6.6310 - mse: 6.6310 - mae: 2.0522 - val_loss: 6.8212 - val_mse: 6.8212 - val_mae: 2.0811\n",
            "Epoch 58/10000000\n",
            "60/60 - 0s - loss: 6.6236 - mse: 6.6236 - mae: 2.0505 - val_loss: 6.8311 - val_mse: 6.8311 - val_mae: 2.0813\n",
            "Epoch 59/10000000\n",
            "60/60 - 0s - loss: 6.6276 - mse: 6.6276 - mae: 2.0510 - val_loss: 6.8300 - val_mse: 6.8300 - val_mae: 2.0811\n",
            "Epoch 60/10000000\n",
            "60/60 - 0s - loss: 6.6144 - mse: 6.6144 - mae: 2.0497 - val_loss: 6.8489 - val_mse: 6.8489 - val_mae: 2.0856\n",
            "Epoch 61/10000000\n",
            "60/60 - 0s - loss: 6.6131 - mse: 6.6131 - mae: 2.0498 - val_loss: 6.8393 - val_mse: 6.8393 - val_mae: 2.0829\n",
            "Epoch 62/10000000\n",
            "60/60 - 0s - loss: 6.6034 - mse: 6.6034 - mae: 2.0476 - val_loss: 6.8590 - val_mse: 6.8590 - val_mae: 2.0863\n",
            "Epoch 63/10000000\n",
            "60/60 - 0s - loss: 6.6205 - mse: 6.6205 - mae: 2.0521 - val_loss: 6.8361 - val_mse: 6.8361 - val_mae: 2.0821\n",
            "Epoch 64/10000000\n",
            "60/60 - 0s - loss: 6.6088 - mse: 6.6088 - mae: 2.0478 - val_loss: 6.8343 - val_mse: 6.8343 - val_mae: 2.0830\n",
            "Epoch 65/10000000\n",
            "60/60 - 0s - loss: 6.5893 - mse: 6.5893 - mae: 2.0461 - val_loss: 6.8450 - val_mse: 6.8450 - val_mae: 2.0841\n",
            "Epoch 66/10000000\n",
            "60/60 - 0s - loss: 6.5928 - mse: 6.5928 - mae: 2.0465 - val_loss: 6.8781 - val_mse: 6.8781 - val_mae: 2.0878\n",
            "Epoch 67/10000000\n",
            "60/60 - 0s - loss: 6.6020 - mse: 6.6020 - mae: 2.0466 - val_loss: 6.8746 - val_mse: 6.8746 - val_mae: 2.0881\n",
            "Epoch 68/10000000\n",
            "60/60 - 0s - loss: 6.5824 - mse: 6.5824 - mae: 2.0449 - val_loss: 6.8638 - val_mse: 6.8638 - val_mae: 2.0883\n",
            "Epoch 69/10000000\n",
            "60/60 - 0s - loss: 6.5878 - mse: 6.5878 - mae: 2.0441 - val_loss: 6.8755 - val_mse: 6.8755 - val_mae: 2.0899\n",
            "Epoch 70/10000000\n",
            "60/60 - 0s - loss: 6.5837 - mse: 6.5837 - mae: 2.0462 - val_loss: 6.8721 - val_mse: 6.8721 - val_mae: 2.0882\n",
            "Epoch 71/10000000\n",
            "60/60 - 0s - loss: 6.5721 - mse: 6.5721 - mae: 2.0416 - val_loss: 6.9180 - val_mse: 6.9180 - val_mae: 2.0966\n",
            "Epoch 72/10000000\n",
            "60/60 - 0s - loss: 6.5659 - mse: 6.5659 - mae: 2.0416 - val_loss: 6.9029 - val_mse: 6.9029 - val_mae: 2.0954\n",
            "Epoch 73/10000000\n",
            "60/60 - 0s - loss: 6.5649 - mse: 6.5649 - mae: 2.0408 - val_loss: 6.8904 - val_mse: 6.8904 - val_mae: 2.0928\n",
            "Epoch 74/10000000\n",
            "60/60 - 0s - loss: 6.5521 - mse: 6.5521 - mae: 2.0407 - val_loss: 6.8840 - val_mse: 6.8840 - val_mae: 2.0906\n",
            "Epoch 75/10000000\n",
            "60/60 - 0s - loss: 6.5594 - mse: 6.5594 - mae: 2.0424 - val_loss: 6.9037 - val_mse: 6.9037 - val_mae: 2.0943\n",
            "Epoch 76/10000000\n",
            "60/60 - 0s - loss: 6.5468 - mse: 6.5468 - mae: 2.0387 - val_loss: 6.8857 - val_mse: 6.8857 - val_mae: 2.0911\n",
            "Epoch 77/10000000\n",
            "60/60 - 0s - loss: 6.5533 - mse: 6.5533 - mae: 2.0391 - val_loss: 6.8941 - val_mse: 6.8941 - val_mae: 2.0937\n",
            "Epoch 78/10000000\n",
            "60/60 - 0s - loss: 6.5366 - mse: 6.5366 - mae: 2.0368 - val_loss: 6.9165 - val_mse: 6.9165 - val_mae: 2.0981\n",
            "Epoch 79/10000000\n",
            "60/60 - 0s - loss: 6.5427 - mse: 6.5427 - mae: 2.0382 - val_loss: 6.9220 - val_mse: 6.9220 - val_mae: 2.0968\n",
            "Epoch 80/10000000\n",
            "60/60 - 0s - loss: 6.5282 - mse: 6.5282 - mae: 2.0345 - val_loss: 6.9176 - val_mse: 6.9176 - val_mae: 2.0959\n",
            "Epoch 81/10000000\n",
            "60/60 - 0s - loss: 6.5250 - mse: 6.5250 - mae: 2.0341 - val_loss: 6.9232 - val_mse: 6.9232 - val_mae: 2.0972\n",
            "Epoch 82/10000000\n",
            "60/60 - 0s - loss: 6.5168 - mse: 6.5168 - mae: 2.0344 - val_loss: 6.9252 - val_mse: 6.9252 - val_mae: 2.0972\n",
            "Epoch 83/10000000\n",
            "60/60 - 0s - loss: 6.5146 - mse: 6.5146 - mae: 2.0345 - val_loss: 6.9278 - val_mse: 6.9278 - val_mae: 2.0976\n",
            "Epoch 84/10000000\n",
            "60/60 - 0s - loss: 6.5123 - mse: 6.5123 - mae: 2.0349 - val_loss: 6.9479 - val_mse: 6.9479 - val_mae: 2.1005\n",
            "Epoch 85/10000000\n",
            "60/60 - 0s - loss: 6.5021 - mse: 6.5021 - mae: 2.0319 - val_loss: 6.9210 - val_mse: 6.9210 - val_mae: 2.0969\n",
            "Epoch 86/10000000\n",
            "60/60 - 0s - loss: 6.5002 - mse: 6.5002 - mae: 2.0294 - val_loss: 6.9443 - val_mse: 6.9443 - val_mae: 2.1020\n",
            "Epoch 87/10000000\n",
            "60/60 - 0s - loss: 6.5006 - mse: 6.5006 - mae: 2.0307 - val_loss: 6.9290 - val_mse: 6.9290 - val_mae: 2.0987\n",
            "Epoch 88/10000000\n",
            "60/60 - 0s - loss: 6.4866 - mse: 6.4866 - mae: 2.0287 - val_loss: 6.9306 - val_mse: 6.9306 - val_mae: 2.0983\n",
            "Epoch 89/10000000\n",
            "60/60 - 0s - loss: 6.4822 - mse: 6.4822 - mae: 2.0279 - val_loss: 6.9560 - val_mse: 6.9560 - val_mae: 2.1017\n",
            "Epoch 90/10000000\n",
            "60/60 - 0s - loss: 6.4773 - mse: 6.4773 - mae: 2.0277 - val_loss: 6.9405 - val_mse: 6.9405 - val_mae: 2.1017\n",
            "Epoch 91/10000000\n",
            "60/60 - 0s - loss: 6.4851 - mse: 6.4851 - mae: 2.0297 - val_loss: 6.9390 - val_mse: 6.9390 - val_mae: 2.0984\n",
            "Epoch 92/10000000\n",
            "60/60 - 0s - loss: 6.4802 - mse: 6.4802 - mae: 2.0280 - val_loss: 6.9589 - val_mse: 6.9589 - val_mae: 2.1042\n",
            "Epoch 93/10000000\n",
            "60/60 - 0s - loss: 6.4688 - mse: 6.4688 - mae: 2.0263 - val_loss: 6.9846 - val_mse: 6.9846 - val_mae: 2.1089\n",
            "Epoch 94/10000000\n",
            "60/60 - 0s - loss: 6.4533 - mse: 6.4533 - mae: 2.0239 - val_loss: 6.9918 - val_mse: 6.9918 - val_mae: 2.1071\n",
            "Epoch 95/10000000\n",
            "60/60 - 0s - loss: 6.4604 - mse: 6.4604 - mae: 2.0251 - val_loss: 6.9717 - val_mse: 6.9717 - val_mae: 2.1065\n",
            "Epoch 96/10000000\n",
            "60/60 - 0s - loss: 6.4560 - mse: 6.4560 - mae: 2.0252 - val_loss: 6.9677 - val_mse: 6.9677 - val_mae: 2.1044\n",
            "Epoch 97/10000000\n",
            "60/60 - 0s - loss: 6.4470 - mse: 6.4470 - mae: 2.0227 - val_loss: 6.9666 - val_mse: 6.9666 - val_mae: 2.1033\n",
            "Epoch 98/10000000\n",
            "60/60 - 0s - loss: 6.4351 - mse: 6.4351 - mae: 2.0205 - val_loss: 6.9695 - val_mse: 6.9695 - val_mae: 2.1052\n",
            "Epoch 99/10000000\n",
            "60/60 - 0s - loss: 6.4276 - mse: 6.4276 - mae: 2.0190 - val_loss: 6.9816 - val_mse: 6.9816 - val_mae: 2.1057\n",
            "Epoch 100/10000000\n",
            "60/60 - 0s - loss: 6.4444 - mse: 6.4444 - mae: 2.0228 - val_loss: 6.9911 - val_mse: 6.9911 - val_mae: 2.1070\n",
            "Epoch 101/10000000\n",
            "60/60 - 0s - loss: 6.4180 - mse: 6.4180 - mae: 2.0180 - val_loss: 7.0148 - val_mse: 7.0148 - val_mae: 2.1093\n",
            "Epoch 102/10000000\n",
            "60/60 - 0s - loss: 6.4148 - mse: 6.4148 - mae: 2.0164 - val_loss: 7.0221 - val_mse: 7.0221 - val_mae: 2.1121\n",
            "Epoch 103/10000000\n",
            "60/60 - 0s - loss: 6.4148 - mse: 6.4148 - mae: 2.0179 - val_loss: 6.9931 - val_mse: 6.9931 - val_mae: 2.1084\n",
            "Epoch 104/10000000\n",
            "60/60 - 0s - loss: 6.4103 - mse: 6.4103 - mae: 2.0192 - val_loss: 7.0247 - val_mse: 7.0247 - val_mae: 2.1113\n",
            "Epoch 105/10000000\n",
            "60/60 - 0s - loss: 6.3997 - mse: 6.3997 - mae: 2.0143 - val_loss: 7.0656 - val_mse: 7.0656 - val_mae: 2.1184\n",
            "Epoch 106/10000000\n",
            "60/60 - 0s - loss: 6.4012 - mse: 6.4012 - mae: 2.0164 - val_loss: 7.0673 - val_mse: 7.0673 - val_mae: 2.1193\n",
            "Epoch 107/10000000\n",
            "60/60 - 0s - loss: 6.4107 - mse: 6.4107 - mae: 2.0183 - val_loss: 7.0343 - val_mse: 7.0343 - val_mae: 2.1138\n",
            "Epoch 108/10000000\n",
            "60/60 - 0s - loss: 6.3916 - mse: 6.3916 - mae: 2.0140 - val_loss: 7.0640 - val_mse: 7.0640 - val_mae: 2.1135\n",
            "Epoch 109/10000000\n",
            "60/60 - 0s - loss: 6.3817 - mse: 6.3817 - mae: 2.0149 - val_loss: 7.0105 - val_mse: 7.0105 - val_mae: 2.1106\n",
            "Epoch 110/10000000\n",
            "60/60 - 0s - loss: 6.3814 - mse: 6.3814 - mae: 2.0140 - val_loss: 7.0751 - val_mse: 7.0751 - val_mae: 2.1186\n",
            "Epoch 111/10000000\n",
            "60/60 - 0s - loss: 6.3969 - mse: 6.3969 - mae: 2.0149 - val_loss: 7.0385 - val_mse: 7.0385 - val_mae: 2.1125\n",
            "Epoch 112/10000000\n",
            "60/60 - 0s - loss: 6.3802 - mse: 6.3802 - mae: 2.0083 - val_loss: 7.0540 - val_mse: 7.0540 - val_mae: 2.1174\n",
            "Epoch 113/10000000\n",
            "60/60 - 0s - loss: 6.3686 - mse: 6.3686 - mae: 2.0109 - val_loss: 7.0836 - val_mse: 7.0836 - val_mae: 2.1203\n",
            "Epoch 114/10000000\n",
            "60/60 - 0s - loss: 6.3753 - mse: 6.3753 - mae: 2.0122 - val_loss: 7.0380 - val_mse: 7.0380 - val_mae: 2.1141\n",
            "Epoch 115/10000000\n",
            "60/60 - 0s - loss: 6.3523 - mse: 6.3523 - mae: 2.0094 - val_loss: 7.0753 - val_mse: 7.0753 - val_mae: 2.1201\n",
            "Epoch 116/10000000\n",
            "60/60 - 0s - loss: 6.3402 - mse: 6.3402 - mae: 2.0058 - val_loss: 7.0933 - val_mse: 7.0933 - val_mae: 2.1227\n",
            "Epoch 117/10000000\n",
            "60/60 - 0s - loss: 6.3472 - mse: 6.3472 - mae: 2.0066 - val_loss: 7.0426 - val_mse: 7.0426 - val_mae: 2.1160\n",
            "Epoch 118/10000000\n",
            "60/60 - 0s - loss: 6.3599 - mse: 6.3599 - mae: 2.0108 - val_loss: 7.1663 - val_mse: 7.1663 - val_mae: 2.1349\n",
            "Epoch 119/10000000\n",
            "60/60 - 0s - loss: 6.3469 - mse: 6.3469 - mae: 2.0067 - val_loss: 7.1202 - val_mse: 7.1202 - val_mae: 2.1260\n",
            "Epoch 120/10000000\n",
            "60/60 - 0s - loss: 6.3285 - mse: 6.3285 - mae: 2.0050 - val_loss: 7.1398 - val_mse: 7.1398 - val_mae: 2.1272\n",
            "Epoch 121/10000000\n",
            "60/60 - 0s - loss: 6.3369 - mse: 6.3369 - mae: 2.0038 - val_loss: 7.1104 - val_mse: 7.1104 - val_mae: 2.1267\n",
            "Epoch 122/10000000\n",
            "60/60 - 0s - loss: 6.3156 - mse: 6.3156 - mae: 2.0040 - val_loss: 7.1117 - val_mse: 7.1117 - val_mae: 2.1223\n",
            "Epoch 123/10000000\n",
            "60/60 - 0s - loss: 6.3186 - mse: 6.3186 - mae: 2.0035 - val_loss: 7.0987 - val_mse: 7.0987 - val_mae: 2.1255\n",
            "Epoch 124/10000000\n",
            "60/60 - 0s - loss: 6.3265 - mse: 6.3265 - mae: 2.0029 - val_loss: 7.1084 - val_mse: 7.1084 - val_mae: 2.1247\n",
            "Epoch 125/10000000\n",
            "60/60 - 0s - loss: 6.3063 - mse: 6.3063 - mae: 2.0009 - val_loss: 7.0992 - val_mse: 7.0992 - val_mae: 2.1250\n",
            "Epoch 126/10000000\n",
            "60/60 - 0s - loss: 6.3148 - mse: 6.3148 - mae: 2.0022 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1203\n",
            "Epoch 127/10000000\n",
            "60/60 - 0s - loss: 6.2892 - mse: 6.2892 - mae: 1.9980 - val_loss: 7.1219 - val_mse: 7.1219 - val_mae: 2.1276\n",
            "Epoch 128/10000000\n",
            "60/60 - 0s - loss: 6.2830 - mse: 6.2830 - mae: 1.9967 - val_loss: 7.1806 - val_mse: 7.1806 - val_mae: 2.1360\n",
            "Epoch 129/10000000\n",
            "60/60 - 0s - loss: 6.3053 - mse: 6.3053 - mae: 1.9986 - val_loss: 7.1735 - val_mse: 7.1735 - val_mae: 2.1358\n",
            "Epoch 130/10000000\n",
            "60/60 - 0s - loss: 6.3067 - mse: 6.3067 - mae: 2.0001 - val_loss: 7.1928 - val_mse: 7.1928 - val_mae: 2.1353\n",
            "Epoch 131/10000000\n",
            "60/60 - 0s - loss: 6.2797 - mse: 6.2797 - mae: 1.9965 - val_loss: 7.1483 - val_mse: 7.1483 - val_mae: 2.1304\n",
            "Epoch 132/10000000\n",
            "60/60 - 0s - loss: 6.2808 - mse: 6.2808 - mae: 1.9982 - val_loss: 7.1682 - val_mse: 7.1682 - val_mae: 2.1372\n",
            "Epoch 133/10000000\n",
            "60/60 - 0s - loss: 6.2704 - mse: 6.2704 - mae: 1.9954 - val_loss: 7.1487 - val_mse: 7.1487 - val_mae: 2.1294\n",
            "Epoch 134/10000000\n",
            "60/60 - 0s - loss: 6.2574 - mse: 6.2574 - mae: 1.9942 - val_loss: 7.1687 - val_mse: 7.1687 - val_mae: 2.1338\n",
            "Epoch 135/10000000\n",
            "60/60 - 0s - loss: 6.2746 - mse: 6.2746 - mae: 1.9950 - val_loss: 7.1715 - val_mse: 7.1715 - val_mae: 2.1385\n",
            "Epoch 136/10000000\n",
            "60/60 - 0s - loss: 6.2377 - mse: 6.2377 - mae: 1.9887 - val_loss: 7.2051 - val_mse: 7.2051 - val_mae: 2.1400\n",
            "Epoch 137/10000000\n",
            "60/60 - 0s - loss: 6.2417 - mse: 6.2417 - mae: 1.9911 - val_loss: 7.1136 - val_mse: 7.1136 - val_mae: 2.1265\n",
            "Epoch 138/10000000\n",
            "60/60 - 0s - loss: 6.2635 - mse: 6.2635 - mae: 1.9935 - val_loss: 7.0996 - val_mse: 7.0996 - val_mae: 2.1223\n",
            "Epoch 139/10000000\n",
            "60/60 - 0s - loss: 6.2530 - mse: 6.2530 - mae: 1.9913 - val_loss: 7.1566 - val_mse: 7.1566 - val_mae: 2.1296\n",
            "Epoch 140/10000000\n",
            "60/60 - 0s - loss: 6.2446 - mse: 6.2446 - mae: 1.9880 - val_loss: 7.1500 - val_mse: 7.1500 - val_mae: 2.1325\n",
            "Epoch 141/10000000\n",
            "60/60 - 0s - loss: 6.2307 - mse: 6.2307 - mae: 1.9884 - val_loss: 7.2126 - val_mse: 7.2126 - val_mae: 2.1416\n",
            "Epoch 142/10000000\n",
            "60/60 - 0s - loss: 6.2322 - mse: 6.2322 - mae: 1.9880 - val_loss: 7.1461 - val_mse: 7.1461 - val_mae: 2.1282\n",
            "Epoch 143/10000000\n",
            "60/60 - 0s - loss: 6.2220 - mse: 6.2220 - mae: 1.9878 - val_loss: 7.1909 - val_mse: 7.1909 - val_mae: 2.1371\n",
            "Epoch 144/10000000\n",
            "60/60 - 0s - loss: 6.2064 - mse: 6.2064 - mae: 1.9849 - val_loss: 7.1638 - val_mse: 7.1638 - val_mae: 2.1295\n",
            "Epoch 145/10000000\n",
            "60/60 - 0s - loss: 6.2037 - mse: 6.2037 - mae: 1.9855 - val_loss: 7.1221 - val_mse: 7.1221 - val_mae: 2.1264\n",
            "Epoch 146/10000000\n",
            "60/60 - 0s - loss: 6.2045 - mse: 6.2045 - mae: 1.9862 - val_loss: 7.1914 - val_mse: 7.1914 - val_mae: 2.1368\n",
            "Epoch 147/10000000\n",
            "60/60 - 0s - loss: 6.1963 - mse: 6.1963 - mae: 1.9836 - val_loss: 7.2405 - val_mse: 7.2405 - val_mae: 2.1443\n",
            "Epoch 148/10000000\n",
            "60/60 - 0s - loss: 6.2148 - mse: 6.2148 - mae: 1.9837 - val_loss: 7.2223 - val_mse: 7.2223 - val_mae: 2.1418\n",
            "Epoch 149/10000000\n",
            "60/60 - 0s - loss: 6.1873 - mse: 6.1873 - mae: 1.9821 - val_loss: 7.2208 - val_mse: 7.2208 - val_mae: 2.1390\n",
            "Epoch 150/10000000\n",
            "60/60 - 0s - loss: 6.1831 - mse: 6.1831 - mae: 1.9804 - val_loss: 7.2232 - val_mse: 7.2232 - val_mae: 2.1401\n",
            "Epoch 151/10000000\n",
            "60/60 - 0s - loss: 6.1820 - mse: 6.1820 - mae: 1.9814 - val_loss: 7.2217 - val_mse: 7.2217 - val_mae: 2.1420\n",
            "Epoch 152/10000000\n",
            "60/60 - 0s - loss: 6.1676 - mse: 6.1676 - mae: 1.9773 - val_loss: 7.1889 - val_mse: 7.1889 - val_mae: 2.1346\n",
            "Epoch 153/10000000\n",
            "60/60 - 0s - loss: 6.1717 - mse: 6.1717 - mae: 1.9784 - val_loss: 7.2643 - val_mse: 7.2643 - val_mae: 2.1478\n",
            "Epoch 154/10000000\n",
            "60/60 - 0s - loss: 6.1810 - mse: 6.1810 - mae: 1.9800 - val_loss: 7.1979 - val_mse: 7.1979 - val_mae: 2.1367\n",
            "Epoch 155/10000000\n",
            "60/60 - 0s - loss: 6.1789 - mse: 6.1789 - mae: 1.9833 - val_loss: 7.2259 - val_mse: 7.2259 - val_mae: 2.1442\n",
            "Epoch 156/10000000\n",
            "60/60 - 0s - loss: 6.1502 - mse: 6.1502 - mae: 1.9772 - val_loss: 7.2129 - val_mse: 7.2129 - val_mae: 2.1396\n",
            "Epoch 157/10000000\n",
            "60/60 - 0s - loss: 6.1330 - mse: 6.1330 - mae: 1.9740 - val_loss: 7.2652 - val_mse: 7.2652 - val_mae: 2.1494\n",
            "Epoch 158/10000000\n",
            "60/60 - 0s - loss: 6.1597 - mse: 6.1597 - mae: 1.9777 - val_loss: 7.2264 - val_mse: 7.2264 - val_mae: 2.1415\n",
            "Epoch 159/10000000\n",
            "60/60 - 0s - loss: 6.1216 - mse: 6.1216 - mae: 1.9679 - val_loss: 7.2841 - val_mse: 7.2841 - val_mae: 2.1499\n",
            "Epoch 160/10000000\n",
            "60/60 - 0s - loss: 6.1220 - mse: 6.1220 - mae: 1.9694 - val_loss: 7.2213 - val_mse: 7.2213 - val_mae: 2.1403\n",
            "Epoch 161/10000000\n",
            "60/60 - 0s - loss: 6.1422 - mse: 6.1422 - mae: 1.9748 - val_loss: 7.1930 - val_mse: 7.1930 - val_mae: 2.1372\n",
            "Epoch 162/10000000\n",
            "60/60 - 0s - loss: 6.1131 - mse: 6.1131 - mae: 1.9686 - val_loss: 7.2849 - val_mse: 7.2849 - val_mae: 2.1503\n",
            "Epoch 163/10000000\n",
            "60/60 - 0s - loss: 6.1282 - mse: 6.1282 - mae: 1.9693 - val_loss: 7.2294 - val_mse: 7.2294 - val_mae: 2.1438\n",
            "Epoch 164/10000000\n",
            "60/60 - 0s - loss: 6.1046 - mse: 6.1046 - mae: 1.9702 - val_loss: 7.2457 - val_mse: 7.2457 - val_mae: 2.1466\n",
            "Epoch 165/10000000\n",
            "60/60 - 0s - loss: 6.1217 - mse: 6.1217 - mae: 1.9697 - val_loss: 7.2858 - val_mse: 7.2858 - val_mae: 2.1493\n",
            "Epoch 166/10000000\n",
            "60/60 - 0s - loss: 6.1117 - mse: 6.1117 - mae: 1.9697 - val_loss: 7.3097 - val_mse: 7.3097 - val_mae: 2.1530\n",
            "Epoch 167/10000000\n",
            "60/60 - 0s - loss: 6.1042 - mse: 6.1042 - mae: 1.9669 - val_loss: 7.2794 - val_mse: 7.2794 - val_mae: 2.1490\n",
            "Epoch 168/10000000\n",
            "60/60 - 0s - loss: 6.0824 - mse: 6.0824 - mae: 1.9638 - val_loss: 7.3257 - val_mse: 7.3257 - val_mae: 2.1546\n",
            "Epoch 169/10000000\n",
            "60/60 - 0s - loss: 6.0997 - mse: 6.0997 - mae: 1.9659 - val_loss: 7.3068 - val_mse: 7.3068 - val_mae: 2.1565\n",
            "Epoch 170/10000000\n",
            "60/60 - 0s - loss: 6.0953 - mse: 6.0953 - mae: 1.9643 - val_loss: 7.2515 - val_mse: 7.2515 - val_mae: 2.1437\n",
            "Epoch 171/10000000\n",
            "60/60 - 0s - loss: 6.0856 - mse: 6.0856 - mae: 1.9647 - val_loss: 7.2927 - val_mse: 7.2927 - val_mae: 2.1548\n",
            "Epoch 172/10000000\n",
            "60/60 - 0s - loss: 6.1041 - mse: 6.1041 - mae: 1.9701 - val_loss: 7.2878 - val_mse: 7.2878 - val_mae: 2.1545\n",
            "Epoch 173/10000000\n",
            "60/60 - 0s - loss: 6.0972 - mse: 6.0972 - mae: 1.9643 - val_loss: 7.3217 - val_mse: 7.3217 - val_mae: 2.1565\n",
            "Epoch 174/10000000\n",
            "60/60 - 0s - loss: 6.0960 - mse: 6.0960 - mae: 1.9670 - val_loss: 7.3282 - val_mse: 7.3282 - val_mae: 2.1591\n",
            "Epoch 175/10000000\n",
            "60/60 - 0s - loss: 6.0541 - mse: 6.0541 - mae: 1.9609 - val_loss: 7.3207 - val_mse: 7.3207 - val_mae: 2.1600\n",
            "Epoch 176/10000000\n",
            "60/60 - 0s - loss: 6.0518 - mse: 6.0518 - mae: 1.9591 - val_loss: 7.2869 - val_mse: 7.2869 - val_mae: 2.1471\n",
            "Epoch 177/10000000\n",
            "60/60 - 0s - loss: 6.0604 - mse: 6.0604 - mae: 1.9586 - val_loss: 7.3356 - val_mse: 7.3356 - val_mae: 2.1569\n",
            "Epoch 178/10000000\n",
            "60/60 - 0s - loss: 6.0494 - mse: 6.0494 - mae: 1.9587 - val_loss: 7.3557 - val_mse: 7.3557 - val_mae: 2.1603\n",
            "Epoch 179/10000000\n",
            "60/60 - 0s - loss: 6.0412 - mse: 6.0412 - mae: 1.9594 - val_loss: 7.3734 - val_mse: 7.3734 - val_mae: 2.1640\n",
            "Epoch 180/10000000\n",
            "60/60 - 0s - loss: 6.0410 - mse: 6.0410 - mae: 1.9570 - val_loss: 7.3849 - val_mse: 7.3849 - val_mae: 2.1670\n",
            "Epoch 181/10000000\n",
            "60/60 - 0s - loss: 6.0420 - mse: 6.0420 - mae: 1.9568 - val_loss: 7.3670 - val_mse: 7.3670 - val_mae: 2.1648\n",
            "Epoch 182/10000000\n",
            "60/60 - 0s - loss: 6.0570 - mse: 6.0570 - mae: 1.9594 - val_loss: 7.3881 - val_mse: 7.3881 - val_mae: 2.1675\n",
            "Epoch 183/10000000\n",
            "60/60 - 0s - loss: 6.0335 - mse: 6.0335 - mae: 1.9560 - val_loss: 7.4183 - val_mse: 7.4183 - val_mae: 2.1693\n",
            "Epoch 184/10000000\n",
            "60/60 - 0s - loss: 6.0518 - mse: 6.0518 - mae: 1.9621 - val_loss: 7.4040 - val_mse: 7.4040 - val_mae: 2.1724\n",
            "Epoch 185/10000000\n",
            "60/60 - 0s - loss: 6.0215 - mse: 6.0215 - mae: 1.9544 - val_loss: 7.3910 - val_mse: 7.3910 - val_mae: 2.1637\n",
            "Epoch 186/10000000\n",
            "60/60 - 0s - loss: 6.0267 - mse: 6.0267 - mae: 1.9543 - val_loss: 7.3668 - val_mse: 7.3668 - val_mae: 2.1606\n",
            "Epoch 187/10000000\n",
            "60/60 - 0s - loss: 6.0308 - mse: 6.0308 - mae: 1.9547 - val_loss: 7.3661 - val_mse: 7.3661 - val_mae: 2.1607\n",
            "Epoch 188/10000000\n",
            "60/60 - 0s - loss: 6.0109 - mse: 6.0109 - mae: 1.9513 - val_loss: 7.3084 - val_mse: 7.3084 - val_mae: 2.1525\n",
            "Epoch 189/10000000\n",
            "60/60 - 0s - loss: 6.0079 - mse: 6.0079 - mae: 1.9541 - val_loss: 7.3633 - val_mse: 7.3633 - val_mae: 2.1609\n",
            "Epoch 190/10000000\n",
            "60/60 - 0s - loss: 5.9895 - mse: 5.9895 - mae: 1.9503 - val_loss: 7.3484 - val_mse: 7.3484 - val_mae: 2.1577\n",
            "Epoch 191/10000000\n",
            "60/60 - 0s - loss: 5.9936 - mse: 5.9936 - mae: 1.9490 - val_loss: 7.4181 - val_mse: 7.4181 - val_mae: 2.1688\n",
            "Epoch 192/10000000\n",
            "60/60 - 0s - loss: 6.0020 - mse: 6.0020 - mae: 1.9497 - val_loss: 7.3354 - val_mse: 7.3354 - val_mae: 2.1558\n",
            "Epoch 193/10000000\n",
            "60/60 - 0s - loss: 5.9979 - mse: 5.9979 - mae: 1.9508 - val_loss: 7.3189 - val_mse: 7.3189 - val_mae: 2.1528\n",
            "Epoch 194/10000000\n",
            "60/60 - 0s - loss: 5.9812 - mse: 5.9812 - mae: 1.9459 - val_loss: 7.4681 - val_mse: 7.4681 - val_mae: 2.1787\n",
            "Epoch 195/10000000\n",
            "60/60 - 0s - loss: 6.0199 - mse: 6.0199 - mae: 1.9528 - val_loss: 7.3567 - val_mse: 7.3567 - val_mae: 2.1602\n",
            "Epoch 196/10000000\n",
            "60/60 - 0s - loss: 5.9926 - mse: 5.9926 - mae: 1.9485 - val_loss: 7.3286 - val_mse: 7.3286 - val_mae: 2.1572\n",
            "Epoch 197/10000000\n",
            "60/60 - 0s - loss: 5.9583 - mse: 5.9583 - mae: 1.9458 - val_loss: 7.4180 - val_mse: 7.4180 - val_mae: 2.1711\n",
            "Epoch 198/10000000\n",
            "60/60 - 0s - loss: 5.9580 - mse: 5.9580 - mae: 1.9426 - val_loss: 7.3911 - val_mse: 7.3911 - val_mae: 2.1664\n",
            "Epoch 199/10000000\n",
            "60/60 - 0s - loss: 5.9684 - mse: 5.9684 - mae: 1.9468 - val_loss: 7.4438 - val_mse: 7.4438 - val_mae: 2.1721\n",
            "Epoch 200/10000000\n",
            "60/60 - 0s - loss: 5.9720 - mse: 5.9720 - mae: 1.9433 - val_loss: 7.3466 - val_mse: 7.3466 - val_mae: 2.1560\n",
            "Epoch 201/10000000\n",
            "60/60 - 0s - loss: 5.9627 - mse: 5.9627 - mae: 1.9425 - val_loss: 7.3798 - val_mse: 7.3798 - val_mae: 2.1590\n",
            "Epoch 202/10000000\n",
            "60/60 - 0s - loss: 5.9833 - mse: 5.9833 - mae: 1.9496 - val_loss: 7.4188 - val_mse: 7.4188 - val_mae: 2.1712\n",
            "Epoch 203/10000000\n",
            "60/60 - 0s - loss: 5.9774 - mse: 5.9774 - mae: 1.9460 - val_loss: 7.4928 - val_mse: 7.4928 - val_mae: 2.1792\n",
            "Epoch 204/10000000\n",
            "60/60 - 0s - loss: 5.9457 - mse: 5.9457 - mae: 1.9422 - val_loss: 7.4647 - val_mse: 7.4647 - val_mae: 2.1728\n",
            "Epoch 205/10000000\n",
            "60/60 - 0s - loss: 5.9390 - mse: 5.9390 - mae: 1.9380 - val_loss: 7.4377 - val_mse: 7.4377 - val_mae: 2.1708\n",
            "Epoch 206/10000000\n",
            "60/60 - 0s - loss: 5.9601 - mse: 5.9601 - mae: 1.9420 - val_loss: 7.4684 - val_mse: 7.4684 - val_mae: 2.1758\n",
            "Epoch 207/10000000\n",
            "60/60 - 0s - loss: 5.9180 - mse: 5.9180 - mae: 1.9391 - val_loss: 7.4420 - val_mse: 7.4420 - val_mae: 2.1712\n",
            "Epoch 208/10000000\n",
            "60/60 - 0s - loss: 5.9531 - mse: 5.9531 - mae: 1.9429 - val_loss: 7.5057 - val_mse: 7.5057 - val_mae: 2.1798\n",
            "Epoch 209/10000000\n",
            "60/60 - 0s - loss: 5.9103 - mse: 5.9103 - mae: 1.9356 - val_loss: 7.4540 - val_mse: 7.4540 - val_mae: 2.1745\n",
            "Epoch 210/10000000\n",
            "60/60 - 0s - loss: 5.9368 - mse: 5.9368 - mae: 1.9430 - val_loss: 7.5096 - val_mse: 7.5096 - val_mae: 2.1826\n",
            "Epoch 00210: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtD_3e8i7GTa"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def model_creation():\n",
        "  model4 = Sequential()\n",
        "  model4.add(Dense(20, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        "  model4.add(Dense(1, kernel_initializer='normal'))\n",
        "  model4.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  return model4\n",
        "  \n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(build_fn=model_creation, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(pipeline, nn_input, nn_output, cv=kfold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s031Hf881Pi"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGKHGipPmspe",
        "outputId": "825756ed-8bee-4fc5-da7d-2f3b00efd215"
      },
      "source": [
        "print(\"%0.2f (%0.2f) MSE\" % (results.mean(), results.std()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-6.83 (0.34) MSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZEK2P4YEsfP",
        "outputId": "c5313318-d1e4-4c59-f7f2-8d15e3eba9f1"
      },
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Dense(32, input_dim=4, activation='relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "model5.add(Dense(64, activation='relu'))\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(Dense(128, activation='relu'))\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(Dense(256, activation='relu'))\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(Dense(256, activation='relu'))\n",
        "model5.add(Dropout(0.2))\n",
        "model5.add(Dense(128, activation='relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "model5.add(Dense(1, activation='linear'))\n",
        "\n",
        "model5.compile(optimizer='adagrad', loss='mse', metrics=['mse', 'mae'])\n",
        "\n",
        "# training model\n",
        "history = model5.fit(x_train, y_train, epochs = 300,\n",
        "                        validation_data=(x_valid, y_valid),\n",
        "                        batch_size = 16, verbose = 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "563/563 [==============================] - 3s 4ms/step - loss: 6.7114 - mse: 6.7114 - mae: 2.0633 - val_loss: 7.0645 - val_mse: 7.0645 - val_mae: 2.1176\n",
            "Epoch 2/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7900 - mse: 6.7900 - mae: 2.0759 - val_loss: 7.0637 - val_mse: 7.0637 - val_mae: 2.1175\n",
            "Epoch 3/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7915 - mse: 6.7915 - mae: 2.0777 - val_loss: 7.0621 - val_mse: 7.0621 - val_mae: 2.1173\n",
            "Epoch 4/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7869 - mse: 6.7869 - mae: 2.0787 - val_loss: 7.0650 - val_mse: 7.0650 - val_mae: 2.1177\n",
            "Epoch 5/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7676 - mse: 6.7676 - mae: 2.0762 - val_loss: 7.0625 - val_mse: 7.0625 - val_mae: 2.1174\n",
            "Epoch 6/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9151 - mse: 6.9151 - mae: 2.1064 - val_loss: 7.0641 - val_mse: 7.0641 - val_mae: 2.1177\n",
            "Epoch 7/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9497 - mse: 6.9497 - mae: 2.0970 - val_loss: 7.0602 - val_mse: 7.0602 - val_mae: 2.1172\n",
            "Epoch 8/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9634 - mse: 6.9634 - mae: 2.1021 - val_loss: 7.0591 - val_mse: 7.0591 - val_mae: 2.1171\n",
            "Epoch 9/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6878 - mse: 6.6878 - mae: 2.0572 - val_loss: 7.0619 - val_mse: 7.0619 - val_mae: 2.1174\n",
            "Epoch 10/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9332 - mse: 6.9332 - mae: 2.0997 - val_loss: 7.0601 - val_mse: 7.0601 - val_mae: 2.1172\n",
            "Epoch 11/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8470 - mse: 6.8470 - mae: 2.0895 - val_loss: 7.0604 - val_mse: 7.0604 - val_mae: 2.1172\n",
            "Epoch 12/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6964 - mse: 6.6964 - mae: 2.0653 - val_loss: 7.0614 - val_mse: 7.0614 - val_mae: 2.1173\n",
            "Epoch 13/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5675 - mse: 6.5675 - mae: 2.0488 - val_loss: 7.0625 - val_mse: 7.0625 - val_mae: 2.1176\n",
            "Epoch 14/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6012 - mse: 6.6012 - mae: 2.0494 - val_loss: 7.0598 - val_mse: 7.0598 - val_mae: 2.1172\n",
            "Epoch 15/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6754 - mse: 6.6754 - mae: 2.0740 - val_loss: 7.0590 - val_mse: 7.0590 - val_mae: 2.1171\n",
            "Epoch 16/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7024 - mse: 6.7024 - mae: 2.0607 - val_loss: 7.0587 - val_mse: 7.0587 - val_mae: 2.1171\n",
            "Epoch 17/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6319 - mse: 6.6319 - mae: 2.0486 - val_loss: 7.0578 - val_mse: 7.0578 - val_mae: 2.1170\n",
            "Epoch 18/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7467 - mse: 6.7467 - mae: 2.0789 - val_loss: 7.0585 - val_mse: 7.0585 - val_mae: 2.1171\n",
            "Epoch 19/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7299 - mse: 6.7299 - mae: 2.0739 - val_loss: 7.0569 - val_mse: 7.0569 - val_mae: 2.1169\n",
            "Epoch 20/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8369 - mse: 6.8369 - mae: 2.0790 - val_loss: 7.0596 - val_mse: 7.0596 - val_mae: 2.1174\n",
            "Epoch 21/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6920 - mse: 6.6920 - mae: 2.0604 - val_loss: 7.0605 - val_mse: 7.0605 - val_mae: 2.1176\n",
            "Epoch 22/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7801 - mse: 6.7801 - mae: 2.0880 - val_loss: 7.0617 - val_mse: 7.0617 - val_mae: 2.1178\n",
            "Epoch 23/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5739 - mse: 6.5739 - mae: 2.0504 - val_loss: 7.0598 - val_mse: 7.0598 - val_mae: 2.1175\n",
            "Epoch 24/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6198 - mse: 6.6198 - mae: 2.0561 - val_loss: 7.0601 - val_mse: 7.0601 - val_mae: 2.1176\n",
            "Epoch 25/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6227 - mse: 6.6227 - mae: 2.0633 - val_loss: 7.0600 - val_mse: 7.0600 - val_mae: 2.1175\n",
            "Epoch 26/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7967 - mse: 6.7967 - mae: 2.0802 - val_loss: 7.0603 - val_mse: 7.0603 - val_mae: 2.1176\n",
            "Epoch 27/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8609 - mse: 6.8609 - mae: 2.1002 - val_loss: 7.0620 - val_mse: 7.0620 - val_mae: 2.1179\n",
            "Epoch 28/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7600 - mse: 6.7600 - mae: 2.0758 - val_loss: 7.0618 - val_mse: 7.0618 - val_mae: 2.1178\n",
            "Epoch 29/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6760 - mse: 6.6760 - mae: 2.0733 - val_loss: 7.0611 - val_mse: 7.0611 - val_mae: 2.1177\n",
            "Epoch 30/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7940 - mse: 6.7940 - mae: 2.0841 - val_loss: 7.0612 - val_mse: 7.0612 - val_mae: 2.1178\n",
            "Epoch 31/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8511 - mse: 6.8511 - mae: 2.0834 - val_loss: 7.0608 - val_mse: 7.0608 - val_mae: 2.1177\n",
            "Epoch 32/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6095 - mse: 6.6095 - mae: 2.0472 - val_loss: 7.0607 - val_mse: 7.0607 - val_mae: 2.1177\n",
            "Epoch 33/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8795 - mse: 6.8795 - mae: 2.0973 - val_loss: 7.0603 - val_mse: 7.0603 - val_mae: 2.1177\n",
            "Epoch 34/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6868 - mse: 6.6868 - mae: 2.0606 - val_loss: 7.0591 - val_mse: 7.0591 - val_mae: 2.1174\n",
            "Epoch 35/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9306 - mse: 6.9306 - mae: 2.1117 - val_loss: 7.0585 - val_mse: 7.0585 - val_mae: 2.1174\n",
            "Epoch 36/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0024 - mse: 7.0024 - mae: 2.1151 - val_loss: 7.0600 - val_mse: 7.0600 - val_mae: 2.1177\n",
            "Epoch 37/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8317 - mse: 6.8317 - mae: 2.0874 - val_loss: 7.0597 - val_mse: 7.0597 - val_mae: 2.1176\n",
            "Epoch 38/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7162 - mse: 6.7162 - mae: 2.0726 - val_loss: 7.0602 - val_mse: 7.0602 - val_mae: 2.1177\n",
            "Epoch 39/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9951 - mse: 6.9951 - mae: 2.0987 - val_loss: 7.0615 - val_mse: 7.0615 - val_mae: 2.1180\n",
            "Epoch 40/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7595 - mse: 6.7595 - mae: 2.0635 - val_loss: 7.0620 - val_mse: 7.0620 - val_mae: 2.1181\n",
            "Epoch 41/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7070 - mse: 6.7070 - mae: 2.0519 - val_loss: 7.0632 - val_mse: 7.0632 - val_mae: 2.1183\n",
            "Epoch 42/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9530 - mse: 6.9530 - mae: 2.1168 - val_loss: 7.0610 - val_mse: 7.0610 - val_mae: 2.1179\n",
            "Epoch 43/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8286 - mse: 6.8286 - mae: 2.0819 - val_loss: 7.0626 - val_mse: 7.0626 - val_mae: 2.1182\n",
            "Epoch 44/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6429 - mse: 6.6429 - mae: 2.0587 - val_loss: 7.0627 - val_mse: 7.0627 - val_mae: 2.1182\n",
            "Epoch 45/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8471 - mse: 6.8471 - mae: 2.0860 - val_loss: 7.0627 - val_mse: 7.0627 - val_mae: 2.1182\n",
            "Epoch 46/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7842 - mse: 6.7842 - mae: 2.0795 - val_loss: 7.0628 - val_mse: 7.0628 - val_mae: 2.1183\n",
            "Epoch 47/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8711 - mse: 6.8711 - mae: 2.1018 - val_loss: 7.0635 - val_mse: 7.0635 - val_mae: 2.1184\n",
            "Epoch 48/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7921 - mse: 6.7921 - mae: 2.0778 - val_loss: 7.0645 - val_mse: 7.0645 - val_mae: 2.1186\n",
            "Epoch 49/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6407 - mse: 6.6407 - mae: 2.0652 - val_loss: 7.0646 - val_mse: 7.0646 - val_mae: 2.1186\n",
            "Epoch 50/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6997 - mse: 6.6997 - mae: 2.0712 - val_loss: 7.0638 - val_mse: 7.0638 - val_mae: 2.1185\n",
            "Epoch 51/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7741 - mse: 6.7741 - mae: 2.0714 - val_loss: 7.0641 - val_mse: 7.0641 - val_mae: 2.1185\n",
            "Epoch 52/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7342 - mse: 6.7342 - mae: 2.0745 - val_loss: 7.0631 - val_mse: 7.0631 - val_mae: 2.1184\n",
            "Epoch 53/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7864 - mse: 6.7864 - mae: 2.0711 - val_loss: 7.0635 - val_mse: 7.0635 - val_mae: 2.1185\n",
            "Epoch 54/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8951 - mse: 6.8951 - mae: 2.0954 - val_loss: 7.0630 - val_mse: 7.0630 - val_mae: 2.1183\n",
            "Epoch 55/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7902 - mse: 6.7902 - mae: 2.0647 - val_loss: 7.0618 - val_mse: 7.0618 - val_mae: 2.1181\n",
            "Epoch 56/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8345 - mse: 6.8345 - mae: 2.0868 - val_loss: 7.0610 - val_mse: 7.0610 - val_mae: 2.1180\n",
            "Epoch 57/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7986 - mse: 6.7986 - mae: 2.0812 - val_loss: 7.0628 - val_mse: 7.0628 - val_mae: 2.1183\n",
            "Epoch 58/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7473 - mse: 6.7473 - mae: 2.0715 - val_loss: 7.0637 - val_mse: 7.0637 - val_mae: 2.1185\n",
            "Epoch 59/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8824 - mse: 6.8824 - mae: 2.0930 - val_loss: 7.0645 - val_mse: 7.0645 - val_mae: 2.1187\n",
            "Epoch 60/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7475 - mse: 6.7475 - mae: 2.0683 - val_loss: 7.0651 - val_mse: 7.0651 - val_mae: 2.1187\n",
            "Epoch 61/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9436 - mse: 6.9436 - mae: 2.1088 - val_loss: 7.0654 - val_mse: 7.0654 - val_mae: 2.1188\n",
            "Epoch 62/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6916 - mse: 6.6916 - mae: 2.0722 - val_loss: 7.0661 - val_mse: 7.0661 - val_mae: 2.1189\n",
            "Epoch 63/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8143 - mse: 6.8143 - mae: 2.0856 - val_loss: 7.0662 - val_mse: 7.0662 - val_mae: 2.1189\n",
            "Epoch 64/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6111 - mse: 6.6111 - mae: 2.0564 - val_loss: 7.0653 - val_mse: 7.0653 - val_mae: 2.1188\n",
            "Epoch 65/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8888 - mse: 6.8888 - mae: 2.0964 - val_loss: 7.0663 - val_mse: 7.0663 - val_mae: 2.1189\n",
            "Epoch 66/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9508 - mse: 6.9508 - mae: 2.1146 - val_loss: 7.0661 - val_mse: 7.0661 - val_mae: 2.1189\n",
            "Epoch 67/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7144 - mse: 6.7144 - mae: 2.0851 - val_loss: 7.0676 - val_mse: 7.0676 - val_mae: 2.1192\n",
            "Epoch 68/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7414 - mse: 6.7414 - mae: 2.0737 - val_loss: 7.0685 - val_mse: 7.0685 - val_mae: 2.1193\n",
            "Epoch 69/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5404 - mse: 6.5404 - mae: 2.0390 - val_loss: 7.0679 - val_mse: 7.0679 - val_mae: 2.1192\n",
            "Epoch 70/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8315 - mse: 6.8315 - mae: 2.0868 - val_loss: 7.0679 - val_mse: 7.0679 - val_mae: 2.1192\n",
            "Epoch 71/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8485 - mse: 6.8485 - mae: 2.0864 - val_loss: 7.0677 - val_mse: 7.0677 - val_mae: 2.1192\n",
            "Epoch 72/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7852 - mse: 6.7852 - mae: 2.0803 - val_loss: 7.0680 - val_mse: 7.0680 - val_mae: 2.1193\n",
            "Epoch 73/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8770 - mse: 6.8770 - mae: 2.0897 - val_loss: 7.0672 - val_mse: 7.0672 - val_mae: 2.1192\n",
            "Epoch 74/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8685 - mse: 6.8685 - mae: 2.0867 - val_loss: 7.0666 - val_mse: 7.0666 - val_mae: 2.1190\n",
            "Epoch 75/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5750 - mse: 6.5750 - mae: 2.0340 - val_loss: 7.0675 - val_mse: 7.0675 - val_mae: 2.1192\n",
            "Epoch 76/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7019 - mse: 6.7019 - mae: 2.0718 - val_loss: 7.0678 - val_mse: 7.0678 - val_mae: 2.1193\n",
            "Epoch 77/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8400 - mse: 6.8400 - mae: 2.0772 - val_loss: 7.0681 - val_mse: 7.0681 - val_mae: 2.1193\n",
            "Epoch 78/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7302 - mse: 6.7302 - mae: 2.0618 - val_loss: 7.0679 - val_mse: 7.0679 - val_mae: 2.1193\n",
            "Epoch 79/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6874 - mse: 6.6874 - mae: 2.0631 - val_loss: 7.0685 - val_mse: 7.0685 - val_mae: 2.1194\n",
            "Epoch 80/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7996 - mse: 6.7996 - mae: 2.0752 - val_loss: 7.0688 - val_mse: 7.0688 - val_mae: 2.1194\n",
            "Epoch 81/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6089 - mse: 6.6089 - mae: 2.0501 - val_loss: 7.0695 - val_mse: 7.0695 - val_mae: 2.1196\n",
            "Epoch 82/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8547 - mse: 6.8547 - mae: 2.0812 - val_loss: 7.0701 - val_mse: 7.0701 - val_mae: 2.1197\n",
            "Epoch 83/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8478 - mse: 6.8478 - mae: 2.0939 - val_loss: 7.0689 - val_mse: 7.0689 - val_mae: 2.1195\n",
            "Epoch 84/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7892 - mse: 6.7892 - mae: 2.0833 - val_loss: 7.0690 - val_mse: 7.0690 - val_mae: 2.1195\n",
            "Epoch 85/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7848 - mse: 6.7848 - mae: 2.0800 - val_loss: 7.0692 - val_mse: 7.0692 - val_mae: 2.1195\n",
            "Epoch 86/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5860 - mse: 6.5860 - mae: 2.0475 - val_loss: 7.0698 - val_mse: 7.0698 - val_mae: 2.1196\n",
            "Epoch 87/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7752 - mse: 6.7752 - mae: 2.0813 - val_loss: 7.0703 - val_mse: 7.0703 - val_mae: 2.1197\n",
            "Epoch 88/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6665 - mse: 6.6665 - mae: 2.0671 - val_loss: 7.0705 - val_mse: 7.0705 - val_mae: 2.1198\n",
            "Epoch 89/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7667 - mse: 6.7667 - mae: 2.0923 - val_loss: 7.0696 - val_mse: 7.0696 - val_mae: 2.1196\n",
            "Epoch 90/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8932 - mse: 6.8932 - mae: 2.0876 - val_loss: 7.0698 - val_mse: 7.0698 - val_mae: 2.1196\n",
            "Epoch 91/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7685 - mse: 6.7685 - mae: 2.0720 - val_loss: 7.0710 - val_mse: 7.0710 - val_mae: 2.1198\n",
            "Epoch 92/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9458 - mse: 6.9458 - mae: 2.1047 - val_loss: 7.0699 - val_mse: 7.0699 - val_mae: 2.1196\n",
            "Epoch 93/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7975 - mse: 6.7975 - mae: 2.0770 - val_loss: 7.0701 - val_mse: 7.0701 - val_mae: 2.1197\n",
            "Epoch 94/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7670 - mse: 6.7670 - mae: 2.0688 - val_loss: 7.0694 - val_mse: 7.0694 - val_mae: 2.1196\n",
            "Epoch 95/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8093 - mse: 6.8093 - mae: 2.0801 - val_loss: 7.0700 - val_mse: 7.0700 - val_mae: 2.1197\n",
            "Epoch 96/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7468 - mse: 6.7468 - mae: 2.0691 - val_loss: 7.0706 - val_mse: 7.0706 - val_mae: 2.1198\n",
            "Epoch 97/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7951 - mse: 6.7951 - mae: 2.0752 - val_loss: 7.0715 - val_mse: 7.0715 - val_mae: 2.1199\n",
            "Epoch 98/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8545 - mse: 6.8545 - mae: 2.0922 - val_loss: 7.0715 - val_mse: 7.0715 - val_mae: 2.1199\n",
            "Epoch 99/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8725 - mse: 6.8725 - mae: 2.0876 - val_loss: 7.0712 - val_mse: 7.0712 - val_mae: 2.1199\n",
            "Epoch 100/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6607 - mse: 6.6607 - mae: 2.0581 - val_loss: 7.0712 - val_mse: 7.0712 - val_mae: 2.1199\n",
            "Epoch 101/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6464 - mse: 6.6464 - mae: 2.0661 - val_loss: 7.0719 - val_mse: 7.0719 - val_mae: 2.1200\n",
            "Epoch 102/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6128 - mse: 6.6128 - mae: 2.0478 - val_loss: 7.0721 - val_mse: 7.0721 - val_mae: 2.1200\n",
            "Epoch 103/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7791 - mse: 6.7791 - mae: 2.0671 - val_loss: 7.0717 - val_mse: 7.0717 - val_mae: 2.1200\n",
            "Epoch 104/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8597 - mse: 6.8597 - mae: 2.0877 - val_loss: 7.0721 - val_mse: 7.0721 - val_mae: 2.1200\n",
            "Epoch 105/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7710 - mse: 6.7710 - mae: 2.0762 - val_loss: 7.0724 - val_mse: 7.0724 - val_mae: 2.1201\n",
            "Epoch 106/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8762 - mse: 6.8762 - mae: 2.0908 - val_loss: 7.0720 - val_mse: 7.0720 - val_mae: 2.1200\n",
            "Epoch 107/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8644 - mse: 6.8644 - mae: 2.0964 - val_loss: 7.0724 - val_mse: 7.0724 - val_mae: 2.1200\n",
            "Epoch 108/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6757 - mse: 6.6757 - mae: 2.0582 - val_loss: 7.0722 - val_mse: 7.0722 - val_mae: 2.1200\n",
            "Epoch 109/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8006 - mse: 6.8006 - mae: 2.0776 - val_loss: 7.0719 - val_mse: 7.0719 - val_mae: 2.1200\n",
            "Epoch 110/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9245 - mse: 6.9245 - mae: 2.0945 - val_loss: 7.0711 - val_mse: 7.0711 - val_mae: 2.1198\n",
            "Epoch 111/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8404 - mse: 6.8404 - mae: 2.0730 - val_loss: 7.0718 - val_mse: 7.0718 - val_mae: 2.1200\n",
            "Epoch 112/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6803 - mse: 6.6803 - mae: 2.0617 - val_loss: 7.0728 - val_mse: 7.0728 - val_mae: 2.1201\n",
            "Epoch 113/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8606 - mse: 6.8606 - mae: 2.0864 - val_loss: 7.0730 - val_mse: 7.0730 - val_mae: 2.1202\n",
            "Epoch 114/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6035 - mse: 6.6035 - mae: 2.0413 - val_loss: 7.0727 - val_mse: 7.0727 - val_mae: 2.1202\n",
            "Epoch 115/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8175 - mse: 6.8175 - mae: 2.0755 - val_loss: 7.0724 - val_mse: 7.0724 - val_mae: 2.1201\n",
            "Epoch 116/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7104 - mse: 6.7104 - mae: 2.0674 - val_loss: 7.0726 - val_mse: 7.0726 - val_mae: 2.1201\n",
            "Epoch 117/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7551 - mse: 6.7551 - mae: 2.0779 - val_loss: 7.0727 - val_mse: 7.0727 - val_mae: 2.1201\n",
            "Epoch 118/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8371 - mse: 6.8371 - mae: 2.0812 - val_loss: 7.0723 - val_mse: 7.0723 - val_mae: 2.1201\n",
            "Epoch 119/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7470 - mse: 6.7470 - mae: 2.0746 - val_loss: 7.0729 - val_mse: 7.0729 - val_mae: 2.1202\n",
            "Epoch 120/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8677 - mse: 6.8677 - mae: 2.0859 - val_loss: 7.0730 - val_mse: 7.0730 - val_mae: 2.1203\n",
            "Epoch 121/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7764 - mse: 6.7764 - mae: 2.0670 - val_loss: 7.0739 - val_mse: 7.0739 - val_mae: 2.1204\n",
            "Epoch 122/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8045 - mse: 6.8045 - mae: 2.0781 - val_loss: 7.0737 - val_mse: 7.0737 - val_mae: 2.1204\n",
            "Epoch 123/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7689 - mse: 6.7689 - mae: 2.0737 - val_loss: 7.0735 - val_mse: 7.0735 - val_mae: 2.1204\n",
            "Epoch 124/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7669 - mse: 6.7669 - mae: 2.0700 - val_loss: 7.0735 - val_mse: 7.0735 - val_mae: 2.1204\n",
            "Epoch 125/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9031 - mse: 6.9031 - mae: 2.0900 - val_loss: 7.0736 - val_mse: 7.0736 - val_mae: 2.1204\n",
            "Epoch 126/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7078 - mse: 6.7078 - mae: 2.0687 - val_loss: 7.0725 - val_mse: 7.0725 - val_mae: 2.1202\n",
            "Epoch 127/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6582 - mse: 6.6582 - mae: 2.0564 - val_loss: 7.0721 - val_mse: 7.0721 - val_mae: 2.1202\n",
            "Epoch 128/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8353 - mse: 6.8353 - mae: 2.0875 - val_loss: 7.0728 - val_mse: 7.0728 - val_mae: 2.1203\n",
            "Epoch 129/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8777 - mse: 6.8777 - mae: 2.0822 - val_loss: 7.0728 - val_mse: 7.0728 - val_mae: 2.1203\n",
            "Epoch 130/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7623 - mse: 6.7623 - mae: 2.0738 - val_loss: 7.0726 - val_mse: 7.0726 - val_mae: 2.1203\n",
            "Epoch 131/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8733 - mse: 6.8733 - mae: 2.0830 - val_loss: 7.0714 - val_mse: 7.0714 - val_mae: 2.1200\n",
            "Epoch 132/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5215 - mse: 6.5215 - mae: 2.0491 - val_loss: 7.0707 - val_mse: 7.0707 - val_mae: 2.1199\n",
            "Epoch 133/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7295 - mse: 6.7295 - mae: 2.0663 - val_loss: 7.0704 - val_mse: 7.0704 - val_mae: 2.1199\n",
            "Epoch 134/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6496 - mse: 6.6496 - mae: 2.0570 - val_loss: 7.0707 - val_mse: 7.0707 - val_mae: 2.1199\n",
            "Epoch 135/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6639 - mse: 6.6639 - mae: 2.0558 - val_loss: 7.0717 - val_mse: 7.0717 - val_mae: 2.1201\n",
            "Epoch 136/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8126 - mse: 6.8126 - mae: 2.0663 - val_loss: 7.0714 - val_mse: 7.0714 - val_mae: 2.1200\n",
            "Epoch 137/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8045 - mse: 6.8045 - mae: 2.0756 - val_loss: 7.0721 - val_mse: 7.0721 - val_mae: 2.1202\n",
            "Epoch 138/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7823 - mse: 6.7823 - mae: 2.0844 - val_loss: 7.0714 - val_mse: 7.0714 - val_mae: 2.1200\n",
            "Epoch 139/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9006 - mse: 6.9006 - mae: 2.0943 - val_loss: 7.0713 - val_mse: 7.0713 - val_mae: 2.1200\n",
            "Epoch 140/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6204 - mse: 6.6204 - mae: 2.0457 - val_loss: 7.0720 - val_mse: 7.0720 - val_mae: 2.1202\n",
            "Epoch 141/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7748 - mse: 6.7748 - mae: 2.0821 - val_loss: 7.0720 - val_mse: 7.0720 - val_mae: 2.1202\n",
            "Epoch 142/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6888 - mse: 6.6888 - mae: 2.0640 - val_loss: 7.0721 - val_mse: 7.0721 - val_mae: 2.1202\n",
            "Epoch 143/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8129 - mse: 6.8129 - mae: 2.0771 - val_loss: 7.0728 - val_mse: 7.0728 - val_mae: 2.1203\n",
            "Epoch 144/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9145 - mse: 6.9145 - mae: 2.0941 - val_loss: 7.0726 - val_mse: 7.0726 - val_mae: 2.1203\n",
            "Epoch 145/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7511 - mse: 6.7511 - mae: 2.0759 - val_loss: 7.0727 - val_mse: 7.0727 - val_mae: 2.1203\n",
            "Epoch 146/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7588 - mse: 6.7588 - mae: 2.0763 - val_loss: 7.0729 - val_mse: 7.0729 - val_mae: 2.1203\n",
            "Epoch 147/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9287 - mse: 6.9287 - mae: 2.1057 - val_loss: 7.0734 - val_mse: 7.0734 - val_mae: 2.1204\n",
            "Epoch 148/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5956 - mse: 6.5956 - mae: 2.0495 - val_loss: 7.0735 - val_mse: 7.0735 - val_mae: 2.1204\n",
            "Epoch 149/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7580 - mse: 6.7580 - mae: 2.0839 - val_loss: 7.0733 - val_mse: 7.0733 - val_mae: 2.1204\n",
            "Epoch 150/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9432 - mse: 6.9432 - mae: 2.1036 - val_loss: 7.0726 - val_mse: 7.0726 - val_mae: 2.1203\n",
            "Epoch 151/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7456 - mse: 6.7456 - mae: 2.0690 - val_loss: 7.0728 - val_mse: 7.0728 - val_mae: 2.1203\n",
            "Epoch 152/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6871 - mse: 6.6871 - mae: 2.0605 - val_loss: 7.0724 - val_mse: 7.0724 - val_mae: 2.1203\n",
            "Epoch 153/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7064 - mse: 6.7064 - mae: 2.0747 - val_loss: 7.0716 - val_mse: 7.0716 - val_mae: 2.1202\n",
            "Epoch 154/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7320 - mse: 6.7320 - mae: 2.0738 - val_loss: 7.0713 - val_mse: 7.0713 - val_mae: 2.1201\n",
            "Epoch 155/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6994 - mse: 6.6994 - mae: 2.0649 - val_loss: 7.0719 - val_mse: 7.0719 - val_mae: 2.1202\n",
            "Epoch 156/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7706 - mse: 6.7706 - mae: 2.0862 - val_loss: 7.0719 - val_mse: 7.0719 - val_mae: 2.1202\n",
            "Epoch 157/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7906 - mse: 6.7906 - mae: 2.0892 - val_loss: 7.0721 - val_mse: 7.0721 - val_mae: 2.1202\n",
            "Epoch 158/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7497 - mse: 6.7497 - mae: 2.0697 - val_loss: 7.0717 - val_mse: 7.0717 - val_mae: 2.1201\n",
            "Epoch 159/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6911 - mse: 6.6911 - mae: 2.0641 - val_loss: 7.0718 - val_mse: 7.0718 - val_mae: 2.1201\n",
            "Epoch 160/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5731 - mse: 6.5731 - mae: 2.0506 - val_loss: 7.0718 - val_mse: 7.0718 - val_mae: 2.1202\n",
            "Epoch 161/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8512 - mse: 6.8512 - mae: 2.0875 - val_loss: 7.0724 - val_mse: 7.0724 - val_mae: 2.1203\n",
            "Epoch 162/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8298 - mse: 6.8298 - mae: 2.0936 - val_loss: 7.0726 - val_mse: 7.0726 - val_mae: 2.1203\n",
            "Epoch 163/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8145 - mse: 6.8145 - mae: 2.0815 - val_loss: 7.0726 - val_mse: 7.0726 - val_mae: 2.1203\n",
            "Epoch 164/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8845 - mse: 6.8845 - mae: 2.0897 - val_loss: 7.0732 - val_mse: 7.0732 - val_mae: 2.1204\n",
            "Epoch 165/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9399 - mse: 6.9399 - mae: 2.0985 - val_loss: 7.0734 - val_mse: 7.0734 - val_mae: 2.1204\n",
            "Epoch 166/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6717 - mse: 6.6717 - mae: 2.0542 - val_loss: 7.0733 - val_mse: 7.0733 - val_mae: 2.1204\n",
            "Epoch 167/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5916 - mse: 6.5916 - mae: 2.0480 - val_loss: 7.0729 - val_mse: 7.0729 - val_mae: 2.1204\n",
            "Epoch 168/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7650 - mse: 6.7650 - mae: 2.0818 - val_loss: 7.0738 - val_mse: 7.0738 - val_mae: 2.1205\n",
            "Epoch 169/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8339 - mse: 6.8339 - mae: 2.0870 - val_loss: 7.0741 - val_mse: 7.0741 - val_mae: 2.1206\n",
            "Epoch 170/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6870 - mse: 6.6870 - mae: 2.0611 - val_loss: 7.0741 - val_mse: 7.0741 - val_mae: 2.1206\n",
            "Epoch 171/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7662 - mse: 6.7662 - mae: 2.0754 - val_loss: 7.0739 - val_mse: 7.0739 - val_mae: 2.1205\n",
            "Epoch 172/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6843 - mse: 6.6843 - mae: 2.0480 - val_loss: 7.0740 - val_mse: 7.0740 - val_mae: 2.1205\n",
            "Epoch 173/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9222 - mse: 6.9222 - mae: 2.1027 - val_loss: 7.0738 - val_mse: 7.0738 - val_mae: 2.1205\n",
            "Epoch 174/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7703 - mse: 6.7703 - mae: 2.0822 - val_loss: 7.0741 - val_mse: 7.0741 - val_mae: 2.1205\n",
            "Epoch 175/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0269 - mse: 7.0269 - mae: 2.1195 - val_loss: 7.0741 - val_mse: 7.0741 - val_mae: 2.1206\n",
            "Epoch 176/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6822 - mse: 6.6822 - mae: 2.0660 - val_loss: 7.0740 - val_mse: 7.0740 - val_mae: 2.1205\n",
            "Epoch 177/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9218 - mse: 6.9218 - mae: 2.0861 - val_loss: 7.0734 - val_mse: 7.0734 - val_mae: 2.1204\n",
            "Epoch 178/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7242 - mse: 6.7242 - mae: 2.0714 - val_loss: 7.0724 - val_mse: 7.0724 - val_mae: 2.1203\n",
            "Epoch 179/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8681 - mse: 6.8681 - mae: 2.0982 - val_loss: 7.0727 - val_mse: 7.0727 - val_mae: 2.1203\n",
            "Epoch 180/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8492 - mse: 6.8492 - mae: 2.0866 - val_loss: 7.0740 - val_mse: 7.0740 - val_mae: 2.1205\n",
            "Epoch 181/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8529 - mse: 6.8529 - mae: 2.0871 - val_loss: 7.0739 - val_mse: 7.0739 - val_mae: 2.1205\n",
            "Epoch 182/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8591 - mse: 6.8591 - mae: 2.0834 - val_loss: 7.0744 - val_mse: 7.0744 - val_mae: 2.1206\n",
            "Epoch 183/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7498 - mse: 6.7498 - mae: 2.0765 - val_loss: 7.0744 - val_mse: 7.0744 - val_mae: 2.1206\n",
            "Epoch 184/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7536 - mse: 6.7536 - mae: 2.0762 - val_loss: 7.0748 - val_mse: 7.0748 - val_mae: 2.1206\n",
            "Epoch 185/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7365 - mse: 6.7365 - mae: 2.0696 - val_loss: 7.0746 - val_mse: 7.0746 - val_mae: 2.1206\n",
            "Epoch 186/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7773 - mse: 6.7773 - mae: 2.0677 - val_loss: 7.0742 - val_mse: 7.0742 - val_mae: 2.1205\n",
            "Epoch 187/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7897 - mse: 6.7897 - mae: 2.0787 - val_loss: 7.0750 - val_mse: 7.0750 - val_mae: 2.1206\n",
            "Epoch 188/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8920 - mse: 6.8920 - mae: 2.0929 - val_loss: 7.0746 - val_mse: 7.0746 - val_mae: 2.1206\n",
            "Epoch 189/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8166 - mse: 6.8166 - mae: 2.0857 - val_loss: 7.0743 - val_mse: 7.0743 - val_mae: 2.1205\n",
            "Epoch 190/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6936 - mse: 6.6936 - mae: 2.0623 - val_loss: 7.0745 - val_mse: 7.0745 - val_mae: 2.1206\n",
            "Epoch 191/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8443 - mse: 6.8443 - mae: 2.0861 - val_loss: 7.0741 - val_mse: 7.0741 - val_mae: 2.1205\n",
            "Epoch 192/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6055 - mse: 6.6055 - mae: 2.0396 - val_loss: 7.0748 - val_mse: 7.0748 - val_mae: 2.1206\n",
            "Epoch 193/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6652 - mse: 6.6652 - mae: 2.0557 - val_loss: 7.0756 - val_mse: 7.0756 - val_mae: 2.1207\n",
            "Epoch 194/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8591 - mse: 6.8591 - mae: 2.1024 - val_loss: 7.0759 - val_mse: 7.0759 - val_mae: 2.1207\n",
            "Epoch 195/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8318 - mse: 6.8318 - mae: 2.0853 - val_loss: 7.0753 - val_mse: 7.0753 - val_mae: 2.1207\n",
            "Epoch 196/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8060 - mse: 6.8060 - mae: 2.0788 - val_loss: 7.0752 - val_mse: 7.0752 - val_mae: 2.1207\n",
            "Epoch 197/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8184 - mse: 6.8184 - mae: 2.0825 - val_loss: 7.0757 - val_mse: 7.0757 - val_mae: 2.1207\n",
            "Epoch 198/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8328 - mse: 6.8328 - mae: 2.0802 - val_loss: 7.0756 - val_mse: 7.0756 - val_mae: 2.1207\n",
            "Epoch 199/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7373 - mse: 6.7373 - mae: 2.0684 - val_loss: 7.0750 - val_mse: 7.0750 - val_mae: 2.1206\n",
            "Epoch 200/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6401 - mse: 6.6401 - mae: 2.0526 - val_loss: 7.0749 - val_mse: 7.0749 - val_mae: 2.1206\n",
            "Epoch 201/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6780 - mse: 6.6780 - mae: 2.0635 - val_loss: 7.0746 - val_mse: 7.0746 - val_mae: 2.1205\n",
            "Epoch 202/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7447 - mse: 6.7447 - mae: 2.0629 - val_loss: 7.0756 - val_mse: 7.0756 - val_mae: 2.1207\n",
            "Epoch 203/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8605 - mse: 6.8605 - mae: 2.0779 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 204/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9386 - mse: 6.9386 - mae: 2.1052 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 205/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8641 - mse: 6.8641 - mae: 2.0876 - val_loss: 7.0758 - val_mse: 7.0758 - val_mae: 2.1207\n",
            "Epoch 206/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6240 - mse: 6.6240 - mae: 2.0469 - val_loss: 7.0754 - val_mse: 7.0754 - val_mae: 2.1207\n",
            "Epoch 207/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7791 - mse: 6.7791 - mae: 2.0882 - val_loss: 7.0758 - val_mse: 7.0758 - val_mae: 2.1208\n",
            "Epoch 208/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8317 - mse: 6.8317 - mae: 2.0770 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1209\n",
            "Epoch 209/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7468 - mse: 6.7468 - mae: 2.0789 - val_loss: 7.0763 - val_mse: 7.0763 - val_mae: 2.1209\n",
            "Epoch 210/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7885 - mse: 6.7885 - mae: 2.0870 - val_loss: 7.0763 - val_mse: 7.0763 - val_mae: 2.1209\n",
            "Epoch 211/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8112 - mse: 6.8112 - mae: 2.0793 - val_loss: 7.0758 - val_mse: 7.0758 - val_mae: 2.1208\n",
            "Epoch 212/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7061 - mse: 6.7061 - mae: 2.0574 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 213/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6451 - mse: 6.6451 - mae: 2.0657 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 214/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7380 - mse: 6.7380 - mae: 2.0596 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1209\n",
            "Epoch 215/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7826 - mse: 6.7826 - mae: 2.0769 - val_loss: 7.0768 - val_mse: 7.0768 - val_mae: 2.1209\n",
            "Epoch 216/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7059 - mse: 6.7059 - mae: 2.0661 - val_loss: 7.0772 - val_mse: 7.0772 - val_mae: 2.1210\n",
            "Epoch 217/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8577 - mse: 6.8577 - mae: 2.0818 - val_loss: 7.0770 - val_mse: 7.0770 - val_mae: 2.1209\n",
            "Epoch 218/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5843 - mse: 6.5843 - mae: 2.0488 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1209\n",
            "Epoch 219/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7960 - mse: 6.7960 - mae: 2.0721 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1208\n",
            "Epoch 220/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8177 - mse: 6.8177 - mae: 2.0772 - val_loss: 7.0763 - val_mse: 7.0763 - val_mae: 2.1208\n",
            "Epoch 221/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9123 - mse: 6.9123 - mae: 2.0961 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1208\n",
            "Epoch 222/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0331 - mse: 7.0331 - mae: 2.1214 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 223/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9265 - mse: 6.9265 - mae: 2.1026 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 224/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5082 - mse: 6.5082 - mae: 2.0337 - val_loss: 7.0756 - val_mse: 7.0756 - val_mae: 2.1207\n",
            "Epoch 225/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6460 - mse: 6.6460 - mae: 2.0522 - val_loss: 7.0756 - val_mse: 7.0756 - val_mae: 2.1207\n",
            "Epoch 226/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8376 - mse: 6.8376 - mae: 2.0738 - val_loss: 7.0753 - val_mse: 7.0753 - val_mae: 2.1207\n",
            "Epoch 227/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9205 - mse: 6.9205 - mae: 2.1004 - val_loss: 7.0755 - val_mse: 7.0755 - val_mae: 2.1207\n",
            "Epoch 228/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7522 - mse: 6.7522 - mae: 2.0699 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 229/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7080 - mse: 6.7080 - mae: 2.0532 - val_loss: 7.0758 - val_mse: 7.0758 - val_mae: 2.1208\n",
            "Epoch 230/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7791 - mse: 6.7791 - mae: 2.0746 - val_loss: 7.0763 - val_mse: 7.0763 - val_mae: 2.1208\n",
            "Epoch 231/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8235 - mse: 6.8235 - mae: 2.0852 - val_loss: 7.0759 - val_mse: 7.0759 - val_mae: 2.1207\n",
            "Epoch 232/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8906 - mse: 6.8906 - mae: 2.0882 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1207\n",
            "Epoch 233/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6462 - mse: 6.6462 - mae: 2.0578 - val_loss: 7.0758 - val_mse: 7.0758 - val_mae: 2.1207\n",
            "Epoch 234/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9515 - mse: 6.9515 - mae: 2.0985 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 235/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7815 - mse: 6.7815 - mae: 2.0812 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 236/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5798 - mse: 6.5798 - mae: 2.0459 - val_loss: 7.0763 - val_mse: 7.0763 - val_mae: 2.1208\n",
            "Epoch 237/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6723 - mse: 6.6723 - mae: 2.0727 - val_loss: 7.0759 - val_mse: 7.0759 - val_mae: 2.1207\n",
            "Epoch 238/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8857 - mse: 6.8857 - mae: 2.0972 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 239/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8617 - mse: 6.8617 - mae: 2.0712 - val_loss: 7.0757 - val_mse: 7.0757 - val_mae: 2.1207\n",
            "Epoch 240/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8030 - mse: 6.8030 - mae: 2.0753 - val_loss: 7.0759 - val_mse: 7.0759 - val_mae: 2.1207\n",
            "Epoch 241/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7614 - mse: 6.7614 - mae: 2.0784 - val_loss: 7.0757 - val_mse: 7.0757 - val_mae: 2.1207\n",
            "Epoch 242/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6885 - mse: 6.6885 - mae: 2.0601 - val_loss: 7.0757 - val_mse: 7.0757 - val_mae: 2.1207\n",
            "Epoch 243/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7715 - mse: 6.7715 - mae: 2.0756 - val_loss: 7.0755 - val_mse: 7.0755 - val_mae: 2.1207\n",
            "Epoch 244/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6061 - mse: 6.6061 - mae: 2.0459 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 245/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6189 - mse: 6.6189 - mae: 2.0482 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 246/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9659 - mse: 6.9659 - mae: 2.1102 - val_loss: 7.0759 - val_mse: 7.0759 - val_mae: 2.1208\n",
            "Epoch 247/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8262 - mse: 6.8262 - mae: 2.0845 - val_loss: 7.0765 - val_mse: 7.0765 - val_mae: 2.1209\n",
            "Epoch 248/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7122 - mse: 6.7122 - mae: 2.0511 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 249/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8134 - mse: 6.8134 - mae: 2.0811 - val_loss: 7.0768 - val_mse: 7.0768 - val_mae: 2.1209\n",
            "Epoch 250/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8745 - mse: 6.8745 - mae: 2.0947 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 251/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6628 - mse: 6.6628 - mae: 2.0572 - val_loss: 7.0765 - val_mse: 7.0765 - val_mae: 2.1209\n",
            "Epoch 252/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6870 - mse: 6.6870 - mae: 2.0614 - val_loss: 7.0774 - val_mse: 7.0774 - val_mae: 2.1210\n",
            "Epoch 253/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9658 - mse: 6.9658 - mae: 2.0972 - val_loss: 7.0768 - val_mse: 7.0768 - val_mae: 2.1210\n",
            "Epoch 254/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8184 - mse: 6.8184 - mae: 2.0853 - val_loss: 7.0764 - val_mse: 7.0764 - val_mae: 2.1209\n",
            "Epoch 255/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9202 - mse: 6.9202 - mae: 2.1050 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 256/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5919 - mse: 6.5919 - mae: 2.0536 - val_loss: 7.0764 - val_mse: 7.0764 - val_mae: 2.1209\n",
            "Epoch 257/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9200 - mse: 6.9200 - mae: 2.1012 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 258/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7354 - mse: 6.7354 - mae: 2.0695 - val_loss: 7.0763 - val_mse: 7.0763 - val_mae: 2.1209\n",
            "Epoch 259/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7176 - mse: 6.7176 - mae: 2.0661 - val_loss: 7.0765 - val_mse: 7.0765 - val_mae: 2.1209\n",
            "Epoch 260/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7398 - mse: 6.7398 - mae: 2.0711 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1209\n",
            "Epoch 261/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6463 - mse: 6.6463 - mae: 2.0561 - val_loss: 7.0764 - val_mse: 7.0764 - val_mae: 2.1209\n",
            "Epoch 262/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7574 - mse: 6.7574 - mae: 2.0742 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1209\n",
            "Epoch 263/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6504 - mse: 6.6504 - mae: 2.0433 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 264/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7875 - mse: 6.7875 - mae: 2.0803 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 265/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8092 - mse: 6.8092 - mae: 2.0807 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 266/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7147 - mse: 6.7147 - mae: 2.0810 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1209\n",
            "Epoch 267/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8245 - mse: 6.8245 - mae: 2.0966 - val_loss: 7.0765 - val_mse: 7.0765 - val_mae: 2.1209\n",
            "Epoch 268/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8540 - mse: 6.8540 - mae: 2.0892 - val_loss: 7.0764 - val_mse: 7.0764 - val_mae: 2.1209\n",
            "Epoch 269/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7340 - mse: 6.7340 - mae: 2.0717 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 270/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9517 - mse: 6.9517 - mae: 2.1109 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 271/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7496 - mse: 6.7496 - mae: 2.0760 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 272/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8663 - mse: 6.8663 - mae: 2.0915 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 273/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9668 - mse: 6.9668 - mae: 2.1015 - val_loss: 7.0760 - val_mse: 7.0760 - val_mae: 2.1208\n",
            "Epoch 274/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9568 - mse: 6.9568 - mae: 2.1003 - val_loss: 7.0764 - val_mse: 7.0764 - val_mae: 2.1208\n",
            "Epoch 275/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9586 - mse: 6.9586 - mae: 2.1124 - val_loss: 7.0765 - val_mse: 7.0765 - val_mae: 2.1209\n",
            "Epoch 276/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8224 - mse: 6.8224 - mae: 2.0857 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 277/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7872 - mse: 6.7872 - mae: 2.0794 - val_loss: 7.0769 - val_mse: 7.0769 - val_mae: 2.1209\n",
            "Epoch 278/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5983 - mse: 6.5983 - mae: 2.0551 - val_loss: 7.0772 - val_mse: 7.0772 - val_mae: 2.1209\n",
            "Epoch 279/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6341 - mse: 6.6341 - mae: 2.0623 - val_loss: 7.0774 - val_mse: 7.0774 - val_mae: 2.1210\n",
            "Epoch 280/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7492 - mse: 6.7492 - mae: 2.0735 - val_loss: 7.0771 - val_mse: 7.0771 - val_mae: 2.1209\n",
            "Epoch 281/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7550 - mse: 6.7550 - mae: 2.0835 - val_loss: 7.0765 - val_mse: 7.0765 - val_mae: 2.1208\n",
            "Epoch 282/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7491 - mse: 6.7491 - mae: 2.0715 - val_loss: 7.0766 - val_mse: 7.0766 - val_mae: 2.1209\n",
            "Epoch 283/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7433 - mse: 6.7433 - mae: 2.0743 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 284/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7883 - mse: 6.7883 - mae: 2.0706 - val_loss: 7.0767 - val_mse: 7.0767 - val_mae: 2.1209\n",
            "Epoch 285/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6728 - mse: 6.6728 - mae: 2.0562 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 286/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6702 - mse: 6.6702 - mae: 2.0537 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 287/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8430 - mse: 6.8430 - mae: 2.0782 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 288/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7488 - mse: 6.7488 - mae: 2.0714 - val_loss: 7.0753 - val_mse: 7.0753 - val_mae: 2.1207\n",
            "Epoch 289/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6613 - mse: 6.6613 - mae: 2.0642 - val_loss: 7.0757 - val_mse: 7.0757 - val_mae: 2.1208\n",
            "Epoch 290/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8001 - mse: 6.8001 - mae: 2.0837 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 291/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6745 - mse: 6.6745 - mae: 2.0486 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 292/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7320 - mse: 6.7320 - mae: 2.0594 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 293/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9868 - mse: 6.9868 - mae: 2.1144 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 294/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7425 - mse: 6.7425 - mae: 2.0682 - val_loss: 7.0762 - val_mse: 7.0762 - val_mae: 2.1208\n",
            "Epoch 295/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6778 - mse: 6.6778 - mae: 2.0622 - val_loss: 7.0759 - val_mse: 7.0759 - val_mae: 2.1208\n",
            "Epoch 296/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8455 - mse: 6.8455 - mae: 2.0925 - val_loss: 7.0761 - val_mse: 7.0761 - val_mae: 2.1208\n",
            "Epoch 297/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8667 - mse: 6.8667 - mae: 2.0863 - val_loss: 7.0771 - val_mse: 7.0771 - val_mae: 2.1210\n",
            "Epoch 298/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7587 - mse: 6.7587 - mae: 2.0831 - val_loss: 7.0771 - val_mse: 7.0771 - val_mae: 2.1210\n",
            "Epoch 299/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0193 - mse: 7.0193 - mae: 2.1024 - val_loss: 7.0773 - val_mse: 7.0773 - val_mae: 2.1210\n",
            "Epoch 300/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7781 - mse: 6.7781 - mae: 2.0890 - val_loss: 7.0771 - val_mse: 7.0771 - val_mae: 2.1210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CT_22ABEscB",
        "outputId": "f09e3a6a-8c87-46a0-f601-5b9e31aa034f"
      },
      "source": [
        "model6 = Sequential()\n",
        "model6.add(Dense(32, input_dim=4, activation='relu'))\n",
        "model6.add(Dropout(0.1))\n",
        "model6.add(Dense(64, activation='relu'))\n",
        "model6.add(Dropout(0.2))\n",
        "model6.add(Dense(128, activation='relu'))\n",
        "model6.add(Dropout(0.2))\n",
        "model6.add(Dense(256, activation='relu'))\n",
        "model6.add(Dropout(0.3))\n",
        "model6.add(Dense(256, activation='relu'))\n",
        "model6.add(Dropout(0.2))\n",
        "model6.add(Dense(128, activation='relu'))\n",
        "model6.add(Dropout(0.1))\n",
        "model6.add(Dense(1, activation='linear'))\n",
        "\n",
        "model6.compile(optimizer='rmsprop', loss='mse', metrics=['mse', 'mae'])\n",
        "\n",
        "# training model\n",
        "history = model6.fit(x_train, y_train, epochs = 300,\n",
        "                        validation_data=(x_valid, y_valid),\n",
        "                        batch_size = 16, verbose = 1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "563/563 [==============================] - 4s 4ms/step - loss: 7.0653 - mse: 7.0653 - mae: 2.1176 - val_loss: 7.0334 - val_mse: 7.0334 - val_mae: 2.1134\n",
            "Epoch 2/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7373 - mse: 6.7373 - mae: 2.0689 - val_loss: 7.0618 - val_mse: 7.0618 - val_mae: 2.1185\n",
            "Epoch 3/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7998 - mse: 6.7998 - mae: 2.0790 - val_loss: 7.0601 - val_mse: 7.0601 - val_mae: 2.1179\n",
            "Epoch 4/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8409 - mse: 6.8409 - mae: 2.0995 - val_loss: 7.0556 - val_mse: 7.0556 - val_mae: 2.1172\n",
            "Epoch 5/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.9497 - mse: 6.9497 - mae: 2.1040 - val_loss: 7.0639 - val_mse: 7.0639 - val_mae: 2.1186\n",
            "Epoch 6/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8316 - mse: 6.8316 - mae: 2.0829 - val_loss: 7.0496 - val_mse: 7.0496 - val_mae: 2.1161\n",
            "Epoch 7/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6456 - mse: 6.6456 - mae: 2.0480 - val_loss: 7.0208 - val_mse: 7.0208 - val_mae: 2.1121\n",
            "Epoch 8/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6426 - mse: 6.6426 - mae: 2.0524 - val_loss: 7.0219 - val_mse: 7.0219 - val_mae: 2.1145\n",
            "Epoch 9/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8275 - mse: 6.8275 - mae: 2.0853 - val_loss: 7.0347 - val_mse: 7.0347 - val_mae: 2.1157\n",
            "Epoch 10/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7649 - mse: 6.7649 - mae: 2.0676 - val_loss: 7.0258 - val_mse: 7.0258 - val_mae: 2.1147\n",
            "Epoch 11/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6804 - mse: 6.6804 - mae: 2.0549 - val_loss: 7.0644 - val_mse: 7.0644 - val_mae: 2.1195\n",
            "Epoch 12/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9389 - mse: 6.9389 - mae: 2.0977 - val_loss: 7.0892 - val_mse: 7.0892 - val_mae: 2.1224\n",
            "Epoch 13/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7677 - mse: 6.7677 - mae: 2.0890 - val_loss: 7.0668 - val_mse: 7.0668 - val_mae: 2.1193\n",
            "Epoch 14/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6437 - mse: 6.6437 - mae: 2.0643 - val_loss: 7.0910 - val_mse: 7.0910 - val_mae: 2.1251\n",
            "Epoch 15/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7045 - mse: 6.7045 - mae: 2.0658 - val_loss: 7.0322 - val_mse: 7.0322 - val_mae: 2.1145\n",
            "Epoch 16/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6904 - mse: 6.6904 - mae: 2.0631 - val_loss: 7.0404 - val_mse: 7.0404 - val_mae: 2.1161\n",
            "Epoch 17/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8846 - mse: 6.8846 - mae: 2.0886 - val_loss: 7.0941 - val_mse: 7.0941 - val_mae: 2.1252\n",
            "Epoch 18/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7738 - mse: 6.7738 - mae: 2.0708 - val_loss: 7.0576 - val_mse: 7.0576 - val_mae: 2.1175\n",
            "Epoch 19/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9160 - mse: 6.9160 - mae: 2.0976 - val_loss: 7.0540 - val_mse: 7.0540 - val_mae: 2.1170\n",
            "Epoch 20/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7600 - mse: 6.7600 - mae: 2.0720 - val_loss: 7.0338 - val_mse: 7.0338 - val_mae: 2.1152\n",
            "Epoch 21/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8155 - mse: 6.8155 - mae: 2.0713 - val_loss: 7.0820 - val_mse: 7.0820 - val_mae: 2.1222\n",
            "Epoch 22/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7294 - mse: 6.7294 - mae: 2.0665 - val_loss: 7.0462 - val_mse: 7.0462 - val_mae: 2.1164\n",
            "Epoch 23/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8663 - mse: 6.8663 - mae: 2.0906 - val_loss: 7.0776 - val_mse: 7.0776 - val_mae: 2.1237\n",
            "Epoch 24/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8229 - mse: 6.8229 - mae: 2.0856 - val_loss: 7.0781 - val_mse: 7.0781 - val_mae: 2.1274\n",
            "Epoch 25/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 7.0301 - mse: 7.0301 - mae: 2.1066 - val_loss: 7.0932 - val_mse: 7.0932 - val_mae: 2.1272\n",
            "Epoch 26/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6009 - mse: 6.6009 - mae: 2.0530 - val_loss: 7.0943 - val_mse: 7.0943 - val_mae: 2.1275\n",
            "Epoch 27/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6793 - mse: 6.6793 - mae: 2.0552 - val_loss: 7.1317 - val_mse: 7.1317 - val_mae: 2.1370\n",
            "Epoch 28/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7563 - mse: 6.7563 - mae: 2.0659 - val_loss: 7.0713 - val_mse: 7.0713 - val_mae: 2.1224\n",
            "Epoch 29/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6354 - mse: 6.6354 - mae: 2.0551 - val_loss: 7.0731 - val_mse: 7.0731 - val_mae: 2.1225\n",
            "Epoch 30/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8924 - mse: 6.8924 - mae: 2.0867 - val_loss: 7.0996 - val_mse: 7.0996 - val_mae: 2.1258\n",
            "Epoch 31/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6507 - mse: 6.6507 - mae: 2.0560 - val_loss: 7.0830 - val_mse: 7.0830 - val_mae: 2.1246\n",
            "Epoch 32/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6375 - mse: 6.6375 - mae: 2.0439 - val_loss: 7.0857 - val_mse: 7.0857 - val_mae: 2.1227\n",
            "Epoch 33/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8862 - mse: 6.8862 - mae: 2.0939 - val_loss: 7.0885 - val_mse: 7.0885 - val_mae: 2.1238\n",
            "Epoch 34/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7923 - mse: 6.7923 - mae: 2.0805 - val_loss: 7.0911 - val_mse: 7.0911 - val_mae: 2.1225\n",
            "Epoch 35/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7874 - mse: 6.7874 - mae: 2.0842 - val_loss: 7.0756 - val_mse: 7.0756 - val_mae: 2.1230\n",
            "Epoch 36/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7018 - mse: 6.7018 - mae: 2.0632 - val_loss: 7.1058 - val_mse: 7.1058 - val_mae: 2.1251\n",
            "Epoch 37/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7950 - mse: 6.7950 - mae: 2.0831 - val_loss: 7.1080 - val_mse: 7.1080 - val_mae: 2.1280\n",
            "Epoch 38/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6666 - mse: 6.6666 - mae: 2.0635 - val_loss: 7.0912 - val_mse: 7.0912 - val_mae: 2.1246\n",
            "Epoch 39/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7489 - mse: 6.7489 - mae: 2.0609 - val_loss: 7.0900 - val_mse: 7.0900 - val_mae: 2.1272\n",
            "Epoch 40/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9022 - mse: 6.9022 - mae: 2.0922 - val_loss: 7.1718 - val_mse: 7.1718 - val_mae: 2.1358\n",
            "Epoch 41/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.8895 - mse: 6.8895 - mae: 2.0898 - val_loss: 7.0972 - val_mse: 7.0972 - val_mae: 2.1285\n",
            "Epoch 42/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6920 - mse: 6.6920 - mae: 2.0616 - val_loss: 7.1166 - val_mse: 7.1166 - val_mae: 2.1283\n",
            "Epoch 43/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6994 - mse: 6.6994 - mae: 2.0590 - val_loss: 7.1053 - val_mse: 7.1053 - val_mae: 2.1261\n",
            "Epoch 44/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7964 - mse: 6.7964 - mae: 2.0761 - val_loss: 7.1334 - val_mse: 7.1334 - val_mae: 2.1305\n",
            "Epoch 45/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6018 - mse: 6.6018 - mae: 2.0559 - val_loss: 7.1138 - val_mse: 7.1138 - val_mae: 2.1264\n",
            "Epoch 46/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6618 - mse: 6.6618 - mae: 2.0551 - val_loss: 7.0904 - val_mse: 7.0904 - val_mae: 2.1241\n",
            "Epoch 47/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7718 - mse: 6.7718 - mae: 2.0679 - val_loss: 7.1033 - val_mse: 7.1033 - val_mae: 2.1263\n",
            "Epoch 48/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8103 - mse: 6.8103 - mae: 2.0758 - val_loss: 7.0949 - val_mse: 7.0949 - val_mae: 2.1242\n",
            "Epoch 49/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 7.0025 - mse: 7.0025 - mae: 2.0998 - val_loss: 7.0852 - val_mse: 7.0852 - val_mae: 2.1236\n",
            "Epoch 50/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8264 - mse: 6.8264 - mae: 2.0740 - val_loss: 7.1037 - val_mse: 7.1037 - val_mae: 2.1248\n",
            "Epoch 51/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7625 - mse: 6.7625 - mae: 2.0684 - val_loss: 7.1399 - val_mse: 7.1399 - val_mae: 2.1294\n",
            "Epoch 52/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7520 - mse: 6.7520 - mae: 2.0656 - val_loss: 7.1608 - val_mse: 7.1608 - val_mae: 2.1303\n",
            "Epoch 53/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7708 - mse: 6.7708 - mae: 2.0728 - val_loss: 7.1048 - val_mse: 7.1048 - val_mae: 2.1241\n",
            "Epoch 54/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7735 - mse: 6.7735 - mae: 2.0787 - val_loss: 7.1613 - val_mse: 7.1613 - val_mae: 2.1327\n",
            "Epoch 55/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7323 - mse: 6.7323 - mae: 2.0667 - val_loss: 7.1384 - val_mse: 7.1384 - val_mae: 2.1317\n",
            "Epoch 56/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6306 - mse: 6.6306 - mae: 2.0552 - val_loss: 7.1232 - val_mse: 7.1232 - val_mae: 2.1298\n",
            "Epoch 57/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6741 - mse: 6.6741 - mae: 2.0556 - val_loss: 7.1529 - val_mse: 7.1529 - val_mae: 2.1332\n",
            "Epoch 58/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7307 - mse: 6.7307 - mae: 2.0710 - val_loss: 7.0702 - val_mse: 7.0702 - val_mae: 2.1223\n",
            "Epoch 59/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7135 - mse: 6.7135 - mae: 2.0668 - val_loss: 7.1018 - val_mse: 7.1018 - val_mae: 2.1270\n",
            "Epoch 60/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.9179 - mse: 6.9179 - mae: 2.0975 - val_loss: 7.2294 - val_mse: 7.2294 - val_mae: 2.1480\n",
            "Epoch 61/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7861 - mse: 6.7861 - mae: 2.0719 - val_loss: 7.1394 - val_mse: 7.1394 - val_mae: 2.1326\n",
            "Epoch 62/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6065 - mse: 6.6065 - mae: 2.0404 - val_loss: 7.1319 - val_mse: 7.1319 - val_mae: 2.1277\n",
            "Epoch 63/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7057 - mse: 6.7057 - mae: 2.0648 - val_loss: 7.1402 - val_mse: 7.1402 - val_mae: 2.1285\n",
            "Epoch 64/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6724 - mse: 6.6724 - mae: 2.0552 - val_loss: 7.1043 - val_mse: 7.1043 - val_mae: 2.1242\n",
            "Epoch 65/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7523 - mse: 6.7523 - mae: 2.0736 - val_loss: 7.2273 - val_mse: 7.2273 - val_mae: 2.1397\n",
            "Epoch 66/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7654 - mse: 6.7654 - mae: 2.0659 - val_loss: 7.1426 - val_mse: 7.1426 - val_mae: 2.1318\n",
            "Epoch 67/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8086 - mse: 6.8086 - mae: 2.0758 - val_loss: 7.1421 - val_mse: 7.1421 - val_mae: 2.1285\n",
            "Epoch 68/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8371 - mse: 6.8371 - mae: 2.0771 - val_loss: 7.0914 - val_mse: 7.0914 - val_mae: 2.1220\n",
            "Epoch 69/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7483 - mse: 6.7483 - mae: 2.0763 - val_loss: 7.1281 - val_mse: 7.1281 - val_mae: 2.1330\n",
            "Epoch 70/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6994 - mse: 6.6994 - mae: 2.0698 - val_loss: 7.1276 - val_mse: 7.1276 - val_mae: 2.1282\n",
            "Epoch 71/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.9381 - mse: 6.9381 - mae: 2.0854 - val_loss: 7.0980 - val_mse: 7.0980 - val_mae: 2.1237\n",
            "Epoch 72/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.9731 - mse: 6.9731 - mae: 2.0971 - val_loss: 7.1507 - val_mse: 7.1507 - val_mae: 2.1318\n",
            "Epoch 73/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7057 - mse: 6.7057 - mae: 2.0664 - val_loss: 7.1138 - val_mse: 7.1138 - val_mae: 2.1285\n",
            "Epoch 74/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7757 - mse: 6.7757 - mae: 2.0742 - val_loss: 7.1403 - val_mse: 7.1403 - val_mae: 2.1292\n",
            "Epoch 75/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7346 - mse: 6.7346 - mae: 2.0712 - val_loss: 7.1705 - val_mse: 7.1705 - val_mae: 2.1330\n",
            "Epoch 76/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.7206 - mse: 6.7206 - mae: 2.0588 - val_loss: 7.1871 - val_mse: 7.1871 - val_mae: 2.1415\n",
            "Epoch 77/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6309 - mse: 6.6309 - mae: 2.0529 - val_loss: 7.1731 - val_mse: 7.1731 - val_mae: 2.1372\n",
            "Epoch 78/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5398 - mse: 6.5398 - mae: 2.0446 - val_loss: 7.2254 - val_mse: 7.2254 - val_mae: 2.1418\n",
            "Epoch 79/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8788 - mse: 6.8788 - mae: 2.0912 - val_loss: 7.1190 - val_mse: 7.1190 - val_mae: 2.1269\n",
            "Epoch 80/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6105 - mse: 6.6105 - mae: 2.0573 - val_loss: 7.2795 - val_mse: 7.2795 - val_mae: 2.1490\n",
            "Epoch 81/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5557 - mse: 6.5557 - mae: 2.0526 - val_loss: 7.1979 - val_mse: 7.1979 - val_mae: 2.1398\n",
            "Epoch 82/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7445 - mse: 6.7445 - mae: 2.0585 - val_loss: 7.1754 - val_mse: 7.1754 - val_mae: 2.1348\n",
            "Epoch 83/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6619 - mse: 6.6619 - mae: 2.0542 - val_loss: 7.1091 - val_mse: 7.1091 - val_mae: 2.1269\n",
            "Epoch 84/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6765 - mse: 6.6765 - mae: 2.0414 - val_loss: 7.0977 - val_mse: 7.0977 - val_mae: 2.1263\n",
            "Epoch 85/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.9221 - mse: 6.9221 - mae: 2.1044 - val_loss: 7.1207 - val_mse: 7.1207 - val_mae: 2.1303\n",
            "Epoch 86/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.5645 - mse: 6.5645 - mae: 2.0355 - val_loss: 7.1395 - val_mse: 7.1395 - val_mae: 2.1287\n",
            "Epoch 87/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6298 - mse: 6.6298 - mae: 2.0447 - val_loss: 7.2511 - val_mse: 7.2511 - val_mae: 2.1410\n",
            "Epoch 88/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7281 - mse: 6.7281 - mae: 2.0647 - val_loss: 7.2529 - val_mse: 7.2529 - val_mae: 2.1459\n",
            "Epoch 89/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6342 - mse: 6.6342 - mae: 2.0514 - val_loss: 7.1271 - val_mse: 7.1271 - val_mae: 2.1275\n",
            "Epoch 90/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7562 - mse: 6.7562 - mae: 2.0714 - val_loss: 7.1679 - val_mse: 7.1679 - val_mae: 2.1375\n",
            "Epoch 91/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6892 - mse: 6.6892 - mae: 2.0530 - val_loss: 7.1848 - val_mse: 7.1848 - val_mae: 2.1419\n",
            "Epoch 92/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6293 - mse: 6.6293 - mae: 2.0550 - val_loss: 7.1207 - val_mse: 7.1207 - val_mae: 2.1254\n",
            "Epoch 93/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5938 - mse: 6.5938 - mae: 2.0502 - val_loss: 7.3025 - val_mse: 7.3025 - val_mae: 2.1500\n",
            "Epoch 94/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6385 - mse: 6.6385 - mae: 2.0497 - val_loss: 7.1044 - val_mse: 7.1044 - val_mae: 2.1291\n",
            "Epoch 95/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8510 - mse: 6.8510 - mae: 2.0782 - val_loss: 7.1117 - val_mse: 7.1117 - val_mae: 2.1306\n",
            "Epoch 96/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5925 - mse: 6.5925 - mae: 2.0426 - val_loss: 7.1836 - val_mse: 7.1836 - val_mae: 2.1388\n",
            "Epoch 97/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4799 - mse: 6.4799 - mae: 2.0192 - val_loss: 7.1216 - val_mse: 7.1216 - val_mae: 2.1320\n",
            "Epoch 98/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.9024 - mse: 6.9024 - mae: 2.0843 - val_loss: 7.1716 - val_mse: 7.1716 - val_mae: 2.1383\n",
            "Epoch 99/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6161 - mse: 6.6161 - mae: 2.0386 - val_loss: 7.1543 - val_mse: 7.1543 - val_mae: 2.1355\n",
            "Epoch 100/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5371 - mse: 6.5371 - mae: 2.0310 - val_loss: 7.2692 - val_mse: 7.2692 - val_mae: 2.1489\n",
            "Epoch 101/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8733 - mse: 6.8733 - mae: 2.0809 - val_loss: 7.1236 - val_mse: 7.1236 - val_mae: 2.1277\n",
            "Epoch 102/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5287 - mse: 6.5287 - mae: 2.0329 - val_loss: 7.1184 - val_mse: 7.1184 - val_mae: 2.1268\n",
            "Epoch 103/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6436 - mse: 6.6436 - mae: 2.0556 - val_loss: 7.2558 - val_mse: 7.2558 - val_mae: 2.1468\n",
            "Epoch 104/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6599 - mse: 6.6599 - mae: 2.0632 - val_loss: 7.2370 - val_mse: 7.2370 - val_mae: 2.1441\n",
            "Epoch 105/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5820 - mse: 6.5820 - mae: 2.0375 - val_loss: 7.1565 - val_mse: 7.1565 - val_mae: 2.1364\n",
            "Epoch 106/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7104 - mse: 6.7104 - mae: 2.0603 - val_loss: 7.1683 - val_mse: 7.1683 - val_mae: 2.1341\n",
            "Epoch 107/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5988 - mse: 6.5988 - mae: 2.0378 - val_loss: 7.1220 - val_mse: 7.1220 - val_mae: 2.1285\n",
            "Epoch 108/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7240 - mse: 6.7240 - mae: 2.0580 - val_loss: 7.2410 - val_mse: 7.2410 - val_mae: 2.1452\n",
            "Epoch 109/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6840 - mse: 6.6840 - mae: 2.0505 - val_loss: 7.1750 - val_mse: 7.1750 - val_mae: 2.1372\n",
            "Epoch 110/300\n",
            "563/563 [==============================] - 2s 3ms/step - loss: 6.6155 - mse: 6.6155 - mae: 2.0539 - val_loss: 7.1020 - val_mse: 7.1020 - val_mae: 2.1275\n",
            "Epoch 111/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8562 - mse: 6.8562 - mae: 2.0782 - val_loss: 7.1479 - val_mse: 7.1479 - val_mae: 2.1340\n",
            "Epoch 112/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5795 - mse: 6.5795 - mae: 2.0403 - val_loss: 7.2252 - val_mse: 7.2252 - val_mae: 2.1448\n",
            "Epoch 113/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6538 - mse: 6.6538 - mae: 2.0528 - val_loss: 7.1834 - val_mse: 7.1834 - val_mae: 2.1354\n",
            "Epoch 114/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8713 - mse: 6.8713 - mae: 2.0909 - val_loss: 7.1763 - val_mse: 7.1763 - val_mae: 2.1371\n",
            "Epoch 115/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4522 - mse: 6.4522 - mae: 2.0083 - val_loss: 7.2113 - val_mse: 7.2113 - val_mae: 2.1424\n",
            "Epoch 116/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6755 - mse: 6.6755 - mae: 2.0377 - val_loss: 7.1635 - val_mse: 7.1635 - val_mae: 2.1325\n",
            "Epoch 117/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4845 - mse: 6.4845 - mae: 2.0206 - val_loss: 7.1664 - val_mse: 7.1664 - val_mae: 2.1356\n",
            "Epoch 118/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5133 - mse: 6.5133 - mae: 2.0224 - val_loss: 7.1596 - val_mse: 7.1596 - val_mae: 2.1324\n",
            "Epoch 119/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8288 - mse: 6.8288 - mae: 2.0839 - val_loss: 7.1369 - val_mse: 7.1369 - val_mae: 2.1307\n",
            "Epoch 120/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6010 - mse: 6.6010 - mae: 2.0432 - val_loss: 7.1996 - val_mse: 7.1996 - val_mae: 2.1412\n",
            "Epoch 121/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7958 - mse: 6.7958 - mae: 2.0793 - val_loss: 7.1436 - val_mse: 7.1436 - val_mae: 2.1283\n",
            "Epoch 122/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5669 - mse: 6.5669 - mae: 2.0329 - val_loss: 7.1694 - val_mse: 7.1694 - val_mae: 2.1348\n",
            "Epoch 123/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7595 - mse: 6.7595 - mae: 2.0606 - val_loss: 7.1572 - val_mse: 7.1572 - val_mae: 2.1346\n",
            "Epoch 124/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5755 - mse: 6.5755 - mae: 2.0512 - val_loss: 7.2206 - val_mse: 7.2206 - val_mae: 2.1444\n",
            "Epoch 125/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6981 - mse: 6.6981 - mae: 2.0556 - val_loss: 7.2217 - val_mse: 7.2217 - val_mae: 2.1446\n",
            "Epoch 126/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8123 - mse: 6.8123 - mae: 2.0677 - val_loss: 7.1354 - val_mse: 7.1354 - val_mae: 2.1328\n",
            "Epoch 127/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6547 - mse: 6.6547 - mae: 2.0490 - val_loss: 7.2137 - val_mse: 7.2137 - val_mae: 2.1397\n",
            "Epoch 128/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5885 - mse: 6.5885 - mae: 2.0441 - val_loss: 7.2244 - val_mse: 7.2244 - val_mae: 2.1394\n",
            "Epoch 129/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5751 - mse: 6.5751 - mae: 2.0278 - val_loss: 7.0670 - val_mse: 7.0670 - val_mae: 2.1203\n",
            "Epoch 130/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7485 - mse: 6.7485 - mae: 2.0606 - val_loss: 7.1382 - val_mse: 7.1382 - val_mae: 2.1318\n",
            "Epoch 131/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5782 - mse: 6.5782 - mae: 2.0281 - val_loss: 7.2356 - val_mse: 7.2356 - val_mae: 2.1404\n",
            "Epoch 132/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6413 - mse: 6.6413 - mae: 2.0498 - val_loss: 7.0775 - val_mse: 7.0775 - val_mae: 2.1224\n",
            "Epoch 133/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.3838 - mse: 6.3838 - mae: 2.0019 - val_loss: 7.0949 - val_mse: 7.0949 - val_mae: 2.1248\n",
            "Epoch 134/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6761 - mse: 6.6761 - mae: 2.0504 - val_loss: 7.1734 - val_mse: 7.1734 - val_mae: 2.1379\n",
            "Epoch 135/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5878 - mse: 6.5878 - mae: 2.0345 - val_loss: 7.2097 - val_mse: 7.2097 - val_mae: 2.1400\n",
            "Epoch 136/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4879 - mse: 6.4879 - mae: 2.0225 - val_loss: 7.2210 - val_mse: 7.2210 - val_mae: 2.1395\n",
            "Epoch 137/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6715 - mse: 6.6715 - mae: 2.0534 - val_loss: 7.2413 - val_mse: 7.2413 - val_mae: 2.1429\n",
            "Epoch 138/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7566 - mse: 6.7566 - mae: 2.0747 - val_loss: 7.0881 - val_mse: 7.0881 - val_mae: 2.1243\n",
            "Epoch 139/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5013 - mse: 6.5013 - mae: 2.0252 - val_loss: 7.0938 - val_mse: 7.0938 - val_mae: 2.1250\n",
            "Epoch 140/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5739 - mse: 6.5739 - mae: 2.0342 - val_loss: 7.1738 - val_mse: 7.1738 - val_mae: 2.1358\n",
            "Epoch 141/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8078 - mse: 6.8078 - mae: 2.0734 - val_loss: 7.0892 - val_mse: 7.0892 - val_mae: 2.1240\n",
            "Epoch 142/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6042 - mse: 6.6042 - mae: 2.0438 - val_loss: 7.1089 - val_mse: 7.1089 - val_mae: 2.1267\n",
            "Epoch 143/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5263 - mse: 6.5263 - mae: 2.0346 - val_loss: 7.0962 - val_mse: 7.0962 - val_mae: 2.1243\n",
            "Epoch 144/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5627 - mse: 6.5627 - mae: 2.0299 - val_loss: 7.1049 - val_mse: 7.1049 - val_mae: 2.1282\n",
            "Epoch 145/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6456 - mse: 6.6456 - mae: 2.0426 - val_loss: 7.1613 - val_mse: 7.1613 - val_mae: 2.1368\n",
            "Epoch 146/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5646 - mse: 6.5646 - mae: 2.0516 - val_loss: 7.1296 - val_mse: 7.1296 - val_mae: 2.1286\n",
            "Epoch 147/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5904 - mse: 6.5904 - mae: 2.0432 - val_loss: 7.0699 - val_mse: 7.0699 - val_mae: 2.1179\n",
            "Epoch 148/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5322 - mse: 6.5322 - mae: 2.0324 - val_loss: 7.1311 - val_mse: 7.1311 - val_mae: 2.1304\n",
            "Epoch 149/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7056 - mse: 6.7056 - mae: 2.0622 - val_loss: 7.1195 - val_mse: 7.1195 - val_mae: 2.1294\n",
            "Epoch 150/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6938 - mse: 6.6938 - mae: 2.0489 - val_loss: 7.1615 - val_mse: 7.1615 - val_mae: 2.1345\n",
            "Epoch 151/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5953 - mse: 6.5953 - mae: 2.0342 - val_loss: 7.3035 - val_mse: 7.3035 - val_mae: 2.1519\n",
            "Epoch 152/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6199 - mse: 6.6199 - mae: 2.0552 - val_loss: 7.1863 - val_mse: 7.1863 - val_mae: 2.1346\n",
            "Epoch 153/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8128 - mse: 6.8128 - mae: 2.0714 - val_loss: 7.2248 - val_mse: 7.2248 - val_mae: 2.1384\n",
            "Epoch 154/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6843 - mse: 6.6843 - mae: 2.0571 - val_loss: 7.1915 - val_mse: 7.1915 - val_mae: 2.1345\n",
            "Epoch 155/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5730 - mse: 6.5730 - mae: 2.0378 - val_loss: 7.1900 - val_mse: 7.1900 - val_mae: 2.1363\n",
            "Epoch 156/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5853 - mse: 6.5853 - mae: 2.0383 - val_loss: 7.1277 - val_mse: 7.1277 - val_mae: 2.1299\n",
            "Epoch 157/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5541 - mse: 6.5541 - mae: 2.0401 - val_loss: 7.1279 - val_mse: 7.1279 - val_mae: 2.1288\n",
            "Epoch 158/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6048 - mse: 6.6048 - mae: 2.0298 - val_loss: 7.2336 - val_mse: 7.2336 - val_mae: 2.1451\n",
            "Epoch 159/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6928 - mse: 6.6928 - mae: 2.0636 - val_loss: 7.1966 - val_mse: 7.1966 - val_mae: 2.1382\n",
            "Epoch 160/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5873 - mse: 6.5873 - mae: 2.0453 - val_loss: 7.1623 - val_mse: 7.1623 - val_mae: 2.1344\n",
            "Epoch 161/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7237 - mse: 6.7237 - mae: 2.0679 - val_loss: 7.1996 - val_mse: 7.1996 - val_mae: 2.1377\n",
            "Epoch 162/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7032 - mse: 6.7032 - mae: 2.0688 - val_loss: 7.2075 - val_mse: 7.2075 - val_mae: 2.1395\n",
            "Epoch 163/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5576 - mse: 6.5576 - mae: 2.0399 - val_loss: 7.1105 - val_mse: 7.1105 - val_mae: 2.1278\n",
            "Epoch 164/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6203 - mse: 6.6203 - mae: 2.0520 - val_loss: 7.2812 - val_mse: 7.2812 - val_mae: 2.1464\n",
            "Epoch 165/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4926 - mse: 6.4926 - mae: 2.0348 - val_loss: 7.0781 - val_mse: 7.0781 - val_mae: 2.1189\n",
            "Epoch 166/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8054 - mse: 6.8054 - mae: 2.0747 - val_loss: 7.1196 - val_mse: 7.1196 - val_mae: 2.1295\n",
            "Epoch 167/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5226 - mse: 6.5226 - mae: 2.0369 - val_loss: 7.1937 - val_mse: 7.1937 - val_mae: 2.1366\n",
            "Epoch 168/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6181 - mse: 6.6181 - mae: 2.0475 - val_loss: 7.1838 - val_mse: 7.1838 - val_mae: 2.1391\n",
            "Epoch 169/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7981 - mse: 6.7981 - mae: 2.0748 - val_loss: 7.1284 - val_mse: 7.1284 - val_mae: 2.1326\n",
            "Epoch 170/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6470 - mse: 6.6470 - mae: 2.0547 - val_loss: 7.1419 - val_mse: 7.1419 - val_mae: 2.1308\n",
            "Epoch 171/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5554 - mse: 6.5554 - mae: 2.0413 - val_loss: 7.2071 - val_mse: 7.2071 - val_mae: 2.1439\n",
            "Epoch 172/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5588 - mse: 6.5588 - mae: 2.0367 - val_loss: 7.1513 - val_mse: 7.1513 - val_mae: 2.1350\n",
            "Epoch 173/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4518 - mse: 6.4518 - mae: 2.0192 - val_loss: 7.1119 - val_mse: 7.1119 - val_mae: 2.1287\n",
            "Epoch 174/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7541 - mse: 6.7541 - mae: 2.0589 - val_loss: 7.2307 - val_mse: 7.2307 - val_mae: 2.1444\n",
            "Epoch 175/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8081 - mse: 6.8081 - mae: 2.0715 - val_loss: 7.1939 - val_mse: 7.1939 - val_mae: 2.1399\n",
            "Epoch 176/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5894 - mse: 6.5894 - mae: 2.0454 - val_loss: 7.1372 - val_mse: 7.1372 - val_mae: 2.1329\n",
            "Epoch 177/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6043 - mse: 6.6043 - mae: 2.0454 - val_loss: 7.3048 - val_mse: 7.3048 - val_mae: 2.1523\n",
            "Epoch 178/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4895 - mse: 6.4895 - mae: 2.0221 - val_loss: 7.1578 - val_mse: 7.1578 - val_mae: 2.1337\n",
            "Epoch 179/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4292 - mse: 6.4292 - mae: 2.0096 - val_loss: 7.2584 - val_mse: 7.2584 - val_mae: 2.1493\n",
            "Epoch 180/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6364 - mse: 6.6364 - mae: 2.0448 - val_loss: 7.2253 - val_mse: 7.2253 - val_mae: 2.1384\n",
            "Epoch 181/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6835 - mse: 6.6835 - mae: 2.0549 - val_loss: 7.1552 - val_mse: 7.1552 - val_mae: 2.1351\n",
            "Epoch 182/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6060 - mse: 6.6060 - mae: 2.0438 - val_loss: 7.1617 - val_mse: 7.1617 - val_mae: 2.1368\n",
            "Epoch 183/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7145 - mse: 6.7145 - mae: 2.0484 - val_loss: 7.2187 - val_mse: 7.2187 - val_mae: 2.1457\n",
            "Epoch 184/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7122 - mse: 6.7122 - mae: 2.0604 - val_loss: 7.1205 - val_mse: 7.1205 - val_mae: 2.1295\n",
            "Epoch 185/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7076 - mse: 6.7076 - mae: 2.0565 - val_loss: 7.2563 - val_mse: 7.2563 - val_mae: 2.1468\n",
            "Epoch 186/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4121 - mse: 6.4121 - mae: 2.0116 - val_loss: 7.1338 - val_mse: 7.1338 - val_mae: 2.1286\n",
            "Epoch 187/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8660 - mse: 6.8660 - mae: 2.0776 - val_loss: 7.2879 - val_mse: 7.2879 - val_mae: 2.1474\n",
            "Epoch 188/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5655 - mse: 6.5655 - mae: 2.0277 - val_loss: 7.1474 - val_mse: 7.1474 - val_mae: 2.1297\n",
            "Epoch 189/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5181 - mse: 6.5181 - mae: 2.0211 - val_loss: 7.1701 - val_mse: 7.1701 - val_mae: 2.1342\n",
            "Epoch 190/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5958 - mse: 6.5958 - mae: 2.0376 - val_loss: 7.1991 - val_mse: 7.1991 - val_mae: 2.1404\n",
            "Epoch 191/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6105 - mse: 6.6105 - mae: 2.0283 - val_loss: 7.1609 - val_mse: 7.1609 - val_mae: 2.1350\n",
            "Epoch 192/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6414 - mse: 6.6414 - mae: 2.0500 - val_loss: 7.0948 - val_mse: 7.0948 - val_mae: 2.1243\n",
            "Epoch 193/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6252 - mse: 6.6252 - mae: 2.0530 - val_loss: 7.1856 - val_mse: 7.1856 - val_mae: 2.1386\n",
            "Epoch 194/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6680 - mse: 6.6680 - mae: 2.0556 - val_loss: 7.2442 - val_mse: 7.2442 - val_mae: 2.1471\n",
            "Epoch 195/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6829 - mse: 6.6829 - mae: 2.0585 - val_loss: 7.2232 - val_mse: 7.2232 - val_mae: 2.1442\n",
            "Epoch 196/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5174 - mse: 6.5174 - mae: 2.0296 - val_loss: 7.2181 - val_mse: 7.2181 - val_mae: 2.1438\n",
            "Epoch 197/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5615 - mse: 6.5615 - mae: 2.0375 - val_loss: 7.0990 - val_mse: 7.0990 - val_mae: 2.1270\n",
            "Epoch 198/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6330 - mse: 6.6330 - mae: 2.0355 - val_loss: 7.2987 - val_mse: 7.2987 - val_mae: 2.1567\n",
            "Epoch 199/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8413 - mse: 6.8413 - mae: 2.0705 - val_loss: 7.2747 - val_mse: 7.2747 - val_mae: 2.1507\n",
            "Epoch 200/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.3848 - mse: 6.3848 - mae: 2.0244 - val_loss: 7.1592 - val_mse: 7.1592 - val_mae: 2.1346\n",
            "Epoch 201/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7090 - mse: 6.7090 - mae: 2.0514 - val_loss: 7.1590 - val_mse: 7.1590 - val_mae: 2.1373\n",
            "Epoch 202/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6525 - mse: 6.6525 - mae: 2.0438 - val_loss: 7.1147 - val_mse: 7.1147 - val_mae: 2.1318\n",
            "Epoch 203/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8172 - mse: 6.8172 - mae: 2.0747 - val_loss: 7.1763 - val_mse: 7.1763 - val_mae: 2.1390\n",
            "Epoch 204/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6258 - mse: 6.6258 - mae: 2.0450 - val_loss: 7.3028 - val_mse: 7.3028 - val_mae: 2.1497\n",
            "Epoch 205/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6757 - mse: 6.6757 - mae: 2.0643 - val_loss: 7.2742 - val_mse: 7.2742 - val_mae: 2.1450\n",
            "Epoch 206/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5036 - mse: 6.5036 - mae: 2.0232 - val_loss: 7.2068 - val_mse: 7.2068 - val_mae: 2.1390\n",
            "Epoch 207/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5709 - mse: 6.5709 - mae: 2.0306 - val_loss: 7.2335 - val_mse: 7.2335 - val_mae: 2.1429\n",
            "Epoch 208/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5014 - mse: 6.5014 - mae: 2.0221 - val_loss: 7.2997 - val_mse: 7.2997 - val_mae: 2.1523\n",
            "Epoch 209/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7352 - mse: 6.7352 - mae: 2.0589 - val_loss: 7.2145 - val_mse: 7.2145 - val_mae: 2.1369\n",
            "Epoch 210/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7474 - mse: 6.7474 - mae: 2.0536 - val_loss: 7.2512 - val_mse: 7.2512 - val_mae: 2.1501\n",
            "Epoch 211/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4827 - mse: 6.4827 - mae: 2.0276 - val_loss: 7.3866 - val_mse: 7.3866 - val_mae: 2.1629\n",
            "Epoch 212/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7222 - mse: 6.7222 - mae: 2.0580 - val_loss: 7.1812 - val_mse: 7.1812 - val_mae: 2.1359\n",
            "Epoch 213/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5604 - mse: 6.5604 - mae: 2.0159 - val_loss: 7.2171 - val_mse: 7.2171 - val_mae: 2.1438\n",
            "Epoch 214/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6484 - mse: 6.6484 - mae: 2.0580 - val_loss: 7.0931 - val_mse: 7.0931 - val_mae: 2.1227\n",
            "Epoch 215/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4809 - mse: 6.4809 - mae: 2.0209 - val_loss: 7.4152 - val_mse: 7.4152 - val_mae: 2.1727\n",
            "Epoch 216/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6873 - mse: 6.6873 - mae: 2.0548 - val_loss: 7.1030 - val_mse: 7.1030 - val_mae: 2.1301\n",
            "Epoch 217/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5518 - mse: 6.5518 - mae: 2.0354 - val_loss: 7.2352 - val_mse: 7.2352 - val_mae: 2.1477\n",
            "Epoch 218/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5114 - mse: 6.5114 - mae: 2.0165 - val_loss: 7.2093 - val_mse: 7.2093 - val_mae: 2.1411\n",
            "Epoch 219/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6162 - mse: 6.6162 - mae: 2.0337 - val_loss: 7.1423 - val_mse: 7.1423 - val_mae: 2.1331\n",
            "Epoch 220/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7746 - mse: 6.7746 - mae: 2.0697 - val_loss: 7.2201 - val_mse: 7.2201 - val_mae: 2.1385\n",
            "Epoch 221/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5329 - mse: 6.5329 - mae: 2.0284 - val_loss: 7.1392 - val_mse: 7.1392 - val_mae: 2.1360\n",
            "Epoch 222/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4474 - mse: 6.4474 - mae: 2.0214 - val_loss: 7.2000 - val_mse: 7.2000 - val_mae: 2.1409\n",
            "Epoch 223/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6702 - mse: 6.6702 - mae: 2.0509 - val_loss: 7.2279 - val_mse: 7.2279 - val_mae: 2.1504\n",
            "Epoch 224/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4606 - mse: 6.4606 - mae: 2.0150 - val_loss: 7.2562 - val_mse: 7.2562 - val_mae: 2.1467\n",
            "Epoch 225/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6586 - mse: 6.6586 - mae: 2.0597 - val_loss: 7.2697 - val_mse: 7.2697 - val_mae: 2.1496\n",
            "Epoch 226/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6201 - mse: 6.6201 - mae: 2.0380 - val_loss: 7.2639 - val_mse: 7.2639 - val_mae: 2.1494\n",
            "Epoch 227/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7226 - mse: 6.7226 - mae: 2.0539 - val_loss: 7.1703 - val_mse: 7.1703 - val_mae: 2.1350\n",
            "Epoch 228/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5436 - mse: 6.5436 - mae: 2.0357 - val_loss: 7.1741 - val_mse: 7.1741 - val_mae: 2.1360\n",
            "Epoch 229/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4496 - mse: 6.4496 - mae: 2.0136 - val_loss: 7.2067 - val_mse: 7.2067 - val_mae: 2.1397\n",
            "Epoch 230/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6310 - mse: 6.6310 - mae: 2.0425 - val_loss: 7.2424 - val_mse: 7.2424 - val_mae: 2.1479\n",
            "Epoch 231/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4768 - mse: 6.4768 - mae: 2.0139 - val_loss: 7.1976 - val_mse: 7.1976 - val_mae: 2.1405\n",
            "Epoch 232/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5854 - mse: 6.5854 - mae: 2.0330 - val_loss: 7.3168 - val_mse: 7.3168 - val_mae: 2.1544\n",
            "Epoch 233/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6382 - mse: 6.6382 - mae: 2.0474 - val_loss: 7.1545 - val_mse: 7.1545 - val_mae: 2.1352\n",
            "Epoch 234/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6072 - mse: 6.6072 - mae: 2.0319 - val_loss: 7.2373 - val_mse: 7.2373 - val_mae: 2.1458\n",
            "Epoch 235/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5502 - mse: 6.5502 - mae: 2.0367 - val_loss: 7.2429 - val_mse: 7.2429 - val_mae: 2.1445\n",
            "Epoch 236/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6442 - mse: 6.6442 - mae: 2.0417 - val_loss: 7.4067 - val_mse: 7.4067 - val_mae: 2.1692\n",
            "Epoch 237/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7459 - mse: 6.7459 - mae: 2.0615 - val_loss: 7.2858 - val_mse: 7.2858 - val_mae: 2.1446\n",
            "Epoch 238/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5173 - mse: 6.5173 - mae: 2.0357 - val_loss: 7.1829 - val_mse: 7.1829 - val_mae: 2.1318\n",
            "Epoch 239/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5027 - mse: 6.5027 - mae: 2.0300 - val_loss: 7.1160 - val_mse: 7.1160 - val_mae: 2.1256\n",
            "Epoch 240/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6184 - mse: 6.6184 - mae: 2.0458 - val_loss: 7.1947 - val_mse: 7.1947 - val_mae: 2.1345\n",
            "Epoch 241/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6200 - mse: 6.6200 - mae: 2.0367 - val_loss: 7.2936 - val_mse: 7.2936 - val_mae: 2.1452\n",
            "Epoch 242/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5136 - mse: 6.5136 - mae: 2.0175 - val_loss: 7.3456 - val_mse: 7.3456 - val_mae: 2.1530\n",
            "Epoch 243/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5179 - mse: 6.5179 - mae: 2.0131 - val_loss: 7.1433 - val_mse: 7.1433 - val_mae: 2.1276\n",
            "Epoch 244/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6750 - mse: 6.6750 - mae: 2.0550 - val_loss: 7.2218 - val_mse: 7.2218 - val_mae: 2.1426\n",
            "Epoch 245/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6075 - mse: 6.6075 - mae: 2.0455 - val_loss: 7.1700 - val_mse: 7.1700 - val_mae: 2.1320\n",
            "Epoch 246/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7834 - mse: 6.7834 - mae: 2.0638 - val_loss: 7.3079 - val_mse: 7.3079 - val_mae: 2.1529\n",
            "Epoch 247/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6821 - mse: 6.6821 - mae: 2.0549 - val_loss: 7.2018 - val_mse: 7.2018 - val_mae: 2.1395\n",
            "Epoch 248/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6113 - mse: 6.6113 - mae: 2.0294 - val_loss: 7.1257 - val_mse: 7.1257 - val_mae: 2.1330\n",
            "Epoch 249/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5913 - mse: 6.5913 - mae: 2.0348 - val_loss: 7.1465 - val_mse: 7.1465 - val_mae: 2.1301\n",
            "Epoch 250/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5999 - mse: 6.5999 - mae: 2.0291 - val_loss: 7.1661 - val_mse: 7.1661 - val_mae: 2.1333\n",
            "Epoch 251/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6745 - mse: 6.6745 - mae: 2.0438 - val_loss: 7.2880 - val_mse: 7.2880 - val_mae: 2.1470\n",
            "Epoch 252/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5468 - mse: 6.5468 - mae: 2.0201 - val_loss: 7.1342 - val_mse: 7.1342 - val_mae: 2.1316\n",
            "Epoch 253/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7105 - mse: 6.7105 - mae: 2.0481 - val_loss: 7.2519 - val_mse: 7.2519 - val_mae: 2.1437\n",
            "Epoch 254/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6426 - mse: 6.6426 - mae: 2.0316 - val_loss: 7.1482 - val_mse: 7.1482 - val_mae: 2.1334\n",
            "Epoch 255/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6001 - mse: 6.6001 - mae: 2.0190 - val_loss: 7.2376 - val_mse: 7.2376 - val_mae: 2.1387\n",
            "Epoch 256/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5768 - mse: 6.5768 - mae: 2.0330 - val_loss: 7.1259 - val_mse: 7.1259 - val_mae: 2.1302\n",
            "Epoch 257/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6749 - mse: 6.6749 - mae: 2.0392 - val_loss: 7.1158 - val_mse: 7.1158 - val_mae: 2.1296\n",
            "Epoch 258/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6172 - mse: 6.6172 - mae: 2.0487 - val_loss: 7.2518 - val_mse: 7.2518 - val_mae: 2.1446\n",
            "Epoch 259/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5315 - mse: 6.5315 - mae: 2.0335 - val_loss: 7.1641 - val_mse: 7.1641 - val_mae: 2.1298\n",
            "Epoch 260/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5570 - mse: 6.5570 - mae: 2.0348 - val_loss: 7.1183 - val_mse: 7.1183 - val_mae: 2.1276\n",
            "Epoch 261/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7058 - mse: 6.7058 - mae: 2.0509 - val_loss: 7.3657 - val_mse: 7.3657 - val_mae: 2.1568\n",
            "Epoch 262/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6582 - mse: 6.6582 - mae: 2.0443 - val_loss: 7.2021 - val_mse: 7.2021 - val_mae: 2.1348\n",
            "Epoch 263/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5938 - mse: 6.5938 - mae: 2.0375 - val_loss: 7.1648 - val_mse: 7.1648 - val_mae: 2.1332\n",
            "Epoch 264/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6820 - mse: 6.6820 - mae: 2.0553 - val_loss: 7.0719 - val_mse: 7.0719 - val_mae: 2.1218\n",
            "Epoch 265/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5802 - mse: 6.5802 - mae: 2.0341 - val_loss: 7.2759 - val_mse: 7.2759 - val_mae: 2.1517\n",
            "Epoch 266/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4982 - mse: 6.4982 - mae: 2.0122 - val_loss: 7.2045 - val_mse: 7.2045 - val_mae: 2.1386\n",
            "Epoch 267/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4015 - mse: 6.4015 - mae: 2.0051 - val_loss: 7.1819 - val_mse: 7.1819 - val_mae: 2.1406\n",
            "Epoch 268/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7236 - mse: 6.7236 - mae: 2.0591 - val_loss: 7.2285 - val_mse: 7.2285 - val_mae: 2.1451\n",
            "Epoch 269/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6129 - mse: 6.6129 - mae: 2.0442 - val_loss: 7.1660 - val_mse: 7.1660 - val_mae: 2.1374\n",
            "Epoch 270/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5405 - mse: 6.5405 - mae: 2.0265 - val_loss: 7.1269 - val_mse: 7.1269 - val_mae: 2.1336\n",
            "Epoch 271/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5457 - mse: 6.5457 - mae: 2.0281 - val_loss: 7.2586 - val_mse: 7.2586 - val_mae: 2.1537\n",
            "Epoch 272/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6159 - mse: 6.6159 - mae: 2.0326 - val_loss: 7.1979 - val_mse: 7.1979 - val_mae: 2.1389\n",
            "Epoch 273/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6140 - mse: 6.6140 - mae: 2.0505 - val_loss: 7.1409 - val_mse: 7.1409 - val_mae: 2.1303\n",
            "Epoch 274/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6016 - mse: 6.6016 - mae: 2.0346 - val_loss: 7.1181 - val_mse: 7.1181 - val_mae: 2.1316\n",
            "Epoch 275/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6305 - mse: 6.6305 - mae: 2.0438 - val_loss: 7.2496 - val_mse: 7.2496 - val_mae: 2.1450\n",
            "Epoch 276/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4488 - mse: 6.4488 - mae: 2.0172 - val_loss: 7.1931 - val_mse: 7.1931 - val_mae: 2.1393\n",
            "Epoch 277/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5382 - mse: 6.5382 - mae: 2.0266 - val_loss: 7.2134 - val_mse: 7.2134 - val_mae: 2.1421\n",
            "Epoch 278/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5385 - mse: 6.5385 - mae: 2.0324 - val_loss: 7.2235 - val_mse: 7.2235 - val_mae: 2.1392\n",
            "Epoch 279/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5112 - mse: 6.5112 - mae: 2.0235 - val_loss: 7.2532 - val_mse: 7.2532 - val_mae: 2.1525\n",
            "Epoch 280/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.3799 - mse: 6.3799 - mae: 2.0076 - val_loss: 7.2335 - val_mse: 7.2335 - val_mae: 2.1435\n",
            "Epoch 281/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5833 - mse: 6.5833 - mae: 2.0348 - val_loss: 7.2738 - val_mse: 7.2738 - val_mae: 2.1522\n",
            "Epoch 282/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5293 - mse: 6.5293 - mae: 2.0181 - val_loss: 7.2080 - val_mse: 7.2080 - val_mae: 2.1426\n",
            "Epoch 283/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7750 - mse: 6.7750 - mae: 2.0699 - val_loss: 7.3570 - val_mse: 7.3570 - val_mae: 2.1655\n",
            "Epoch 284/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6171 - mse: 6.6171 - mae: 2.0435 - val_loss: 7.2526 - val_mse: 7.2526 - val_mae: 2.1480\n",
            "Epoch 285/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5934 - mse: 6.5934 - mae: 2.0290 - val_loss: 7.3427 - val_mse: 7.3427 - val_mae: 2.1625\n",
            "Epoch 286/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5681 - mse: 6.5681 - mae: 2.0249 - val_loss: 7.3091 - val_mse: 7.3091 - val_mae: 2.1582\n",
            "Epoch 287/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6327 - mse: 6.6327 - mae: 2.0428 - val_loss: 7.1876 - val_mse: 7.1876 - val_mae: 2.1379\n",
            "Epoch 288/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4789 - mse: 6.4789 - mae: 2.0256 - val_loss: 7.2338 - val_mse: 7.2338 - val_mae: 2.1444\n",
            "Epoch 289/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4706 - mse: 6.4706 - mae: 2.0225 - val_loss: 7.1876 - val_mse: 7.1876 - val_mae: 2.1380\n",
            "Epoch 290/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5431 - mse: 6.5431 - mae: 2.0296 - val_loss: 7.3073 - val_mse: 7.3073 - val_mae: 2.1588\n",
            "Epoch 291/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6960 - mse: 6.6960 - mae: 2.0544 - val_loss: 7.2924 - val_mse: 7.2924 - val_mae: 2.1626\n",
            "Epoch 292/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5797 - mse: 6.5797 - mae: 2.0395 - val_loss: 7.2341 - val_mse: 7.2341 - val_mae: 2.1483\n",
            "Epoch 293/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.8091 - mse: 6.8091 - mae: 2.0698 - val_loss: 7.1594 - val_mse: 7.1594 - val_mae: 2.1320\n",
            "Epoch 294/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6509 - mse: 6.6509 - mae: 2.0562 - val_loss: 7.1919 - val_mse: 7.1919 - val_mae: 2.1380\n",
            "Epoch 295/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7560 - mse: 6.7560 - mae: 2.0610 - val_loss: 7.3126 - val_mse: 7.3126 - val_mae: 2.1529\n",
            "Epoch 296/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.4858 - mse: 6.4858 - mae: 2.0265 - val_loss: 7.2654 - val_mse: 7.2654 - val_mae: 2.1477\n",
            "Epoch 297/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6837 - mse: 6.6837 - mae: 2.0564 - val_loss: 7.1241 - val_mse: 7.1241 - val_mae: 2.1304\n",
            "Epoch 298/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.5748 - mse: 6.5748 - mae: 2.0276 - val_loss: 7.2413 - val_mse: 7.2413 - val_mae: 2.1469\n",
            "Epoch 299/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.6474 - mse: 6.6474 - mae: 2.0454 - val_loss: 7.2328 - val_mse: 7.2328 - val_mae: 2.1476\n",
            "Epoch 300/300\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 6.7100 - mse: 6.7100 - mae: 2.0613 - val_loss: 7.2354 - val_mse: 7.2354 - val_mae: 2.1462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dDEqxTGEsZK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0NKjCWEsWi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
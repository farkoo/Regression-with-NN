{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qol-ovwtLUoI",
        "outputId": "6a4091b2-dc2a-49c9-8f4c-627e2065255d"
      },
      "source": [
        "%cd '/content/drive/My Drive/AI'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akQKed_BKnZ_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.regularizers import l1\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OQ3skMDKrSu"
      },
      "source": [
        "dataframe = pd.read_csv(\"4.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBhEoYpKuZi"
      },
      "source": [
        "nn_input = np.asarray(dataframe.iloc[:,0:4])\n",
        "nn_output = np.asarray(dataframe.iloc[:,4])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04LoNzphKzqR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_temp, y_train, y_temp = train_test_split( nn_input, nn_output, test_size = 0.4, random_state = 55) \n",
        "x_valid, x_test, y_valid, y_test = train_test_split( x_temp, y_temp, test_size = 0.3, random_state = 65) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbHnX9Q7Kzng"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, input_dim=4, activity_regularizer=l1(0.005)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(500, activity_regularizer=l1(0.006)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(800, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(900, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(500, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100, activity_regularizer=l1(0.004)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1, activity_regularizer=l1(0.002)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxtrwoCiK5CQ"
      },
      "source": [
        "model.compile(loss='mse',\n",
        "                  optimizer=Adam(learning_rate=0.001),\n",
        "                  metrics=['mse', 'mae'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uz2PxcoLqJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e5c6ab-e3b2-4eaa-aef5-ad94205238c8"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 200,\n",
        "                        validation_data=(x_valid, y_valid),\n",
        "                        batch_size = 16, verbose = 1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 18s 7ms/step - loss: 7.1041 - mse: 6.7847 - mae: 2.0726 - val_loss: 6.7933 - val_mse: 6.7143 - val_mae: 2.0604\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7267 - mse: 6.6756 - mae: 2.0695 - val_loss: 6.7300 - val_mse: 6.7098 - val_mae: 2.0598\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7494 - mse: 6.7326 - mae: 2.0413 - val_loss: 6.7244 - val_mse: 6.7108 - val_mae: 2.0599\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9253 - mse: 6.9090 - mae: 2.0897 - val_loss: 6.7360 - val_mse: 6.7199 - val_mae: 2.0613\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8750 - mse: 6.8584 - mae: 2.0909 - val_loss: 6.7292 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7945 - mse: 6.7802 - mae: 2.0692 - val_loss: 6.7370 - val_mse: 6.7085 - val_mae: 2.0595\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6591 - mse: 6.6415 - mae: 2.0581 - val_loss: 6.7239 - val_mse: 6.7138 - val_mae: 2.0604\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8784 - mse: 6.8420 - mae: 2.0745 - val_loss: 6.7830 - val_mse: 6.7135 - val_mae: 2.0603\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9751 - mse: 6.9301 - mae: 2.1045 - val_loss: 6.7710 - val_mse: 6.7446 - val_mae: 2.0652\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8646 - mse: 6.8380 - mae: 2.0820 - val_loss: 6.7266 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7045 - mse: 6.6921 - mae: 2.0500 - val_loss: 6.7198 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7836 - mse: 6.7723 - mae: 2.0767 - val_loss: 6.7278 - val_mse: 6.7087 - val_mae: 2.0596\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7823 - mse: 6.7645 - mae: 2.0779 - val_loss: 6.7274 - val_mse: 6.7140 - val_mae: 2.0604\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 6.8818 - mse: 6.8716 - mae: 2.0902 - val_loss: 6.7273 - val_mse: 6.7141 - val_mae: 2.0604\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5166 - mse: 6.5040 - mae: 2.0263 - val_loss: 6.7322 - val_mse: 6.7149 - val_mae: 2.0605\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8757 - mse: 6.8599 - mae: 2.0937 - val_loss: 6.7190 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7400 - mse: 6.7328 - mae: 2.0793 - val_loss: 6.7174 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7273 - mse: 6.7208 - mae: 2.0849 - val_loss: 6.7194 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8560 - mse: 6.8498 - mae: 2.0865 - val_loss: 6.7197 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7025 - mse: 6.6943 - mae: 2.0666 - val_loss: 6.7220 - val_mse: 6.7138 - val_mae: 2.0604\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8641 - mse: 6.8568 - mae: 2.0808 - val_loss: 6.7200 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7261 - mse: 6.7194 - mae: 2.0674 - val_loss: 6.7237 - val_mse: 6.7076 - val_mae: 2.0593\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7779 - mse: 6.7504 - mae: 2.0684 - val_loss: 6.7208 - val_mse: 6.7136 - val_mae: 2.0603\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9191 - mse: 6.9110 - mae: 2.0963 - val_loss: 6.7187 - val_mse: 6.7115 - val_mae: 2.0600\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9268 - mse: 6.9189 - mae: 2.0872 - val_loss: 6.7262 - val_mse: 6.7115 - val_mae: 2.0600\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9135 - mse: 6.9035 - mae: 2.0872 - val_loss: 6.7203 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7867 - mse: 6.7795 - mae: 2.0792 - val_loss: 6.7173 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9190 - mse: 6.9138 - mae: 2.1028 - val_loss: 6.7170 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0462 - mse: 7.0413 - mae: 2.1140 - val_loss: 6.7170 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0094 - mse: 7.0057 - mae: 2.1018 - val_loss: 6.7166 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9953 - mse: 6.9907 - mae: 2.1197 - val_loss: 6.7160 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7460 - mse: 6.7421 - mae: 2.0569 - val_loss: 6.7165 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.1578 - mse: 7.1544 - mae: 2.1380 - val_loss: 6.7159 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8330 - mse: 6.8299 - mae: 2.0979 - val_loss: 6.7155 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9765 - mse: 6.9736 - mae: 2.1104 - val_loss: 6.7159 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6773 - mse: 6.6743 - mae: 2.0557 - val_loss: 6.7153 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7293 - mse: 6.7264 - mae: 2.0741 - val_loss: 6.7155 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7643 - mse: 6.7606 - mae: 2.0736 - val_loss: 6.7181 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9539 - mse: 6.9497 - mae: 2.0872 - val_loss: 6.7179 - val_mse: 6.7132 - val_mae: 2.0603\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7366 - mse: 6.7323 - mae: 2.0731 - val_loss: 6.8807 - val_mse: 6.7164 - val_mae: 2.0606\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9757 - mse: 6.8805 - mae: 2.0914 - val_loss: 6.7443 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6388 - mse: 6.6144 - mae: 2.0399 - val_loss: 6.7243 - val_mse: 6.7112 - val_mae: 2.0600\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0124 - mse: 7.0017 - mae: 2.1140 - val_loss: 6.7188 - val_mse: 6.7116 - val_mae: 2.0601\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9006 - mse: 6.8924 - mae: 2.1048 - val_loss: 6.7210 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6843 - mse: 6.6757 - mae: 2.0612 - val_loss: 6.7194 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9239 - mse: 6.9165 - mae: 2.0853 - val_loss: 6.7188 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8467 - mse: 6.8402 - mae: 2.0911 - val_loss: 6.7173 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8403 - mse: 6.8352 - mae: 2.0915 - val_loss: 6.7172 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9961 - mse: 6.9912 - mae: 2.1181 - val_loss: 6.7173 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7284 - mse: 6.7232 - mae: 2.0753 - val_loss: 6.7165 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8665 - mse: 6.8624 - mae: 2.1024 - val_loss: 6.7156 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8286 - mse: 6.8248 - mae: 2.0838 - val_loss: 6.7154 - val_mse: 6.7116 - val_mae: 2.0601\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8933 - mse: 6.8895 - mae: 2.0944 - val_loss: 6.7154 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0234 - mse: 7.0199 - mae: 2.1142 - val_loss: 6.7173 - val_mse: 6.7129 - val_mae: 2.0603\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8171 - mse: 6.8133 - mae: 2.0737 - val_loss: 6.7177 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7191 - mse: 6.7151 - mae: 2.0653 - val_loss: 6.7161 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8646 - mse: 6.8609 - mae: 2.0729 - val_loss: 6.7157 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8173 - mse: 6.8007 - mae: 2.0732 - val_loss: 6.7763 - val_mse: 6.7079 - val_mae: 2.0594\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8163 - mse: 6.7768 - mae: 2.0795 - val_loss: 6.7363 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0082 - mse: 6.9919 - mae: 2.0999 - val_loss: 6.7211 - val_mse: 6.7134 - val_mae: 2.0603\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8319 - mse: 6.8241 - mae: 2.0984 - val_loss: 6.7205 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8689 - mse: 6.8605 - mae: 2.0923 - val_loss: 6.7213 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5978 - mse: 6.5908 - mae: 2.0495 - val_loss: 6.7191 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0614 - mse: 7.0557 - mae: 2.1131 - val_loss: 6.7183 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9513 - mse: 6.9452 - mae: 2.1089 - val_loss: 6.7183 - val_mse: 6.7132 - val_mae: 2.0603\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8394 - mse: 6.8341 - mae: 2.0854 - val_loss: 6.7172 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8196 - mse: 6.8153 - mae: 2.0696 - val_loss: 6.7172 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7883 - mse: 6.7826 - mae: 2.0607 - val_loss: 6.7210 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8958 - mse: 6.8893 - mae: 2.0931 - val_loss: 6.7178 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8816 - mse: 6.8768 - mae: 2.1023 - val_loss: 6.7171 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7926 - mse: 6.7883 - mae: 2.0775 - val_loss: 6.7156 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7764 - mse: 6.7728 - mae: 2.0848 - val_loss: 6.7161 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0257 - mse: 7.0218 - mae: 2.1075 - val_loss: 6.7158 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7829 - mse: 6.7796 - mae: 2.0796 - val_loss: 6.7158 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6587 - mse: 6.6556 - mae: 2.0517 - val_loss: 6.7151 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8188 - mse: 6.8147 - mae: 2.0731 - val_loss: 6.7174 - val_mse: 6.7108 - val_mae: 2.0599\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7793 - mse: 6.7750 - mae: 2.0655 - val_loss: 6.7155 - val_mse: 6.7112 - val_mae: 2.0600\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9127 - mse: 6.9094 - mae: 2.0937 - val_loss: 6.7151 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7655 - mse: 6.7619 - mae: 2.0731 - val_loss: 6.7150 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9534 - mse: 6.9504 - mae: 2.0954 - val_loss: 6.7151 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9077 - mse: 6.9045 - mae: 2.0945 - val_loss: 6.7451 - val_mse: 6.7189 - val_mae: 2.0611\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8185 - mse: 6.7690 - mae: 2.0790 - val_loss: 6.7230 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9529 - mse: 6.9447 - mae: 2.0985 - val_loss: 6.7192 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6058 - mse: 6.6000 - mae: 2.0414 - val_loss: 6.7174 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8565 - mse: 6.8519 - mae: 2.0919 - val_loss: 6.7174 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 6.8349 - mse: 6.8301 - mae: 2.0835 - val_loss: 6.7174 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9313 - mse: 6.9271 - mae: 2.1015 - val_loss: 6.7166 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9157 - mse: 6.9121 - mae: 2.1013 - val_loss: 6.7171 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0126 - mse: 7.0085 - mae: 2.1087 - val_loss: 6.7162 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8583 - mse: 6.8539 - mae: 2.0779 - val_loss: 6.7164 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9925 - mse: 6.9885 - mae: 2.1104 - val_loss: 6.7183 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8378 - mse: 6.8320 - mae: 2.0900 - val_loss: 6.7250 - val_mse: 6.7135 - val_mae: 2.0603\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8862 - mse: 6.8762 - mae: 2.1139 - val_loss: 6.7192 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7436 - mse: 6.7368 - mae: 2.0720 - val_loss: 6.7179 - val_mse: 6.7113 - val_mae: 2.0600\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8932 - mse: 6.8876 - mae: 2.1046 - val_loss: 6.7160 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9509 - mse: 6.9466 - mae: 2.1036 - val_loss: 6.7181 - val_mse: 6.7134 - val_mae: 2.0603\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8158 - mse: 6.8116 - mae: 2.0978 - val_loss: 6.7161 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7076 - mse: 6.7036 - mae: 2.0592 - val_loss: 6.7190 - val_mse: 6.7138 - val_mae: 2.0604\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0477 - mse: 7.0422 - mae: 2.1099 - val_loss: 6.7173 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9660 - mse: 6.9104 - mae: 2.0996 - val_loss: 6.7653 - val_mse: 6.7148 - val_mae: 2.0605\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8131 - mse: 6.7903 - mae: 2.0756 - val_loss: 6.7225 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7198 - mse: 6.7107 - mae: 2.0806 - val_loss: 6.7224 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7861 - mse: 6.7767 - mae: 2.0667 - val_loss: 6.7184 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7633 - mse: 6.7567 - mae: 2.0749 - val_loss: 6.7161 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7681 - mse: 6.7633 - mae: 2.0708 - val_loss: 6.7161 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9719 - mse: 6.9672 - mae: 2.1107 - val_loss: 6.7166 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0070 - mse: 7.0021 - mae: 2.0997 - val_loss: 6.7164 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7047 - mse: 6.7005 - mae: 2.0374 - val_loss: 6.7159 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9852 - mse: 6.9815 - mae: 2.1133 - val_loss: 6.7157 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8381 - mse: 6.8343 - mae: 2.0913 - val_loss: 6.7168 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8754 - mse: 6.8712 - mae: 2.0944 - val_loss: 6.7169 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8221 - mse: 6.8184 - mae: 2.0792 - val_loss: 6.7155 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9623 - mse: 6.9590 - mae: 2.1176 - val_loss: 6.7153 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8648 - mse: 6.8618 - mae: 2.0930 - val_loss: 6.7164 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9067 - mse: 6.9013 - mae: 2.0879 - val_loss: 6.7172 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7771 - mse: 6.7730 - mae: 2.0842 - val_loss: 6.7154 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8997 - mse: 6.8963 - mae: 2.0903 - val_loss: 6.7160 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9046 - mse: 6.9015 - mae: 2.0930 - val_loss: 6.7167 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9146 - mse: 6.9114 - mae: 2.0901 - val_loss: 6.7155 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8216 - mse: 6.8182 - mae: 2.0762 - val_loss: 6.7157 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7955 - mse: 6.7921 - mae: 2.0880 - val_loss: 6.7158 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.1208 - mse: 7.1172 - mae: 2.1303 - val_loss: 6.7154 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8463 - mse: 6.8429 - mae: 2.0850 - val_loss: 6.7150 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8529 - mse: 6.8498 - mae: 2.0924 - val_loss: 6.7150 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0003 - mse: 6.9971 - mae: 2.1130 - val_loss: 6.7152 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9774 - mse: 6.9723 - mae: 2.0977 - val_loss: 7.2009 - val_mse: 6.6970 - val_mae: 2.0564\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0952 - mse: 6.9125 - mae: 2.0982 - val_loss: 6.7549 - val_mse: 6.7113 - val_mae: 2.0600\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8665 - mse: 6.8202 - mae: 2.0827 - val_loss: 6.7474 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6364 - mse: 6.6023 - mae: 2.0504 - val_loss: 6.7430 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9939 - mse: 6.9651 - mae: 2.0957 - val_loss: 6.7325 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8292 - mse: 6.8081 - mae: 2.0797 - val_loss: 6.7293 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9776 - mse: 6.9621 - mae: 2.1013 - val_loss: 6.7301 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7991 - mse: 6.7835 - mae: 2.0738 - val_loss: 6.7235 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9452 - mse: 6.9324 - mae: 2.1002 - val_loss: 6.7277 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8268 - mse: 6.8145 - mae: 2.0751 - val_loss: 6.7247 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6713 - mse: 6.6595 - mae: 2.0579 - val_loss: 6.7219 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8551 - mse: 6.8448 - mae: 2.0846 - val_loss: 6.7202 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8629 - mse: 6.8532 - mae: 2.0750 - val_loss: 6.7215 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8200 - mse: 6.8107 - mae: 2.0730 - val_loss: 6.7205 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8617 - mse: 6.8536 - mae: 2.0900 - val_loss: 6.7208 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7665 - mse: 6.7581 - mae: 2.0760 - val_loss: 6.7203 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9118 - mse: 6.9045 - mae: 2.0963 - val_loss: 6.7188 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8024 - mse: 6.7956 - mae: 2.0890 - val_loss: 6.7184 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9234 - mse: 6.9169 - mae: 2.0994 - val_loss: 6.7176 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7724 - mse: 6.7665 - mae: 2.0689 - val_loss: 6.7193 - val_mse: 6.7135 - val_mae: 2.0603\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7935 - mse: 6.7873 - mae: 2.0755 - val_loss: 6.7191 - val_mse: 6.7114 - val_mae: 2.0600\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9563 - mse: 6.9484 - mae: 2.0966 - val_loss: 6.7163 - val_mse: 6.7122 - val_mae: 2.0601\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8706 - mse: 6.8661 - mae: 2.0973 - val_loss: 6.7182 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9092 - mse: 6.9049 - mae: 2.0900 - val_loss: 6.7192 - val_mse: 6.7139 - val_mae: 2.0604\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7860 - mse: 6.7813 - mae: 2.0882 - val_loss: 6.7162 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7334 - mse: 6.7296 - mae: 2.0772 - val_loss: 6.7157 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9531 - mse: 6.9496 - mae: 2.1122 - val_loss: 6.7171 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8220 - mse: 6.8176 - mae: 2.0842 - val_loss: 6.7156 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8253 - mse: 6.8220 - mae: 2.0837 - val_loss: 6.7161 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8340 - mse: 6.8303 - mae: 2.0849 - val_loss: 6.7154 - val_mse: 6.7116 - val_mae: 2.0601\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8332 - mse: 6.8297 - mae: 2.0832 - val_loss: 6.7149 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7540 - mse: 6.7507 - mae: 2.0820 - val_loss: 6.7163 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8939 - mse: 6.8906 - mae: 2.0830 - val_loss: 6.7157 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7381 - mse: 6.7348 - mae: 2.0689 - val_loss: 6.7159 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6042 - mse: 6.6010 - mae: 2.0514 - val_loss: 6.7159 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7186 - mse: 6.7156 - mae: 2.0676 - val_loss: 6.7158 - val_mse: 6.7128 - val_mae: 2.0602\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0516 - mse: 7.0484 - mae: 2.1078 - val_loss: 6.7157 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7870 - mse: 6.7840 - mae: 2.0663 - val_loss: 6.7154 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8151 - mse: 6.8122 - mae: 2.0745 - val_loss: 6.7151 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7095 - mse: 6.7067 - mae: 2.0674 - val_loss: 6.7152 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7888 - mse: 6.7860 - mae: 2.0767 - val_loss: 6.7160 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7781 - mse: 6.7747 - mae: 2.0595 - val_loss: 6.7155 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7005 - mse: 6.6974 - mae: 2.0749 - val_loss: 6.7147 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5664 - mse: 6.5636 - mae: 2.0283 - val_loss: 6.7154 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8176 - mse: 6.8124 - mae: 2.0792 - val_loss: 6.7170 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9023 - mse: 6.8975 - mae: 2.0794 - val_loss: 6.7164 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.5292 - mse: 6.5249 - mae: 2.0393 - val_loss: 6.7159 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8856 - mse: 6.8816 - mae: 2.1011 - val_loss: 6.7156 - val_mse: 6.7117 - val_mae: 2.0601\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 6.9253 - mse: 6.9206 - mae: 2.1080 - val_loss: 6.7154 - val_mse: 6.7114 - val_mae: 2.0600\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7934 - mse: 6.7897 - mae: 2.0814 - val_loss: 6.7158 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7301 - mse: 6.7258 - mae: 2.0710 - val_loss: 6.7164 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9116 - mse: 6.9070 - mae: 2.0868 - val_loss: 6.7158 - val_mse: 6.7120 - val_mae: 2.0601\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0059 - mse: 7.0021 - mae: 2.1138 - val_loss: 6.7153 - val_mse: 6.7102 - val_mae: 2.0598\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0384 - mse: 7.0310 - mae: 2.1053 - val_loss: 6.7163 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9583 - mse: 6.9538 - mae: 2.1096 - val_loss: 6.7161 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9429 - mse: 6.9394 - mae: 2.0956 - val_loss: 6.7158 - val_mse: 6.7125 - val_mae: 2.0602\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8197 - mse: 6.8160 - mae: 2.0729 - val_loss: 6.7163 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0935 - mse: 7.0901 - mae: 2.1233 - val_loss: 6.7157 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7725 - mse: 6.7692 - mae: 2.0733 - val_loss: 6.7162 - val_mse: 6.7131 - val_mae: 2.0603\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8022 - mse: 6.7992 - mae: 2.0886 - val_loss: 6.7157 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8964 - mse: 6.8931 - mae: 2.0977 - val_loss: 6.7159 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8662 - mse: 6.8633 - mae: 2.0946 - val_loss: 6.7158 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0164 - mse: 7.0132 - mae: 2.1074 - val_loss: 6.7149 - val_mse: 6.7119 - val_mae: 2.0601\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9855 - mse: 6.9824 - mae: 2.1179 - val_loss: 6.7150 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0017 - mse: 6.9988 - mae: 2.1139 - val_loss: 6.7153 - val_mse: 6.7124 - val_mae: 2.0602\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.9289 - mse: 6.9247 - mae: 2.1047 - val_loss: 6.7167 - val_mse: 6.7123 - val_mae: 2.0602\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0007 - mse: 6.9963 - mae: 2.1160 - val_loss: 6.7203 - val_mse: 6.7136 - val_mae: 2.0603\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0965 - mse: 7.0912 - mae: 2.0994 - val_loss: 6.7166 - val_mse: 6.7127 - val_mae: 2.0602\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0293 - mse: 7.0217 - mae: 2.1075 - val_loss: 6.7401 - val_mse: 6.7133 - val_mae: 2.0603\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 7.0214 - mse: 6.9676 - mae: 2.1082 - val_loss: 6.7290 - val_mse: 6.7129 - val_mae: 2.0602\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6661 - mse: 6.6497 - mae: 2.0514 - val_loss: 6.7223 - val_mse: 6.7126 - val_mae: 2.0602\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.8694 - mse: 6.8594 - mae: 2.0821 - val_loss: 6.7205 - val_mse: 6.7121 - val_mae: 2.0601\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6791 - mse: 6.6717 - mae: 2.0628 - val_loss: 6.7191 - val_mse: 6.7118 - val_mae: 2.0601\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.7177 - mse: 6.7114 - mae: 2.0697 - val_loss: 6.7196 - val_mse: 6.7130 - val_mae: 2.0603\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 6.6546 - mse: 6.6472 - mae: 2.0470 - val_loss: 6.7183 - val_mse: 6.7118 - val_mae: 2.0601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_soV27MfcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66177fbc-5513-423c-d722-4f5880e9542d"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(50, input_dim=4, activation='relu'))\n",
        "model2.add(Dense(40, activation='relu'))\n",
        "model2.add(Dense(30, activation='relu'))\n",
        "model2.add(Dense(20, activation='relu'))\n",
        "model2.add(Dense(10, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "\n",
        "model2.compile(optimizer='rmsprop', loss='mse', metrics=['mse', 'mae'])\n",
        "\n",
        "# training model\n",
        "history = model2.fit(x_train, y_train, epochs = 200,\n",
        "                        validation_data=(x_valid, y_valid),\n",
        "                        batch_size = 16, verbose = 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 7.0955 - mse: 7.0955 - mae: 2.1181 - val_loss: 6.7042 - val_mse: 6.7042 - val_mae: 2.0596\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8293 - mse: 6.8293 - mae: 2.0941 - val_loss: 6.7011 - val_mse: 6.7011 - val_mae: 2.0601\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.8254 - mse: 6.8254 - mae: 2.0822 - val_loss: 6.6983 - val_mse: 6.6983 - val_mae: 2.0592\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.6354 - mse: 6.6354 - mae: 2.0555 - val_loss: 6.7063 - val_mse: 6.7063 - val_mae: 2.0608\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.7924 - mse: 6.7924 - mae: 2.0675 - val_loss: 6.7137 - val_mse: 6.7137 - val_mae: 2.0624\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.6932 - mse: 6.6932 - mae: 2.0607 - val_loss: 6.7159 - val_mse: 6.7159 - val_mae: 2.0631\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7559 - mse: 6.7559 - mae: 2.0654 - val_loss: 6.7283 - val_mse: 6.7283 - val_mae: 2.0652\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8324 - mse: 6.8324 - mae: 2.0935 - val_loss: 6.7096 - val_mse: 6.7096 - val_mae: 2.0623\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7466 - mse: 6.7466 - mae: 2.0778 - val_loss: 6.7154 - val_mse: 6.7154 - val_mae: 2.0630\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.9204 - mse: 6.9204 - mae: 2.1005 - val_loss: 6.7237 - val_mse: 6.7237 - val_mae: 2.0631\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.8058 - mse: 6.8058 - mae: 2.0816 - val_loss: 6.7427 - val_mse: 6.7427 - val_mae: 2.0712\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.9080 - mse: 6.9080 - mae: 2.0829 - val_loss: 6.7722 - val_mse: 6.7722 - val_mae: 2.0722\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.9065 - mse: 6.9065 - mae: 2.0929 - val_loss: 6.7773 - val_mse: 6.7773 - val_mae: 2.0743\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8358 - mse: 6.8358 - mae: 2.0828 - val_loss: 6.7848 - val_mse: 6.7848 - val_mae: 2.0767\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7840 - mse: 6.7840 - mae: 2.0686 - val_loss: 6.7455 - val_mse: 6.7455 - val_mae: 2.0686\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8882 - mse: 6.8882 - mae: 2.0897 - val_loss: 6.7644 - val_mse: 6.7644 - val_mae: 2.0741\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.5356 - mse: 6.5356 - mae: 2.0375 - val_loss: 6.7541 - val_mse: 6.7541 - val_mae: 2.0728\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.6131 - mse: 6.6131 - mae: 2.0341 - val_loss: 6.8030 - val_mse: 6.8030 - val_mae: 2.0796\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8790 - mse: 6.8790 - mae: 2.0891 - val_loss: 6.7790 - val_mse: 6.7790 - val_mae: 2.0739\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 7.0100 - mse: 7.0100 - mae: 2.1157 - val_loss: 6.7636 - val_mse: 6.7636 - val_mae: 2.0713\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.6414 - mse: 6.6414 - mae: 2.0527 - val_loss: 6.7738 - val_mse: 6.7738 - val_mae: 2.0737\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.5814 - mse: 6.5814 - mae: 2.0357 - val_loss: 6.8037 - val_mse: 6.8037 - val_mae: 2.0786\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8675 - mse: 6.8675 - mae: 2.0858 - val_loss: 6.7794 - val_mse: 6.7794 - val_mae: 2.0763\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7785 - mse: 6.7785 - mae: 2.0793 - val_loss: 6.7627 - val_mse: 6.7627 - val_mae: 2.0744\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7733 - mse: 6.7733 - mae: 2.0701 - val_loss: 6.8016 - val_mse: 6.8016 - val_mae: 2.0783\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7897 - mse: 6.7897 - mae: 2.0820 - val_loss: 6.8190 - val_mse: 6.8190 - val_mae: 2.0829\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.6685 - mse: 6.6685 - mae: 2.0574 - val_loss: 6.8070 - val_mse: 6.8070 - val_mae: 2.0768\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8714 - mse: 6.8714 - mae: 2.0689 - val_loss: 6.8343 - val_mse: 6.8343 - val_mae: 2.0833\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.7243 - mse: 6.7243 - mae: 2.0649 - val_loss: 6.8201 - val_mse: 6.8201 - val_mae: 2.0829\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.5508 - mse: 6.5508 - mae: 2.0289 - val_loss: 6.7980 - val_mse: 6.7980 - val_mae: 2.0781\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.5504 - mse: 6.5504 - mae: 2.0362 - val_loss: 6.8935 - val_mse: 6.8935 - val_mae: 2.0939\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.4388 - mse: 6.4388 - mae: 2.0146 - val_loss: 6.8838 - val_mse: 6.8838 - val_mae: 2.0936\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.6696 - mse: 6.6696 - mae: 2.0562 - val_loss: 6.9166 - val_mse: 6.9166 - val_mae: 2.0952\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.6278 - mse: 6.6278 - mae: 2.0470 - val_loss: 6.8688 - val_mse: 6.8688 - val_mae: 2.0897\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.8800 - mse: 6.8800 - mae: 2.0758 - val_loss: 6.8722 - val_mse: 6.8722 - val_mae: 2.0841\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.4391 - mse: 6.4391 - mae: 2.0261 - val_loss: 6.9041 - val_mse: 6.9041 - val_mae: 2.0975\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.6178 - mse: 6.6178 - mae: 2.0434 - val_loss: 6.9103 - val_mse: 6.9103 - val_mae: 2.0952\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.6419 - mse: 6.6419 - mae: 2.0521 - val_loss: 6.9886 - val_mse: 6.9886 - val_mae: 2.1070\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.3961 - mse: 6.3961 - mae: 2.0119 - val_loss: 7.0715 - val_mse: 7.0715 - val_mae: 2.1182\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.5411 - mse: 6.5411 - mae: 2.0230 - val_loss: 6.9147 - val_mse: 6.9147 - val_mae: 2.0938\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3189 - mse: 6.3189 - mae: 1.9997 - val_loss: 7.0079 - val_mse: 7.0079 - val_mae: 2.1096\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2919 - mse: 6.2919 - mae: 1.9923 - val_loss: 7.0504 - val_mse: 7.0504 - val_mae: 2.1193\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.6021 - mse: 6.6021 - mae: 2.0403 - val_loss: 6.9462 - val_mse: 6.9462 - val_mae: 2.0984\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.4611 - mse: 6.4611 - mae: 2.0108 - val_loss: 7.0438 - val_mse: 7.0438 - val_mae: 2.1127\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.5909 - mse: 6.5909 - mae: 2.0390 - val_loss: 7.0150 - val_mse: 7.0150 - val_mae: 2.1085\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3590 - mse: 6.3590 - mae: 1.9992 - val_loss: 6.9885 - val_mse: 6.9885 - val_mae: 2.1024\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.2759 - mse: 6.2759 - mae: 1.9934 - val_loss: 7.0790 - val_mse: 7.0790 - val_mae: 2.1224\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.3486 - mse: 6.3486 - mae: 2.0079 - val_loss: 6.9448 - val_mse: 6.9448 - val_mae: 2.0963\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.4167 - mse: 6.4167 - mae: 2.0104 - val_loss: 7.1112 - val_mse: 7.1112 - val_mae: 2.1275\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.5508 - mse: 6.5508 - mae: 2.0274 - val_loss: 7.0124 - val_mse: 7.0124 - val_mae: 2.1102\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.5135 - mse: 6.5135 - mae: 2.0352 - val_loss: 7.1526 - val_mse: 7.1526 - val_mae: 2.1329\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.5218 - mse: 6.5218 - mae: 2.0134 - val_loss: 7.1215 - val_mse: 7.1215 - val_mae: 2.1262\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2315 - mse: 6.2315 - mae: 1.9748 - val_loss: 7.0918 - val_mse: 7.0918 - val_mae: 2.1254\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.3927 - mse: 6.3927 - mae: 2.0033 - val_loss: 7.1782 - val_mse: 7.1782 - val_mae: 2.1378\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.4503 - mse: 6.4503 - mae: 2.0130 - val_loss: 7.1457 - val_mse: 7.1457 - val_mae: 2.1342\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2865 - mse: 6.2865 - mae: 1.9844 - val_loss: 7.0961 - val_mse: 7.0961 - val_mae: 2.1217\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3845 - mse: 6.3845 - mae: 2.0088 - val_loss: 7.1155 - val_mse: 7.1155 - val_mae: 2.1275\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2685 - mse: 6.2685 - mae: 1.9756 - val_loss: 7.0994 - val_mse: 7.0994 - val_mae: 2.1212\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3686 - mse: 6.3686 - mae: 2.0012 - val_loss: 7.2388 - val_mse: 7.2388 - val_mae: 2.1468\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3387 - mse: 6.3387 - mae: 1.9901 - val_loss: 7.3190 - val_mse: 7.3190 - val_mae: 2.1599\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.5886 - mse: 6.5886 - mae: 2.0245 - val_loss: 7.3942 - val_mse: 7.3942 - val_mae: 2.1725\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3651 - mse: 6.3651 - mae: 1.9951 - val_loss: 7.1305 - val_mse: 7.1305 - val_mae: 2.1276\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.1415 - mse: 6.1415 - mae: 1.9523 - val_loss: 7.2546 - val_mse: 7.2546 - val_mae: 2.1449\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0646 - mse: 6.0646 - mae: 1.9483 - val_loss: 7.2007 - val_mse: 7.2007 - val_mae: 2.1384\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3370 - mse: 6.3370 - mae: 1.9914 - val_loss: 7.2253 - val_mse: 7.2253 - val_mae: 2.1452\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.3015 - mse: 6.3015 - mae: 1.9845 - val_loss: 7.2289 - val_mse: 7.2289 - val_mae: 2.1473\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0629 - mse: 6.0629 - mae: 1.9410 - val_loss: 7.2810 - val_mse: 7.2810 - val_mae: 2.1497\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.1136 - mse: 6.1136 - mae: 1.9642 - val_loss: 7.2540 - val_mse: 7.2540 - val_mae: 2.1526\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.1579 - mse: 6.1579 - mae: 1.9464 - val_loss: 7.4855 - val_mse: 7.4855 - val_mae: 2.1827\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.1851 - mse: 6.1851 - mae: 1.9690 - val_loss: 7.3853 - val_mse: 7.3853 - val_mae: 2.1720\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2282 - mse: 6.2282 - mae: 1.9697 - val_loss: 7.3792 - val_mse: 7.3792 - val_mae: 2.1721\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.1249 - mse: 6.1249 - mae: 1.9554 - val_loss: 7.2656 - val_mse: 7.2656 - val_mae: 2.1536\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2831 - mse: 6.2831 - mae: 1.9809 - val_loss: 7.3717 - val_mse: 7.3717 - val_mae: 2.1685\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.1547 - mse: 6.1547 - mae: 1.9504 - val_loss: 7.2962 - val_mse: 7.2962 - val_mae: 2.1644\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0747 - mse: 6.0747 - mae: 1.9527 - val_loss: 7.3578 - val_mse: 7.3578 - val_mae: 2.1639\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2181 - mse: 6.2181 - mae: 1.9751 - val_loss: 7.5410 - val_mse: 7.5410 - val_mae: 2.1883\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0615 - mse: 6.0615 - mae: 1.9422 - val_loss: 7.4077 - val_mse: 7.4077 - val_mae: 2.1744\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0582 - mse: 6.0582 - mae: 1.9441 - val_loss: 7.3149 - val_mse: 7.3149 - val_mae: 2.1625\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0107 - mse: 6.0107 - mae: 1.9444 - val_loss: 7.4150 - val_mse: 7.4150 - val_mae: 2.1750\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.1541 - mse: 6.1541 - mae: 1.9682 - val_loss: 7.6077 - val_mse: 7.6077 - val_mae: 2.2127\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.2375 - mse: 6.2375 - mae: 1.9771 - val_loss: 7.6531 - val_mse: 7.6531 - val_mae: 2.2081\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0330 - mse: 6.0330 - mae: 1.9332 - val_loss: 7.5556 - val_mse: 7.5556 - val_mae: 2.1992\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9390 - mse: 5.9390 - mae: 1.9210 - val_loss: 7.4662 - val_mse: 7.4662 - val_mae: 2.1771\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9657 - mse: 5.9657 - mae: 1.9297 - val_loss: 7.5444 - val_mse: 7.5444 - val_mae: 2.1931\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9756 - mse: 5.9756 - mae: 1.9160 - val_loss: 7.4084 - val_mse: 7.4084 - val_mae: 2.1711\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0551 - mse: 6.0551 - mae: 1.9199 - val_loss: 7.6996 - val_mse: 7.6996 - val_mae: 2.2172\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 6.0157 - mse: 6.0157 - mae: 1.9350 - val_loss: 7.3800 - val_mse: 7.3800 - val_mae: 2.1618\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 5.9016 - mse: 5.9016 - mae: 1.9182 - val_loss: 7.5136 - val_mse: 7.5136 - val_mae: 2.1868\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9049 - mse: 5.9049 - mae: 1.9001 - val_loss: 7.5205 - val_mse: 7.5205 - val_mae: 2.1860\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9155 - mse: 5.9155 - mae: 1.9042 - val_loss: 7.7439 - val_mse: 7.7439 - val_mae: 2.2214\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9520 - mse: 5.9520 - mae: 1.9203 - val_loss: 7.6834 - val_mse: 7.6834 - val_mae: 2.2146\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9522 - mse: 5.9522 - mae: 1.9231 - val_loss: 7.5359 - val_mse: 7.5359 - val_mae: 2.1848\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8876 - mse: 5.8876 - mae: 1.9133 - val_loss: 7.5645 - val_mse: 7.5645 - val_mae: 2.1925\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 5.8711 - mse: 5.8711 - mae: 1.8972 - val_loss: 7.5342 - val_mse: 7.5342 - val_mae: 2.1928\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9750 - mse: 5.9750 - mae: 1.9254 - val_loss: 7.6202 - val_mse: 7.6202 - val_mae: 2.2087\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 6.0561 - mse: 6.0561 - mae: 1.9259 - val_loss: 7.5897 - val_mse: 7.5897 - val_mae: 2.2030\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8705 - mse: 5.8705 - mae: 1.9041 - val_loss: 7.5964 - val_mse: 7.5964 - val_mae: 2.2019\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6388 - mse: 5.6388 - mae: 1.8530 - val_loss: 7.7363 - val_mse: 7.7363 - val_mae: 2.2193\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7467 - mse: 5.7467 - mae: 1.8916 - val_loss: 7.7658 - val_mse: 7.7658 - val_mae: 2.2207\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 5.9182 - mse: 5.9182 - mae: 1.9241 - val_loss: 7.6151 - val_mse: 7.6151 - val_mae: 2.2029\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7875 - mse: 5.7875 - mae: 1.8913 - val_loss: 7.5097 - val_mse: 7.5097 - val_mae: 2.1884\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9627 - mse: 5.9627 - mae: 1.9294 - val_loss: 7.6063 - val_mse: 7.6063 - val_mae: 2.2039\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9357 - mse: 5.9357 - mae: 1.9204 - val_loss: 8.0831 - val_mse: 8.0831 - val_mae: 2.2725\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7914 - mse: 5.7914 - mae: 1.8893 - val_loss: 7.7261 - val_mse: 7.7261 - val_mae: 2.2190\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9769 - mse: 5.9769 - mae: 1.9219 - val_loss: 7.6894 - val_mse: 7.6894 - val_mae: 2.2157\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9351 - mse: 5.9351 - mae: 1.9129 - val_loss: 7.5469 - val_mse: 7.5469 - val_mae: 2.1873\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8473 - mse: 5.8473 - mae: 1.9198 - val_loss: 7.6829 - val_mse: 7.6829 - val_mae: 2.2120\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9079 - mse: 5.9079 - mae: 1.9251 - val_loss: 7.6510 - val_mse: 7.6510 - val_mae: 2.2142\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7313 - mse: 5.7313 - mae: 1.8802 - val_loss: 7.8512 - val_mse: 7.8512 - val_mae: 2.2311\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 5.9691 - mse: 5.9691 - mae: 1.9254 - val_loss: 7.7669 - val_mse: 7.7669 - val_mae: 2.2220\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 5.9096 - mse: 5.9096 - mae: 1.9112 - val_loss: 7.9287 - val_mse: 7.9287 - val_mae: 2.2419\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7755 - mse: 5.7755 - mae: 1.9081 - val_loss: 7.7704 - val_mse: 7.7704 - val_mae: 2.2202\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8253 - mse: 5.8253 - mae: 1.8860 - val_loss: 7.7826 - val_mse: 7.7826 - val_mae: 2.2242\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.9039 - mse: 5.9039 - mae: 1.9100 - val_loss: 7.7668 - val_mse: 7.7668 - val_mae: 2.2229\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7115 - mse: 5.7115 - mae: 1.8693 - val_loss: 7.8318 - val_mse: 7.8318 - val_mae: 2.2339\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6939 - mse: 5.6939 - mae: 1.8727 - val_loss: 7.9432 - val_mse: 7.9432 - val_mae: 2.2544\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6984 - mse: 5.6984 - mae: 1.8800 - val_loss: 7.6942 - val_mse: 7.6942 - val_mae: 2.2182\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6772 - mse: 5.6772 - mae: 1.8783 - val_loss: 7.8287 - val_mse: 7.8287 - val_mae: 2.2307\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5194 - mse: 5.5194 - mae: 1.8606 - val_loss: 7.8210 - val_mse: 7.8210 - val_mae: 2.2343\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5973 - mse: 5.5973 - mae: 1.8477 - val_loss: 7.7706 - val_mse: 7.7706 - val_mae: 2.2164\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8938 - mse: 5.8938 - mae: 1.9096 - val_loss: 7.9342 - val_mse: 7.9342 - val_mae: 2.2578\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8539 - mse: 5.8539 - mae: 1.9061 - val_loss: 7.7432 - val_mse: 7.7432 - val_mae: 2.2177\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.7533 - mse: 5.7533 - mae: 1.8891 - val_loss: 7.9428 - val_mse: 7.9428 - val_mae: 2.2515\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6427 - mse: 5.6427 - mae: 1.8643 - val_loss: 7.8288 - val_mse: 7.8288 - val_mae: 2.2352\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4834 - mse: 5.4834 - mae: 1.8361 - val_loss: 8.2248 - val_mse: 8.2248 - val_mae: 2.2926\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5225 - mse: 5.5225 - mae: 1.8401 - val_loss: 7.9081 - val_mse: 7.9081 - val_mae: 2.2505\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 5.5821 - mse: 5.5821 - mae: 1.8597 - val_loss: 7.9014 - val_mse: 7.9014 - val_mae: 2.2414\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.8118 - mse: 5.8118 - mae: 1.8938 - val_loss: 8.1741 - val_mse: 8.1741 - val_mae: 2.2804\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6267 - mse: 5.6267 - mae: 1.8596 - val_loss: 8.1744 - val_mse: 8.1744 - val_mae: 2.2776\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4381 - mse: 5.4381 - mae: 1.8397 - val_loss: 7.9235 - val_mse: 7.9235 - val_mae: 2.2441\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3074 - mse: 5.3074 - mae: 1.8163 - val_loss: 8.0736 - val_mse: 8.0736 - val_mae: 2.2725\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5368 - mse: 5.5368 - mae: 1.8489 - val_loss: 8.1003 - val_mse: 8.1003 - val_mae: 2.2740\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3436 - mse: 5.3436 - mae: 1.8150 - val_loss: 8.1739 - val_mse: 8.1739 - val_mae: 2.2822\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4644 - mse: 5.4644 - mae: 1.8332 - val_loss: 7.9151 - val_mse: 7.9151 - val_mae: 2.2501\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5802 - mse: 5.5802 - mae: 1.8568 - val_loss: 8.1396 - val_mse: 8.1396 - val_mae: 2.2823\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6478 - mse: 5.6478 - mae: 1.8542 - val_loss: 8.2944 - val_mse: 8.2944 - val_mae: 2.3069\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5501 - mse: 5.5501 - mae: 1.8502 - val_loss: 8.2814 - val_mse: 8.2814 - val_mae: 2.2965\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.6972 - mse: 5.6972 - mae: 1.8736 - val_loss: 7.9579 - val_mse: 7.9579 - val_mae: 2.2505\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5031 - mse: 5.5031 - mae: 1.8473 - val_loss: 8.0695 - val_mse: 8.0695 - val_mae: 2.2732\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4608 - mse: 5.4608 - mae: 1.8413 - val_loss: 8.1448 - val_mse: 8.1448 - val_mae: 2.2797\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3752 - mse: 5.3752 - mae: 1.8221 - val_loss: 8.3233 - val_mse: 8.3233 - val_mae: 2.2982\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5186 - mse: 5.5186 - mae: 1.8382 - val_loss: 8.1605 - val_mse: 8.1605 - val_mae: 2.2906\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3774 - mse: 5.3774 - mae: 1.8170 - val_loss: 8.2201 - val_mse: 8.2201 - val_mae: 2.2901\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4237 - mse: 5.4237 - mae: 1.8309 - val_loss: 8.2541 - val_mse: 8.2541 - val_mae: 2.2928\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3158 - mse: 5.3158 - mae: 1.8086 - val_loss: 8.3098 - val_mse: 8.3098 - val_mae: 2.3084\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4559 - mse: 5.4559 - mae: 1.8336 - val_loss: 8.1917 - val_mse: 8.1917 - val_mae: 2.2897\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5246 - mse: 5.5246 - mae: 1.8377 - val_loss: 8.3948 - val_mse: 8.3948 - val_mae: 2.3135\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5548 - mse: 5.5548 - mae: 1.8388 - val_loss: 8.0912 - val_mse: 8.0912 - val_mae: 2.2671\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3389 - mse: 5.3389 - mae: 1.8184 - val_loss: 8.3011 - val_mse: 8.3011 - val_mae: 2.3001\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3774 - mse: 5.3774 - mae: 1.8134 - val_loss: 7.9836 - val_mse: 7.9836 - val_mae: 2.2518\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4958 - mse: 5.4958 - mae: 1.8434 - val_loss: 8.1298 - val_mse: 8.1298 - val_mae: 2.2802\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4113 - mse: 5.4113 - mae: 1.8291 - val_loss: 8.0825 - val_mse: 8.0825 - val_mae: 2.2710\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0118 - mse: 5.0118 - mae: 1.7589 - val_loss: 8.3426 - val_mse: 8.3426 - val_mae: 2.3014\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3847 - mse: 5.3847 - mae: 1.8091 - val_loss: 8.1869 - val_mse: 8.1869 - val_mae: 2.2863\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.2581 - mse: 5.2581 - mae: 1.7966 - val_loss: 8.1914 - val_mse: 8.1914 - val_mae: 2.2890\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3371 - mse: 5.3371 - mae: 1.8182 - val_loss: 8.3078 - val_mse: 8.3078 - val_mae: 2.3044\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.5181 - mse: 5.5181 - mae: 1.8269 - val_loss: 8.1282 - val_mse: 8.1282 - val_mae: 2.2851\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4200 - mse: 5.4200 - mae: 1.8153 - val_loss: 8.1464 - val_mse: 8.1464 - val_mae: 2.2806\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3665 - mse: 5.3665 - mae: 1.8036 - val_loss: 8.4094 - val_mse: 8.4094 - val_mae: 2.3170\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1576 - mse: 5.1576 - mae: 1.7834 - val_loss: 8.2884 - val_mse: 8.2884 - val_mae: 2.3016\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3355 - mse: 5.3355 - mae: 1.8008 - val_loss: 8.4071 - val_mse: 8.4071 - val_mae: 2.3193\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.4375 - mse: 5.4375 - mae: 1.8329 - val_loss: 8.2953 - val_mse: 8.2953 - val_mae: 2.3017\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3536 - mse: 5.3536 - mae: 1.8132 - val_loss: 8.3017 - val_mse: 8.3017 - val_mae: 2.2949\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.2213 - mse: 5.2213 - mae: 1.7733 - val_loss: 8.3852 - val_mse: 8.3852 - val_mae: 2.3207\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3703 - mse: 5.3703 - mae: 1.8179 - val_loss: 8.4262 - val_mse: 8.4262 - val_mae: 2.3134\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.2154 - mse: 5.2154 - mae: 1.7828 - val_loss: 8.4441 - val_mse: 8.4441 - val_mae: 2.3178\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1216 - mse: 5.1216 - mae: 1.7827 - val_loss: 8.2926 - val_mse: 8.2926 - val_mae: 2.2872\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1196 - mse: 5.1196 - mae: 1.7565 - val_loss: 8.2772 - val_mse: 8.2772 - val_mae: 2.2949\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3606 - mse: 5.3606 - mae: 1.8118 - val_loss: 8.4693 - val_mse: 8.4693 - val_mae: 2.3303\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1254 - mse: 5.1254 - mae: 1.7789 - val_loss: 8.5617 - val_mse: 8.5617 - val_mae: 2.3432\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0927 - mse: 5.0927 - mae: 1.7470 - val_loss: 8.4822 - val_mse: 8.4822 - val_mae: 2.3257\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0566 - mse: 5.0566 - mae: 1.7660 - val_loss: 8.3876 - val_mse: 8.3876 - val_mae: 2.3093\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.3615 - mse: 5.3615 - mae: 1.8198 - val_loss: 8.4018 - val_mse: 8.4018 - val_mae: 2.3118\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0860 - mse: 5.0860 - mae: 1.7593 - val_loss: 8.4661 - val_mse: 8.4661 - val_mae: 2.3186\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1477 - mse: 5.1477 - mae: 1.7723 - val_loss: 8.3670 - val_mse: 8.3670 - val_mae: 2.3106\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.2012 - mse: 5.2012 - mae: 1.7964 - val_loss: 8.4952 - val_mse: 8.4952 - val_mae: 2.3249\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 5.2657 - mse: 5.2657 - mae: 1.7923 - val_loss: 8.7146 - val_mse: 8.7146 - val_mae: 2.3542\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0205 - mse: 5.0205 - mae: 1.7770 - val_loss: 8.5583 - val_mse: 8.5583 - val_mae: 2.3391\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0752 - mse: 5.0752 - mae: 1.7694 - val_loss: 8.3917 - val_mse: 8.3917 - val_mae: 2.3153\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1549 - mse: 5.1549 - mae: 1.7677 - val_loss: 8.4422 - val_mse: 8.4422 - val_mae: 2.3138\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1369 - mse: 5.1369 - mae: 1.7731 - val_loss: 8.5470 - val_mse: 8.5470 - val_mae: 2.3301\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0328 - mse: 5.0328 - mae: 1.7500 - val_loss: 8.5451 - val_mse: 8.5451 - val_mae: 2.3346\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1118 - mse: 5.1118 - mae: 1.7709 - val_loss: 8.5973 - val_mse: 8.5973 - val_mae: 2.3474\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1800 - mse: 5.1800 - mae: 1.7700 - val_loss: 8.7550 - val_mse: 8.7550 - val_mae: 2.3705\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0544 - mse: 5.0544 - mae: 1.7568 - val_loss: 8.6266 - val_mse: 8.6266 - val_mae: 2.3461\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.9263 - mse: 4.9263 - mae: 1.7368 - val_loss: 8.5361 - val_mse: 8.5361 - val_mae: 2.3337\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.8751 - mse: 4.8751 - mae: 1.7319 - val_loss: 8.5532 - val_mse: 8.5532 - val_mae: 2.3421\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.9655 - mse: 4.9655 - mae: 1.7484 - val_loss: 8.5404 - val_mse: 8.5404 - val_mae: 2.3283\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0666 - mse: 5.0666 - mae: 1.7625 - val_loss: 8.6156 - val_mse: 8.6156 - val_mae: 2.3490\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0149 - mse: 5.0149 - mae: 1.7459 - val_loss: 8.6493 - val_mse: 8.6493 - val_mae: 2.3397\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1183 - mse: 5.1183 - mae: 1.7665 - val_loss: 9.0190 - val_mse: 9.0190 - val_mae: 2.4097\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0608 - mse: 5.0608 - mae: 1.7430 - val_loss: 8.6702 - val_mse: 8.6702 - val_mae: 2.3565\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0833 - mse: 5.0833 - mae: 1.7516 - val_loss: 8.7920 - val_mse: 8.7920 - val_mae: 2.3683\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0911 - mse: 5.0911 - mae: 1.7761 - val_loss: 8.8564 - val_mse: 8.8564 - val_mae: 2.3795\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.8992 - mse: 4.8992 - mae: 1.7281 - val_loss: 8.7620 - val_mse: 8.7620 - val_mae: 2.3616\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.1600 - mse: 5.1600 - mae: 1.7768 - val_loss: 8.5492 - val_mse: 8.5492 - val_mae: 2.3264\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.7864 - mse: 4.7864 - mae: 1.7143 - val_loss: 8.8348 - val_mse: 8.8348 - val_mae: 2.3714\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.9042 - mse: 4.9042 - mae: 1.7438 - val_loss: 8.9306 - val_mse: 8.9306 - val_mae: 2.3887\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 4.9615 - mse: 4.9615 - mae: 1.7377 - val_loss: 8.8893 - val_mse: 8.8893 - val_mae: 2.3790\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 5.0990 - mse: 5.0990 - mae: 1.7566 - val_loss: 8.9335 - val_mse: 8.9335 - val_mae: 2.3794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjK6n529rRhR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}